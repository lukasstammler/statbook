[["index.html", "Leitfaden Statistik 1 Über diesen Leitfaden", " Leitfaden Statistik Lukas Stammler 2021-11-29 1 Über diesen Leitfaden Dieses Dokument ergänzt die Unterrichtsmaterialien zum Grundkurs Statistik am Studiengang BSc Physiotherapie der Berner Fachhochschule BFH, Departement Gesundheit. Es enthält die Lernziele für einen 2 ECTS-Kurs und vertieft gewisse Aspekte, die im Unterricht nur kursorisch behandelt werden können. Der Leitfaden basiert teilweise auf der Arbeit der OpenIntro-Gruppe. OpenIntro ist eine Nonprofit-Organisation, die sich zum Ziel gesetzt hat, Studierenden und Lehrer:innen qualitativ hochwertiges Schulungsmaterial für den Statistikunterricht kostenfrei zur Verfügung zu stellen. Einige Abschnitte dieses Textes sind Übersetzungen aus dem Englischen aus dem Buch OpenIntro-Statistics (Dietz, Barr, and Cetinkaya-Rundel 2017). Für einige Abbildungen wurde der R-Code aus dem OpenIntro-Github-Repositorium übernommen und für den vorliegenden Text angepasst. Ich kann das didaktisch hervorragende Buch, das über die Homepage von OpenIntro gratis im pdf-Format heruntergeladen werden kann, allen Interessierten wärmstens empfehlen. Im Unterricht mit den Bachelorstudierenden arbeiten wir mit der R-Umgebung jamovi (The Jamovi Project 2021), damit die Studierenden nicht zusätzlich mit dem Lernen von R (R Core Team 2021) belastet werden. Video-Anleitungen für die Arbeit mit jamovi findet man z.B. hier oder im Buch von Navarro and Foxcroft (2019), das als pdf-Download frei zugänglich ist. Übungen werden über Rpubs bereitgestellt. Die verwendeten Datensätze können hier als .csv oder hier als zip-Datei heruntergeladen werden. Der Leitfaden wurde mit ´Bookdown´ Xie (2021) erstellt. Lukas Stammler, Winter 2021/22 Version 0.1 Hinweise auf Fehler gerne an lukas.stammler@bfh.ch References "],["einführung.html", "2 Einführung", " 2 Einführung All models are wrong, but some are useful.  George E.P. Box In den Naturwissenschaften sind Erkenntnisse meist mit einer gewissen Unsicherheit verbunden. Beispiele dafür sind die Wettervorhersage für die nächsten Tage oder das tägliche Verkehrsaufkommen bei einer Brücke. Auch wenn man die Zugfestigkeit von Sehnen experimentell ermittelt, ist das Ergebnis mit Unsicherheit verbunden; einerseits infolge von Messungenauigkeit, andererseits weil eine natürliche Variabilität zwischen Beobachtungseinheiten vorhanden ist (keine zwei Beobachtungseinheiten sind exakt identisch). Die Unsicherheit kann auch durch fehlendes Wissen auftreten, z.B. weil wir nur einen beschränkten Zugriff auf Daten haben (wir können nie den Blutdruck von allen Menschen messen). Wir benötigen daher Methoden, um unsichere Phänomene angemessen zu modellieren, aber auch um Daten richtig zu verstehen. Aus den vorliegenden Daten wollen wir ja (korrekte) Rückschlüsse ziehen, um auf dieser Grundlage Entscheidungen zu treffen. Die Wahrscheinlichkeitsrechnung und die Statistik liefern Methoden, die uns dabei unterstützen. Was tun Wissenschaftler, die in der Forschung arbeiten, die also versuchen, bestimmte Teilaspekte der uns umgebenden Welt zu verstehen? Manche von ihnen machen das,was die meisten Menschen von Wissenschaftlern erwarten: Sie beobachten, zählen, messen, registrieren, katalogisieren. Sie sind die Empiriker:innen. Sie streben danach, möglichst genaue Informationen über die Vorgänge in der Natur zu erhalten. Das ist die eine Seite der wissenschaftlichen Arbeit. Für die andere Seite sind die Theoretiker:innen zuständig, die versuchen, in den Beobachtungen der Empiriker:innen Gesetzmässigkeiten zu erkennen und diese so zu formulieren, dass sie nicht nur mit den vorhandenen Beobachtungen übereinstimmen, sondern auch die Ergebnisse von Experimenten voraussagen können, die noch gar nicht durchgeführt worden sind. Solche Gesetzmässigkeiten können unterschiedliche Gestalt annehmen: Formeln, Diagramme oder Algorithmen. Jede wissenschaftliche Theorie ist ein Modell des beobachteten Aspekts der Wirklichkeit. Modelle stellen stets eine Abstraktion oder Idealisierung dar: Sie beschreiben die Realität niemals absolut genau, sondern erfassen bestimmte relevante Aspekte »hinreichend gut«; für eine Fragestellung weniger bedeutende Details werden dabei vernachlässigt. So gesehen sind alle Modelle falsch, wie der Statistiker George Box provokant formulierte. Trotzdem sind sie nützlich, weil sie uns helfen, von einzelnen Beobachtungen auf das Ganze zu schliessen. Die Modelle, welche z.B. in der Wettervorhersage verwendet werden, so komplex sie sein mögen, beruhen auf vielen Vereinfachungen; daher trifft die die Wettervorhersage nicht immer zu - aber sie ist, zumindest gelegentlich, sehr nützlich. Die (komplexe) Realität kann mit Modellen abgebildet werden. Modelle liefern zwar vereinfachende Beschreibungen der Realität, dadurch ermöglichen sie aber allgemeine Aussagen, welche sonst nicht gemacht werden könnten.  Marco Waser In der Statistik geht es darum, aus vorhandenen Daten auf den datengenerierenden Mechanismus zu schliessen. Wir sehen ein paar (wenige) Datenpunkte (z.B. Blutdruckmessungen) und versuchen mit diesem beschränkten Wissen herauszufinden, was wohl ein gutes Modell dafür ist. Auch wenn wir Experimente durchführen, erhalten wir Daten, die angemessen ausgewertet werden müssen. Wenn wir also einen wissenschaftlichen Fachartikel beurteilen sollen, dann kommt darin wohl fast immer auch eine Datenanalyse vor. Um Fehlschlüsse zu vermeiden und Fehlinterpretationen zu durchschauen benötigen wir ein Verständnis der theoretischen Grundlagen. "],["deskriptive-statistik.html", "3 Deskriptive Statistik 3.1 Lernziele 3.2 Grundbegriffe 3.3 Quantitative und qualitative Daten 3.4 Quantitative Daten zusammenfassen 3.5 Qualitative Daten zusammenfassen 3.6 Grundregeln für die Erstellung von Grafiken", " 3 Deskriptive Statistik Ein Bild sagt mehr als tausend Worte. Jede statistische Analyse beginnt mit der Beschreibung und der Zusammenfassung der vorliegenden Daten. In diesem Kapitel geht es darum, wie die verschiedenen Datentypen, durch Kennzahlen und Grafiken geeignet zusammengefasst und präsentiert werden können. 3.1 Lernziele Beschreibe Daten mit den Begriffen Beobachtungseinheit, Beobachtungsmerkmal (= Variable), Ausprägung von Beobachtungseinheiten. Unterscheide quantitative und qualitative Daten. Unterscheide bei quantitativen Daten zwischen kontinuierlichen und diskreten Variablen. Unterscheide bei qualitativen Daten zwischen nominalen (= kategoriale) und ordinalen Variablen. Erwähne bei der Beschreibung von quantitativen Daten die Form der Verteilung und die Kennzahlen der Lage und der Streuung. Kennzahlen der Lage: Mittelwert \\(\\bar{x}\\) und Median Kennzahlen der Streuung: Varianz \\(s^2\\), Standardabweichung \\(s\\), Variationsbreite (= Spannweite) und Interquartilabstand (IQR, engl. interquartile range) Beschreibe die Verteilung einer Variable als symmetrisch, rechtsschief oder linksschief. Verwende Histogramme und Boxplots um die Verteilung von quantitativen Daten zu beschreiben. Definiere robuste statisische Kennzahlen wie Median und IQR als Kennzahlen, die wenig von der Verteilungsform und von Ausreissern beeinflusst werden. Verwende Kreuztabellen und Balkendiagramme zur Beschreibung qualitativer Daten. 3.2 Grundbegriffe Wir verwenden in diesem Kapitel einen Datensatz mit biometrischen Merkmalen von Studierenden Tabelle 3.1: Daten der ersten 5 Studierenden im Datensatz phy.csv (n = 228) ID Kohorte Klasse Geschlecht Augenfarbe Groesse Gewicht Statistik 1 phy14 2 w blau 170 62 3 2 phy14 1 w gruen 160 56 2 3 phy14 1 w blau 169 68 2 4 phy14 1 m blau 182 70 2 5 phy14 1 w gruen 173 73 2 Codebook: ID: Student:in Kohorte: Jahrgang: PHY14, PHY15, PHY16, PHY17 Klasse: Klasse: 1, 2 Geschlecht: Geschlecht: m = männlich, w = weiblich Augenfarbe: Farbe: blau, grün, braun Groesse: Körpergrösse in cm Gewicht: Körpergewicht in kg Statistik: Interesse am Fach Statistik \\(^a\\) \\(^a\\) Frage: Statistik interessiert mich Auswahlitems: 1 trifft nicht zu 2 trifft kaum zu 3 trifft etwas zu 4 trifft eher zu 5 trifft sehr zu In der Statistik beobachten wir typischerweise verschiedene (Beobachtungs-)Merkmale, wie das Geschlecht, die Körpergröße oder die Zugehörigkeit zu einer Klasse in der Datenerhebung im Studiengang Physiotherapie, an Beobachtungseinheiten, im vorliegenden Fall an Studierenden. Solche Merkmale bezeichnen wir als Variablen und die Werte, welche die Variablen annehmen können als Merkmalsausprägungen. Bei der Datenerhebung in Studien werden die Daten in Tabellen erfasst. In diesen Datentabellen (Datensätzen) wird für jedes erhobene Merkmale in eine separate Spalte erstellt. Jede Beobachtungseinheit wird in einer separaten Zeile erfasst, in der die jeweilige Ausprägung der Merkmale eingetragen wird. Ein Fehler der häufig gemacht wird, ist der, dass pro Zelle mehr als eine Ausprägung erfasst wird, was die spätere Auswertung der Daten erheblich erschwert oder sogar unmöglich macht (Wickham 2014). 3.3 Quantitative und qualitative Daten Als erste Eigenschaft unterscheiden wir zwischen qualitativen und quantitativen Variablen, je nachdem, welche Werte die Variable annehmen und wie man mathematisch damit umgehen kann kann. Quantitative Variablen sind Beobachtungsmerkmale, die wir durch Messen oder Zählen ermitteln. Mit quantitativen Daten können wir sinnvolle mathematische Operationen durchführen, wie z.B. einen Durchschnitt bestimmen. Bei quantitativen Daten unterscheiden wir zwei Unterkategorien: quantitativ-kontinuierliche Variablen werden durch Messung erhoben. Sie werden auch als numerische oder stetige Variablen bezeichnet. Im phy- Datensatz sind Groesse, Gewicht und Schuhgroesse kontinuierliche Variablen. quantitativ-diskrete Variablen werden durch Zählen erhoben. Sie können nur ganzzahlige Werte annehmen. Beispiele sind Anzahl roter Blutkörperchen pro ml Blut oder die Anzahl Geschwister. Qualitative Variablen sind Beobachtungsmerkmale, die wir nicht durch messen oder zählen sondern durch direkte Anschauung ermitteln. Qualitative Daten lassen sich nicht sinnvoll addieren oder subtrahieren, d.h. wir können z.B. keinen Durchschnitt wie bei quantitativen Daten berechnen. Qualitative Daten eignen sich jedoch für Vergleiche z.B. für den Vergleich der durchschnittlichen Körpergrösse von Männern und Frauen. Auch bei qualitativen Daten unterscheiden wir zwei Unterkategorien: qualitativ-nominal: Die Variable gibt eine Gruppenzugehörigkeit an. Im phy- Datensatz sind die Variablen ID, Kohorte, Klasse, Augenfarbe und Geschlecht diesem Variablentyp zuzuordnen. qualitativ-ordinal: Bei diesem Typ sind die Kategorien logisch geordnet, wie z. B. der Schweregrad einer Krankheit oder die Antworten stimme nicht zu, stimme teilweise zu, stimme zu in einer Umfrage. Im phy-Datensatz entspricht die Variable Statistik diesem Variablentyp. 3.4 Quantitative Daten zusammenfassen Mit Hilfe von Kennzahlen lassen sich Variablen zusammenfassen. Kennzahlen der zentralen Tendenz (Lagemasse) geben Auskunft über den Schwerpunkt einer Variable und Kennzahlen der Streuung vermitteln uns einen Eindruck darüber, wie die Variablenwerte um diesen Schwerpunkt verteilt sind. In vielen Fällen sind Grafiken (engl. plots) einfacher lesbar als umfangreiche Tabellen. 3.4.1 Kennzahlen der zentralen Tendenz (Lagemasse) Mittelwert Das gebräuchlichste Lagemass ist der Mittelwert (auch Durchschnitt).Der Mittelwert ist derjenige Wert, der die Daten auf einer Waage ausbalanciert. Wir nehmen dabei an, dass die Waage kein Gewicht hat und alle Beobachtungen gleich schwer sind. Weit entfernte Beobachtungen haben eine starke Hebelkraft, also einen starken Einfluss auf den Mittelwert. Der Mittelwert (engl. mean) von \\(n\\) Beobachtungen \\(x_1, x_2, ..., x_n\\) ist \\[\\bar{x} = \\frac{(x_1 + x_2 + ... + x_n)}{n} = \\frac{1}{n} \\sum_{i=1}^n x_i\\] Abbildung 3.1: Mittelwert In der Abbildung 3.1 ist erkennbar, dass wenn die zwei höchsten Werte aus der Abbildung links nach rechts verschoben werden, also höhere Werte annehmen, sich auch der Mittelwert nach rechts verschiebt. Den Mittelwert einer Variable in R berechnen (R Core Team 2021): # Daten generieren x &lt;- c(2, 2, 3, 3, 4) # Mittelwert von x berechnen mean(x) ## [1] 2.8 Median Der Median beschreibt die Mitte, den 50 %-Punkt der Daten. Als Spezialfall eines Perzentils ist der Median definiert als ein Wert, der die Daten in zwei gleiche Hälften teilt. Bestimmung des Medians: Gegeben ist eine Variable \\(x\\) mit den Werten \\(x = (3, 2, 2, 2, 4)\\) Werte der Variablen \\(x\\) nach Grösse sortieren: \\(2, 2, 2, 3, 4\\) Der Wert, der die Zahlenreihe halbiert ist der Median: \\(Median = 2\\) Wenn die Variable eine geradzahlige Anzahl an Werten hat, bestimmen wir das arithmetische Mittel der beiden mittleren Werte: \\(x = (3, 2, 2, 2, 4, 4)\\) Werte nach Grösse sortieren: \\(2, 2, 2, 3, 4, 4\\) Die beiden mittleren Werte sind \\(2\\) und \\(3\\), das arithmetische Mittel ist 2.5, d.h. \\(Median = 2.5\\) Den Median einer Variable in R berechnen: # Daten generieren x &lt;- c(2, 2, 2, 3, 4) # Median von x berechnen median(x) ## [1] 2 # Höchsten Wert von x erhöhen x &lt;- c(2, 2, 2, 3, 20) # Median von x berechnen median(x) ## [1] 2 # Variable x mit geradzahliger Anzahl an Werten x &lt;- c(3, 2, 2, 2, 4, 4) # Median von x berechnen median(x) ## [1] 2.5 Einfluss extremer Werte auf den Median: Abbildung 3.2: Median Die Abbildung 3.2 zeigt, dass eine Verschiebung der beiden höchsten Werte in der Abbildung links keinen Einfluss auf den Median hat. Die Eigenschaft, dass eine Kennzahl oder Methode nicht stark von einzelnen Werten abhängt, bezeichnet man als robust. Merke: Der Mittelwert ist empfindlich für Extremwerte, der Median hingegen ist robust. Mittelwert oder Median Auswahl der Kennzahl der Lage ist abhängigig davon, wie die Daten verteilt sind und welchen Aspekt der Verteilung mit der Kennzahl dokumentiert werden soll. Wir illustrieren das am Beispiel der Verteilung der monatlichen Einkommens von Schweizer Frauen im Jahr 2018 Bundesamt für Statistik. Abbildung 3.3: Monatliches Einkommen Frauen CH, 2018 Das monatliche Einkommen ist rechtsschief verteilt. Es beträgt im Durchschnitt CHF 4600.-, der Median liegt mit CHF 4000.- um CHF 600.- (13%) tiefer. Der Mittelwert ist vergleichsweise hoch, weil einige wenige sehr gut verdienende Personen diesen nach oben ziehen. Für die Einzelperson hat daher der Mittelwert wenig Aussagekraft, informativer ist für diese der Median. Die Steuerbehörde interessiert sich eher für den Mittelwert, der es z.B. erlaubt, das totale Einkommen der Stadt und die zu erwartenden Steuern zu berechnen. Ob zur Charakterisierung einer Variablen der Mittelwert oder Median verwendet werden soll, ist von den Antworten auf die folgenden Fragen abhängig: Soll ein typischer (Median) oder durchschnittlicher (Mittelwert) Wert als Repräsentant der Variablen angegeben werden. Was hat die Verteilung für eine Form? Ist sie schief oder symmetrisch? Welche inferenzstatistischen Auswertungsmethoden werden für die Variable gewählt? Wenn parametrische Verfahren (t-Tests) durchgeführt werden wird eher der Mittelwert angegeben, wenn nicht-parametrische Verfahren (Rangtests) durchgeführt werden wird eher der Median berichtet. Perzentile Perzentile (auch Quantile) sind Hilfsmittel zur Beschreibung der Verteilung von Daten. Die Definition für ein Perzentil ist etwas schwerfällig: Eine Zahl \\(p_k\\) heißt \\(k\\)-tes Perzentil (\\(k\\) bezeichnet hierbei eine ganze Zahl zwischen 1 und 99) einer Variablen, wenn mindestens \\(k\\) % der Beobachtungen der Variable kleiner oder gleich \\(p_k\\) und mindestens (100 - \\(k\\)) %größer oder gleich \\(p_k\\) sind. Einfacher geht es mit einem Beispiel: Uns interessiert, wo die Einkommensgrenze zwischen dem unteren und dem mittleren Drittel liegt. Das bedeutet, wir müssen das 33. Perzentil der Einkommensverteilung bestimmen. # 33. Perzentile berechnen quantile(einkommen$Einkommen, .33) ## 33% ## 3 Interpretation: Wir erhalten für die 33. Perzentile den Wert 3. Die Angaben sind jeweils mit 1000 zu multiplizieren. Die 33% Frauen mit dem niedrigsten monatlichen Einkommen verdienen zwischen 0 und 3000 CHF. Quartile sind spezielle Perzentilen, welche eine Variable in vier gleiche Teile unterteilen. Das 1. Quartil (auch unteres Quartil) ist das 25. Perzentil, das 2. Quartil ist das 50. Perzentil (also der Median) und das 3. Quartil (auch oberes Quartil) ist das 75. Perzentil. # Quartile berechnen quantile(einkommen$Einkommen, c(.25, .5, .75)) ## 25% 50% 75% ## 3 4 6 Intepretation: 25% der Frauen verdienen CHF 3000.- oder weniger 25% der Frauen verdienen zwischen CHF 3000 und 4000. 25% der Frauen verdienen zwischen CHF 4000 und 6000. 25% der Frauen verdienen CHF 6000.- oder mehr. 3.4.2 Exkurs: Der Mittelwert als Kleinst-Quadrat-Modell Im Hinblick auf das Streuungsmass Varianz und später erläuterte statistische Methoden wird hier ergänzend ein etwas anderes Konzept des Mittelwerts vorgestellt. Beispiel: Wie viele Freunde haben Statistik-Lehrer? Aus einer kleinen Umfrage liegen uns die Daten für fünf Statistiklehrer vor: Tabelle 3.2: Anzahl Freunde von Statistiklehrern ID Freunde 1 1 2 2 3 3 4 3 5 4 Abbildung 3.4: Streudiagramm Anzahl Freunde Aus dem Streudiagramm 3.4 schätzen wir den Mittelwert. Als erstes entscheiden wir uns für einen Mittelwert \\(\\bar{x} = 2\\) Abbildung 3.5: Geschätzter Mittelwert = 2 Die horizontale schwarze Linie gibt unseren geschätzen Mittelwert von \\(\\bar{x} = 2\\) an. Die gelben Linien geben den Abstand zum Mittelwert an. Die Länge der Linien gibt die Grösse des Fehler \\(e\\) an, um den unser geschätzter Mittelwert jeden einzelnen Messpunkt unter- oder überschätzt. Die Summe der Fehler \\(e\\) ergibt den gesamten Fehler in unserem Modell. Es hat sich in der Statistik allerdings als Standard etabliert, dass nicht die Summe der einfachen Fehler \\(e\\) , sondern die Summe der quadrierten Fehler \\(e^2\\) berücksichtigt wird. Dies, weil damit einerseits negative Werte für Fehler, welche die Fehlersumme fälschlicherweise zu klein erscheinen lassen, vermieden werden und andererseits grosse Fehler das System bestrafen. (Durch das Quadrieren werden Fehler die kleiner als 1 sind noch kleiner, z.B. \\(0.5^2 = 0.25\\) und Fehler die grösser als 1 sind, erhalten ein grösseres Gewicht, z.B. \\(2^2 = 4\\).) Tabelle 3.3: Fehler e und Fehlerquadrate e_sq bei geschätztem Mittelwert = 2 ID Freunde Est e e_sq 1 1 2 -1 1 2 2 2 0 0 3 3 2 1 1 4 3 2 1 1 5 4 2 2 4 Wir addieren aus der Tabelle 3.3 die Werte der quadrierten Fehler \\(e^2\\) (= e_sq) und erhalten für unser Modell mit \\(\\bar{x} = 2\\) eine Fehlerquadratsumme von 7. Wir können jetzt unseren Fehler mit der Zahl 7 quantifizieren. Vielleicht gibt es aber einen besseren Mittelwert und als nächstes schätzen wir einen Mittelwert \\(\\bar{x} = 3\\). Wiederum berechnen wir die Fehlerquadratsumme. Abbildung 3.6: Geschätzter Mittelwert = 3 Tabelle 3.4: Fehler und Fehlerquadrate bei geschätztem Mittelwert = 3 ID Freunde Est e e_sq 1 1 3 -2 4 2 2 3 -1 1 3 3 3 0 0 4 3 3 0 0 5 4 3 1 1 Bei einem geschätzten Mittelwert \\(\\bar{x}\\) ergibt sich gemäss Tabelle 3.4 eine Fehlerquadratsumme von 6. Jetzt setzen wir den wahren Mittelwert \\(\\bar{x} = 2.6\\) ein und machen das ganze noch einmal. Abbildung 3.7: Fehler bei wahrem Mittelwert = 2.6 Tabelle 3.5: Fehler und Fehlerquadrate beim wahren Mittelwert = 2.6 ID Freunde Est e e_sq 1 1 2.6 -1.6 2.56 2 2 2.6 -0.6 0.36 3 3 2.6 0.4 0.16 4 3 2.6 0.4 0.16 5 4 2.6 1.4 1.96 Der wahre Mittelwert ergibt eine Fehlerquadratsumme von 5.2. Dieser Wert ist kleiner als die Fehlerquadratsumme für die beiden anderen geschätzten Mittelwerte. Wir halten fest: Der Mittelwert einer Variable ist der Wert, der die Fehlerquadratsumme minimiert. Grafisch dargestellt: Abbildung 3.8: Verteilung der Fehlerquadratsummen Der Mittelwert \\(\\bar{x} = 2.6\\) entspricht der Stelle, an der die Summe der quadrierten Fehler minimal ist \\(\\sum{e_i} = 5.2\\). Das Verfahren der Bestimmung der Fehlerquadratsumme ist ein grundlegendes Prinzip in der Statistik, das bei zahlreichen Verfahren zum Einsatz kommt. 3.4.3 Kennzahlen der Streuung (Streuungsmasse) Lagekennzahlen beschreiben einen Aspekt einer Stichprobe oder einer Verteilung. Abbildung 3.9 verdeutlicht, dass Lagekennzahlen nicht ausreichen, um eine Verteilung genügend zu charakterisieren. Beide Stichproben haben einen Mittelwert von 0 (senkrechte Linie), trotzdem würden wir nicht behaupten, dass sie aus der gleichen Verteilung stammen: Die Beobachtungen in der oberen Stichprobe streuen mehr, sie sind im Mittel weiter weg vom Mittelwert. Variabilitätskennzahlen quantifizieren diese Eigenschaft. Abbildung 3.9: Zwei Variablen mit Mittelwert 0 Varianz Die Varianz einer Stichprobe (engl. variance) ist die mittlere quadratische Abweichung der Beobachtungen vom Mittelwert: \\[s^2=\\frac{(x_1-\\bar{x})^2 + (x_2-\\bar{x})^2+...+(x_n-\\bar{x})^2}{n-1} = \\frac{1}{n-1} \\sum_{i=1}^n (x_i-\\bar{x})^2\\] Um die Variabilität der Stichprobe in einer Zahl zusammenzufassen, wäre man auf den ersten Blick versucht, die Abweichungen \\(x_1-\\bar{x}... x_n-\\bar{x}\\) der Beobachtungen vom Mittelwert zu mitteln. Dies würde allerdings bedeuten, dass sich positive und negative Abweichungen gegenseitig aufheben, und die Varianz wäre 0. Dieses Vorgehen ist deshalb ungeeignet. Werden die Abweichungen \\(x_i-\\bar{x}\\) jedoch quadriert, dann gehen sie alle positiv in die Summe ein, d. h., eine gegebene Abweichung vom Mittelwert nach unten trägt gleichviel bei wie die identische Abweichung vom Mittelwert nach oben. Die Verwendung von \\(n-1\\) als Nenner hat einen theoretischen Hintergrund, auf den an dieser Stelle nicht eingegangen wird (die Herleitung ist mathematisch komplex, siehe z.B. Wikipedia. Berechnung der Varianz einer Variablen \\(x\\) in R # Variable x erzeugen x &lt;- c(1, 1, 2, 3, 4, 4, 4, 5) # Varianz von x berechnen var(x) ## [1] 2.285714 Standardabweichung Gemäß ihrer Definition wird die Varianz \\(s^2\\) im Quadrat der Einheit der ursprünglichen Daten angegeben (bei der Körpergröße z. B. \\(cm^2\\) ). Um eine Kennzahl auf derselben Skala wie die Originaldaten zu erhalten, ist es gebräuchlich, die Wurzel aus der Varianz, die Standardabweichung (engl. standard deviation, SD) zu berechnen. \\[s=\\sqrt{s^2}\\] Die Standardabweichung hat die gleiche Einheit wie die Originaldaten, beispielsweise bei der Körpergröße cm. In Abbildung 3.9 betragen die Standardabweichungen 1.18 für die blaue Stichprobe und 0.21 für die rote Stichprobe. Berechnung der Standardabweichung einer Variablen \\(x\\) in R # Variable x erzeugen x &lt;- c(1, 1, 2, 3, 4, 4, 4, 5) # Standardabweichung von x berechnen sd(x) ## [1] 1.511858 # Standardabweichung als Quadratwurzel der Varianz berechnen sqrt(var(x)) ## [1] 1.511858 Spannweite Die Spannweite (engl. range), auch Variationsbreite, ist die Differenz zwischen Maximum und Minimum und gibt den Bereich an, in dem die Daten liegen. \\[Spannweite = Maximum - Minimum\\] Die Spannbreite wird nur durch die Extremwerte einer Stichprobe bestimmt und ist daher sehr empfindlich für Extremwerte (wenig robust). Berechnung der Spannbreite einer Variablen \\(x\\) in R # Variable x erzeugen x &lt;- c(1, 1, 2, 3, 4, 4, 4, 5) # Spannweite von x berechnen max(x) - min(x) ## [1] 4 Interquartilsabstand Der Interquartilsabstand (engl. interquartile range, IQR) ist die Differenz zwischen dem 75. und dem 25. Perzentil. Der IQR umfasst die Spannweite der mittleren 50% der Daten. Der IQR beschreibt die Länge der Box im Boxplot, welche die zentralen 50% der Daten umfasst. Berechnung des IQR einer Variablen \\(x\\) in R # Daten generieren x &lt;- c(19, 19, 20, 21, 21, 21, 22, 23, 23, 27, 27, 29, 29, 31) # IQR für x berechnen IQR(x) ## [1] 6 # Quartile für x berechnen quantile(x, c(.25, .75)) ## 25% 75% ## 21 27 3.4.4 Grafiken für quantitative Daten Grafiken sind elementare Werkzeuge der Datenanalyse. Sie eignen sich auch dafür, Muster in den Daten einem grösseren Publikum vorzustellen. Mit geeigneten grafischen Darstellungen können die Eigenschaften einer Verteilung beurteilt und mehrere Stichproben leicht miteinander verglichen werden. Histogramm Mit einem Histogramm wird die Verteilung von quantitativen Daten visualisiert. Dazu wird der Bereich der Daten in gleiche, anliegende aber sich nicht überlappende Intervalle (Klassen) zerlegt. Dann zählt man die Anzahl der Beobachtungen in jedem Intervall und erstellt ein Balkendiagramm. Abbildung 3.10: Körpergrösse von Studentinnen, n = 183 Die Abbildung 3.10 zeigt vier Histogramme der gleichen Variablen (Körpergrösse von Studentinnen) mit unterschiedlichen Klassenbreiten: (A) Klassenbreite = 1, (B) Klassenbreite = 2, (C) Klassenbreite = 5 und (D) Klassenbreite = 10. Bei der Wahl der Klassenbreite muss man etwas spielen um ein aussagekräftiges Bild zu erhalten. Wählt man die Klassenbreite zu klein, entsteht ein zu detailliertes Bild, das keine gute Übersicht zulässt und Lücken aufweist; wählt man die Klassenbreite zu gross, verliert man zu viel an Detailinformation. Im Gegensatz zum im weiter unten vorgestellten Balkendiagramm für qualitative Daten, bestehen zwischen den Balken eines Histogramms keine Lücken (ausser bei fehlenden Daten), da die x-Achse ein kontinuierliches Datenspektrum darstellt. Am Histogramm beurteilen wir - die Streubreite, d.h. die Variablilität der Daten. - die Spitze (-n), d.h. die höchsten Gruppen von Balken. - die Symmetrie, d.h. ob die Verteilung symmetrisch um ihren Mittelpunkt, links- oder rechtsschief ist. Ein einfaches Histogramm in R erstellen # Körpergrösse von 183 Studentinnen groesse &lt;- c(170, 160, 169, 173, 172, 170, 167, 175, 173, 169, 169, 169, 180, 164, 165, 168, 167, 156, 161, 170, 168, 170, 175, 165, 165, 164, 170, 170, 170, 171, 164, 168, 168, 170, 164, 170, 165, 172, 167, 164, 162, 172, 162, 168, 170, 165, 172, 162, 165, 174, 167, 168, 169, 164, 165, 162, 163, 165, 161, 157, 170, 171, 163, 171, 161, 164, 166, 164, 174, 164, 181, 168, 163, 169, 160, 160, 148, 163, 165, 155, 158, 174, 168, 163, 170, 178, 159, 170, 163, 171, 172, 171, 178, 163, 164, 176, 168, 170, 171, 173, 162, 156, 174, 165, 168, 165, 177, 168, 160, 165, 163, 170, 168, 168, 158, 163, 161, 165, 165, 168, 180, 162, 162, 162, 162, 174, 168, 160, 178, 160, 168, 162, 177, 180, 170, 172, 163, 168, 156, 166, 168, 171, 165, 166, 160, 169, 167, 171, 158, 156, 166, 164, 163, 175, 163, 166, 162, 163, 160, 168, 163, 164, 172, 166, 164, 162, 170, 183, 168, 170, 165, 172, 160, 164, 163, 179, 170, 158, 164, 167, 175, 178, 170) # Die interessierende Variable ist phy_w$Groesse hist(groesse) # mit dem Parameter breaks = kann die Anzahl der Klassen definiert werden hist(groesse, breaks = 35) # Anpassung der Beschriftung hist(groesse, main = &quot;Körpergrösse von Studentinnen (n = 183)&quot;, xlab = &quot;Grösse (cm)&quot;, ylab = &quot;Anzahl&quot;) Boxplot Boxplots sind ein weiteres grafisches Hilfsmittel, um die Verteilung von Daten zu visualisieren, verschiedene Gruppen oder Zeitpunkte zu vergleichen und auffällige Werte zu entdecken. Boxplots gehören zu den vom Autor bevorzugten Grafiken, da sie eine grosse Menge an Informationen enthalten. Die Box im Boxplot (engl. box and whiskers plot) gibt den Bereich vom 25. zum 75. Perzentil an, der horizontale Strich in der Box den Median. Die Stäbe (engl. whiskers), die aus der Box herausragen, sind nicht einheitlich definiert. Bei einfachen Boxplots reichen sie zum Minimum und zum Maximum. Eine verbreitete Definition, die auf John W. Tukey zurückgeht, besteht darin, die Länge der Whiskers auf maximal das 1,5-fache der Boxlänge zu beschränken. Beobachtungen außerhalb dieses Bereichs werden als Ausreisser gekennzeichnet. Boxplot für die Grösse von 50 Frauen Die Abbildung illustriert die Definitionen des Boxplots an der Grösse von 50 Frauen. Am Boxplot beurteilen wir - die Spannweite - die Lage der zentralen 50% der Daten (IQR) - die Lage des Medians - die Verteilung der Daten. Liegt der Median etwa in der Mitte zwischen dem 25. und dem 75. Perzentil, können wir von einer symmetrischen Verteilung der Daten ausgehen. Liegt der Median näher am 25. Perzentil, spricht dies eher für eine rechtsschiefe Verteilung, liegt er näher am 75. Perzentil, spricht dies eher für eine linksschiefe Verteilung. Boxplots eignen sich sehr gut für den Vergleich von Gruppen. Abbildung 3.11: Körpergrösse von Studierenden Die Abbildung 3.11 zeigt die Verteilung der Körpergrösse von Studentinnen und Studenten. Auf den ersten Blick ist erkennbar, dass die Studentinnen im Durchschnitt kleiner sind als die Studenten. Die Grösse bei den Frauen liegt etwa zwischen 148 cm (Minimum) und 178 cm (Maximum), bei den Männern etwa zwischen 169 cm und 198 cm. Der Median bei Frauen liegt bei 167.5 cm und bei Männern bei 180 cm. 50% der Frauen sind zwischen 163 cm und 170 cm gross (IQR), 50% der Männer sind zwischen 175 cm und 189 cm gross. Der Median liegt nicht exakt in der Mitte der Box und ist bei beiden Geschlechtern leicht zum 75. Perzentil verschoben, was ein Hinweis auf eine leicht linksschiefe Verteilung sein könnte. Einen einfachen Boxplot in R erstellen Wir verwenden den Datensatz PlantGrowth, der bereits mit R mitgeliefert wird. Er umfasst die Ergebnisse eines Experiments, das den Einfluss von zwei verschiedenen Düngern auf die Ernte einer Pflanze untersucht. Der Datensatz besteht aus zwei Variablen: weight: Trockengewicht der Pflanzen group: 3 Gruppen: ctrl = Kontrollgruppe, trt1 = Dünger 1, trt2 = Dünger 2 Jede Gruppe umfasst n = 10 Messungen. # Datensatz laden data(&quot;PlantGrowth&quot;) # Boxplot für die Verteilung des Gewichts erstellen boxplot(PlantGrowth$weight) # Boxplot für die Verteilung des Gewichts nach Gruppe erstellen boxplot(weight ~ group, data = PlantGrowth) # Boxplot beschriften boxplot(weight ~ group, data = PlantGrowth, main = &quot;Trockengewicht, n = 10 pro Gruppe&quot;, xlab = &quot;Gruppe&quot;, ylab = &quot;Gewicht (g)&quot;) # Extra: Boxplots einfärben boxplot(weight ~ group, data = PlantGrowth, main = &quot;Trockengewicht, n = 10 pro Gruppe&quot;, xlab = &quot;Gruppe&quot;, ylab = &quot;Gewicht (g)&quot;, col = c(&quot;yellow&quot;, &quot;orange&quot;, &quot;pink&quot;)) 3.5 Qualitative Daten zusammenfassen Bei diskreten Daten interessiert man sich für die Häufigkeiten der vorkommenden Kategorien. Diese Häufigkeiten werden in der Regel absolut (Anzahl) und relativ (in Prozentzahlen) angegeben. 3.5.1 Kreuztabellen Qualitative Daten können in einer Kreuztabelle (engl. contingency table) zusammenfassend dargestellt werden. Tabelle 3.6: Augenfarben von 228 Studierenden Augenfarbe n Prozent blau 99 43.4 braun 78 34.2 gruen 51 22.4 Total 228 100.0 In Tabelle 3.6 sind die Augenfarben von 228 Studierenden in einer Kreuztabelle zusammengefasst. Die Spalte n gibt die absoluten Häufigkeiten an, die Spalter Prozent die relativen Häufigkeiten in Prozent. Tabelle 3.7: Augenfarben nach Geschlecht Augenfarbe m w Summe blau 19 80 99 braun 12 66 78 gruen 14 37 51 Total 45 183 228 Bei der Berechnung von Prozentzahlen (relativen Häufigkeiten) gilt es immer genau zu überlegen, welche Anzahl als 100% festgelegt werden soll: Wir können Prozentzahlen bezüglich der Spalten- oder Zeilentotale der Tabelle sowie der totalen Anzahl Beobachtungen in der Tabelle berechnen. Welche Zahlen berechnet werden sollen, hängt von der Fragestellung ab. 3.5.2 Balkendiagramme Eine geeignete grafische Darstellung von Tabelle 3.6 ist ein Balkendiagramm.Da die x-Achse getrennte Kategorien bezeichnet, liegen die Balken nicht aneinander, sondern werden mit einem kleinen Abstand dazwischen gezeichnet. Abbildung 3.12: Augenfarben von Studierenden, n = 228 Die Höhe der Balken entspricht der Anzahl Beobachtungseinheiten in einer Kategorie. Für jede Kategorie wird ein separater Balken erstellt. Balkendiagramme in R erstellen barplot(table(phy$Augenfarbe)) Eine Alternative zu Balkendiagrammen sind Tortendiagramme. Allerdings sind Tortendiagramme visuell schwierig zu beurteilen, da das menschliche Auge Längenunterschiede besser beurteilen kann als Flächenunterschiede. Von Tortendiagrammen wird daher abgeraten. Abbildung 3.13: Kuchendiagramme vs. Balkendiagramme In den Tortendiagrammen sind die Grössenunterschiede der fünf Kategorien kaum zu differenzieren, ganz im Gegensatz zu den Balkendiagrammen. Hier noch ein witziges Tortendiagramm Abbildung 3.14: Pyramide - R Code in der Helpdatei zu pie() 3.6 Grundregeln für die Erstellung von Grafiken Effektive Datenvisualisierungen sind die Voraussetzung jeder Datenanalyse, da sie allgemeine Muster in den Daten zeigen, was bei der reinen Betrachtung von Rohdaten nicht der Fall ist. Datenvisualisierungen werden von unserem Gehirn besser verarbeitet als einzelne Zahlen oder Zahlentabellen. Deshalb sind für die Präsentation von Daten Grafiken, wenn immer möglich, Zahlentabellen vorzuziehen. Mittels moderner Software kann eine Vielzahl von Grafiken erstellt werden, allerdings ist nicht jede Grafik auch eine gute Grafik. Die zahllosen Gestaltungsmöglichkeiten können schnell zur Erstellung von fancy Grafiken verleiten die zwar effektvoll aussehen, jedoch wenig bis keine Information über die Daten selbst vermitteln. Deshalb hier ein paar Grundregeln für die Erstellung von Grafiken für statistische Zwecke: Die Daten stehen im Mittelpunkt. Eine gute Grafik visualisiert die Daten und hilft dem Auge, Muster zu erkennen. Sie erleichtert die Beurteilung der Verteilung der Daten und den Vergleich von Messungen in verschiedenen Gruppen. Es sollen alle relevanten Informationen mit möglichst wenigen grafischen Elementen dargestellt werden. Keep it simple! Vermeide Ablenkung wie 3D-Effekte, Schatten, unnötige Farben, unruhige Hintergründe. Es soll klar ersichtlich sein, was dargestellt ist: Eine gute Grafik enthält eine Überschrift Achsenbeschriftungen, gegebenenfalls mit der Angabe von Einheiten Angaben zu Stichprobenumfang, Erhebungszeitpunkt, Gruppen Die Daten werden möglichst unverzerrt dargestellt. Abbildung 3.15: Serotoninspiegel von Heuschrecken in engem Habitat, n = 10 In der linken Grafik in Abbildung 3.15 ist die Streuung der Daten zu den drei Messzeitpunkten leicht zu erkennen. Jeder blaue Punkt stellt eine Messung dar und wir erkennen, dass die Mehrheit der Punkte unter dem Mittelwert liegen. Der Boxplot zeigt die Verteilung der Daten und den Median, der rote Punkt gibt den Mittelwert an. Wir erkennen dass mit zunehmender Behandlungsdauer der durchschnittliche Serotoninspiegel ansteigt. Die rechte Grafik zeigt nur die Mittelwerte zu den drei Messzeitpunkten. Der Informationsgehalt dieser Grafik ist minimal. Häufige Fehler bei der Erstellung von Grafiken für statistische Zwecke Mangelhafte Beschriftung (Achsenbeschriftungen fehlen oder sind ungenau, Stichprobenumfänge nicht angegeben, Titel fehlt) Skalenfehler wie z.B. unterschiedliche Skalen bei vergleichenden Grafiken, y-Achse beginnt nicht bei 0 bei Histogrammen oder Balkendiagrammen. Abbildung 3.16: Schlusskurse der Apple-Aktie 1.1. bis 24.11.2021 Beide Grafiken in Abbildung 3.16 visualiseren die Schlusskurse der Appleaktie (AAPL) im Jahr 2021. In der linken Abbildung ist die y-Achse ist auf den Datenbereich zwischen 115 und 165 beschränkt. Die wirken die Kursausschläge wirken extrem und suggerieren eine Verdoppelung des Aktienwerts zwischen der ersten und der zweiten Jahreshälfte. In der Abbildung rechts, beginnt die y-Achse bei 0 und die Ausschläge wirken eher moderat. Wenn es darum geht, Unterschiede darzustellen, macht die rechte Grafik Sinn, wenn es wichtig ist Grössenverhältnisse darzustellen ist die rechte Grafik eher geeignet. Geeignete Darstellungen von Daten für eine nominale Variable: Kreuztabelle, Balkendiagramm für eine quantitative Variable: Histogramm, Boxplot, Liniendiagramm Zusammenhang zwischen zwei nominalen Variablen: Kreuztabelle, gruppiertes Balkendiagramm Zusammenhang zwischen quantitativen Variablen: Streudiagramm Zusammenhang zwischen einer quantitativen Variablen und einer nominalen Variablen: Gruppierte Boxplots oder mehrere Histogramme (Achte auf gleiche Skalierung der Achsen). Abbildung 3.17: Länge der Kelchblätter von drei Iris-Spezies, n = 50/Spezies Im Iris-Datensatz (Bestandteil von R) ist Species eine nominale Variable und die Länge der Kelchblätter Sepal.Length eine kontinuierliche Variable. Die Abbildung 3.17 zeigt zwei Möglichkeiten des Zusammenhangs: Links als gruppierter Boxplot und rechts als Histogramm. References "],["wahrscheinlichkeitsverteilungen.html", "4 Wahrscheinlichkeitsverteilungen 4.1 Lernziele 4.2 Zufallsvariablen 4.3 Wahrscheinlichkeitsverteilungen 4.4 Die Normalverteilung 4.5 Die \\(t\\)-Verteilung", " 4 Wahrscheinlichkeitsverteilungen 4.1 Lernziele Definiere Zufallsvariable als Beobachtungsmerkmal, dessen Ausprägung variiert und daher nicht exakt vorhergesagt werden kann. Interpretiere die Wahrscheinlichkeitsverteilung einer Variable als Modell, das sich auf eine Grundpopulation bezieht. Beachte, dass die Wahrscheinlichkeit \\(P\\) für ein Ereignis stets zwischen 0% und 100% liegt. \\(P\\) kann daher nur Werte zwischen 0 und 1 annehmen. Interpretiere die Normalverteilung als eine kontinuierliche Verteilung. In kontinuierlichen Verteilungen ist die Wahrscheinlichkeit für ein ganz bestimmtes Ereignis stets Null. Es ist aber möglich Wahrscheinlichkeiten für Wertebereiche (Intervalle) zu berechnen. Die Normalverteilung ist symmetrisch um den Mittelwert und kann durch die Parameter Mittelwert \\(\\mu\\) und Standardabweichung \\(\\sigma\\) vollständig beschrieben werden. Mittelwert und Median sind in diesem Fall annähernd identisch. Interpretiere die Standardnormalverteilung als eine Normalverteilung mit dem Mittelwert \\(\\mu = 0\\) und der Standardabweichung \\(\\sigma = 1\\). Jede Normalverteilung kann durch \\(z\\)-Transformation in die Standardnormalverteilung umgewandelt werden. \\[z_n=\\frac{x_n - \\bar{x}}{s}\\] Interpretiere den \\(z\\)-Wert als Abstand eines Datenpunktes vom Mittelwert in Anzahl Standardabweichungen. Punkte mit negativen z-Werten liegen links vom Mittelwert und Punkte mit positiven z-Werten liegen rechts vom Mittelwert. Verwende den \\(z\\)-Wert,  um die Perzentile eines Datenpunktes zu bestimmen (z.B. bei der Berechnung von Vertrauensintervallen).  um zu bestimmen, ob ein Datenpunkt als ungewöhnlich beurteilt werden muss (Faustregel: \\(z\\) &gt; 2 ist ungewöhnlich). Beurteile die Form einer Verteilung nach dem \\(z\\)-Wert des Medians (für den Mittelwert gilt immer \\(z\\) = 0) Bei linkssteilen Verteilungen hat der Median einen negativen \\(z\\)-Wert. Bei rechtssteilen Verteilungen hat der Median einen postiven \\(z\\)-Wert. Die 68-95-99.7%-Regel ist eine Faustregel die besagt, dass unter der Normalverteilungskurve 68% der Fläche innerhalb von \\(\\bar{x} \\pm 1s\\), 95% der Fläche innerhalb von \\(\\bar{x} \\pm 2s\\) und 99.7% der Fläche innerhalb von \\(\\bar{x} \\pm 3s\\) liegen. Beurteile anhand eines Histogramms, eines Boxplots oder eines QQ-Plots, ob die beobachteten Daten aus einer normalverteilten Population stammen oder nicht. Interpretiere die \\(t\\)-Verteilung als Anpassung der Normalverteilung, wenn die Standardabweichung \\(\\sigma\\) einer Population unbekannt ist (was fast immer der Fall ist). Die Form der \\(t\\)-Verteilung ist nur abhängig vom Stichprobenumfang. Dieser wird in Freiheitsgraden df angegeben, wobei \\(df = n-1\\). Ist der Stichprobenumfang \\(n\\) &gt; 30, nähert sich die Form der \\(t\\)-Verteilung der Normalverteilung an. Die \\(t\\)-Verteilung wird mit dem Parameter \\(df\\) vollständig beschrieben. Interpretiere \\(t\\)-Werte, die von Statistikprogrammen angegeben werden, gleich wie z-Werte. 4.2 Zufallsvariablen Unter einer Zufallsvariable verstehen wir ein Beobachtungsmerkmal, dessen Ausprägung in gewissem Umfang vom Zufall abhängig ist, d.h. dessen Ausprägung variiert und daher nicht exakt vorhergesagt werden kann. 4.3 Wahrscheinlichkeitsverteilungen Eine Wahrscheinlichkeitsverteilung ist eine mathematische Funktion (ein Modell), welche die Wahrscheinlichkeiten für alle möglichen Werte einer Zufallsvariable beschreibt. Das tönt recht technisch, ist aber anhand von einem Beispiel leicht zu verstehen: Stell dir vor, du möchtest wissen, wie gross deine Kolleginnen in der Klasse sind. Dazu misst du von jeder Person die Körpergrösse und stellst fest, dass gewisse Körpergrössen häufig und andere eher selten sind. Wahrscheinlichkeitsverteilungen helfen dir, wenn es darum geht zu verstehen, welche Merkmalsausprägungen eher häufig und welche eher selten zu erwarten sind. Sie erlauben auch die Beantwortung von Fragen wie: Wie gross ist die Wahrscheinlichkeit, dass die nächste Person, die ich messe, grösser als zwei Meter ist? In der deskriptiven Statistik haben wir bereits Verteilungen von Zufallsvariablen kennen gelernt: Sie lassen sich durch Form (symmetrisch, links- oder rechtssteil, irregulär), Kennzahlen der zentralen Tendenz und Kennzahlen der Streuung beschreiben. Beachte, dass Histogramme, Boxplots, Punktediagramme die Verteilung von Stichprobendaten beschreiben, während Wahrscheinlichkeitsverteilungen Modelle für die Verteilung von Daten in Populationen sind. In der statistischen Schreibweise wird die Wahrscheinlichkeit für ein Ereignis \\(X\\) geschrieben als \\[p(X) = Zahl~zwischen~0~und~1\\] Die Summe für alle möglichen Ausprägungen von \\(X\\) ist stets 1. Ausserdem ist die Wahrscheinlichkeit für eine bestimmte Merkmalsausprägung \\(X\\) ein Wert zwischen 0 (0%) und 1 (100%). Wenn wir also eine Münze werfen, dann ist die Wahrscheinlichkeit \\[p(Kopf) = 0.5\\] \\[p(Zahl) = 0.5\\] Eine andere Möglichkeit für das Ereignis \\(X\\) existiert nicht. Die Summe aller möglichen Ereignisse \\(X\\) für den Münzwurf ist daher \\[p(Kopf) + p(Zahl) = 1\\] Wahrscheinlichkeitsverteilungen beschreiben also die Verteilung der Werte (Merkmalsausprägungen) einer bestimmten Zufallsvariable (Beobachtungsmerkmal). Daher ist es naheliegend, dass die Art der Variable einen Einfluss auf den Verteilungstyp hat. In der Statistik unterscheidet man zwischen Verteilungen für diskrete Variablen (z.B. Binomialverteilung) und Verteilungen für kontinuierliche Variablen (z.B. Normalverteilung) Wir beschränken uns im Folgenden auf die Normalverteilung, die für zahlreiche statistische Verfahren von zentraler Bedeutung ist. 4.4 Die Normalverteilung Wenn eine Variable innerhalb eines Bereichs unendlich viele Werte annehmen kann, kann diese mittels einer kontinuierlichen Verteilung modelliert werden. Mathematisch ausgedrückt ist die Wahrscheinlichkeit, dass eine kontinuierliche Variable einen ganz bestimmten Wert annimmt gleich null. Z.B. die Wahrscheinlichkeit, dass eine Temperaturmessung exakt 37° C ergibt ist gleich null. Warum? In einem unendlichen Wertespektrum kann die aktuelle Temperatur unendlich viele kleinere oder grössere Werte annehmen, z.B. 36.99999999 oder 36.999999998 oder 37.000000001 etc. (es sind unendlich viele Nachkommastellen möglich). 4.4.1 Wahrscheinlichkeiten für kontinuierliche Daten? Da es unmöglich ist, die Wahrscheinlichkeit für einen bestimmten Wert in einem kontinuierlichen Datenspektrum anzugeben, werden Wahrscheinlichkeiten für kontinuierliche Daten für Wertebereiche (Werteintervalle) berechnet und nicht für einzelne Werte. Was berechnet werden kann, ist die Wahrscheinlichkeit, dass ein gesuchter Wert in einem bestimmten Intervall liegt. In einem Wahrscheinlichkeitsdiagramm ist die Fläche unter der Kurve gleich 1. Dies entspricht der Summe der Wahrscheinlichkeiten für alle möglichen Ausprägungen einer Variablen \\(X\\). Abbildung 4.1: Die Fläche unter der Kurve ist gleich 1 In der Statistik nimmt die Normalverteilung (auch Gauss-Verteilung, Glockenkurve) eine zentrale Stellung ein. Diese symmetrische Wahrscheinlichkeitsverteilung erlaubt es, eine Vielzahl von kontinuierlichen Variablen wie z.B. Körpergrösse oder IQ-Scores zu modellieren. Eine Normalverteilung wird durch die Parameter Mittelwert \\(\\bar{x}\\) und Standardabweichung \\(\\sigma\\) vollständig beschrieben: Während eine Änderung des Mittelwerts die Glockenkurve nach links oder nach rechts verschiebt, führt eine Änderung der Standardabweichung dazu, dass die Kurve breiter oder schmaler wird. Die Normalverteilung von Daten ist eine wichtige Voraussetzung für zahlreiche statistische Verfahren. Üblicherweise kennt man die wahre Verteilung einer Variablen in einer Population jedoch nicht und man muss aus den Stichprobendaten ermitteln, ob Evidenz dafür vorliegt, dass die Daten aus einer normalverteilten Population stammen. Wie man dabei vorgeht, wird weiter unten beschrieben. 4.4.2 Anwendung der Normalverteilung Beispiel: Der Intelligenzquotient (IQ-Score) ist normalverteilt. Er hat einen Mittelwert \\(\\mu\\) = 100 und eine Standardabweichung \\(\\sigma\\) = 15. Die Abbildung zeigt die Wahrscheinlichkeitsverteilung für den IQ-Score. Uns interessiert z.B. die Frage, wie gross ist die Wahrscheinlichkeit, dass bei einem Test der IQ-Score zwischen 120 und 140 (also in ein bestimmtes Werteintervall) fällt. Abbildung 4.2: Wahrscheinlichkeit für IQ-Score zwischen 120 und 140 Die Abbildung 4.2 zeigt, dass die Verteilung des IQ-Score symmetrisch ist. Die Höhe der Kurve in einem bestimmten Abschnitt gibt die Wahrscheinlichkeit an. Die Kurve hat ihr Maximum Werte um 100, also beim Mittelwert. Je weiter wir uns nach links oder rechts vom Mittelwert entfernen, desto geringer wird die Wahrscheinlichkeit für den IQ-Score. Die blaue Fläche zwischen den IQ-Scores 120 und 140 macht 8.7% der Gesamtfläche unter der Kurve aus. Damit ist die Wahrscheinlichkeit, dass der IQ-Score zwischen 120 und 140 fällt \\(p\\) = 0.087 bzw. 8.7%. Wir sehen also, dass ein IQ-Score zwischen 120 und 140 ein nicht sehr häufiges Ereignis ist. 4.4.3 Normalverteilung Vertiefung Wie bereits erwähnt ist die Normalverteilung ist eine wichtige Wahrscheinlichkeitsverteilung in der Statistik, weil sie die Modellierung zahlreicher natürlicher Phänomene erlaubt. So sind z.B. Körpergrösse, Blutdruck, Messfehler von Instrumenten und Hämoglobin-Gehalt im Blut normal verteilt. Als Wahrscheinlichkeitsfunktion beschreibt sie, wie die Werte (Merkmalsausprägungen) einer Variablen (Beobachtungsmerkmal) verteilt sind. Die Kurve hat die Form einer Glocke (Gausssche Glockenkurve) und ist symmetrisch bezüglich des Mittelwerts, d.h. die häufigsten Merkmalsausprägugen liegen in der Nähe des Mittelwerts. Mit zunehmendem Abstand vom Mittelwert nach links oder rechts nimmt die Wahrscheinlichkeit für Werte ab und die Verteilungskurve nähert sich dem Wert 0 (den sie aber nie erreicht!). Beispiel: Körpergrösse ist eine normalverteilte Variable ist. Die Abbildung zeigt die Verteilung der Körpergrösse von 14-jährigen Frauen aus einer Stichprobe von n = 800. Abbildung 4.3: Körpergrösse 14-jähriger Mädchen in m (n = 800) Das Histogramm in Abb. 4.3 zeigt die Verteilung der Daten in der Stichprobe und wir erkennen, dass die meisten Werte um den Mittelwert \\(\\bar{x}\\) = 1.52m liegen. Werte über 1.65m oder unter 1.4m sind vergleichsweise selten anzutreffen. Die rote Kurve ist die Normalverteilungskurve mit dem Mittelwert \\(\\bar{x}\\) = 1.52 und der Standardabweichung \\(s\\) = 0.07. Obwohl die Kurve das Histogramm nicht exakt abbildet, scheint sie ein akzeptables Modell für die Häufigkeitsverteilung zu liefern und wir dürfen annehmen, dass unsere Stichprobe aus einer normalverteilten Population stammt. 4.4.4 Parameter der Normalverteilung Eine Normalverteilung wird mit den Parametern Mittelwert \\(\\mu\\) und Standardabweichung \\(\\sigma\\) vollständig beschrieben. Die Form einer Normalverteilung variiert jedoch in Abhängigkeit von diesen Parametern. Der Mittelwert ist die Kennzahl der zentralen Lage. Er gibt den Wert an, an dem die Glockenkurve ihr Maximum hat. Die meisten Werte gruppieren sich um den Mittelwert herum. Eine Veränderung des Mittelwerts verschiebt die Kurve nach links oder nach rechts auf der x-Achse einer Grafik. Abbildung 4.4: Der Mittelwert beeinflusst die Lage der Verteilung auf der x-Achse Die Standardabweichung ist eine Kennzahl der Streuung. Unterschiedliche Standardabweichungen beeinflussen Breite der Glockenkurve. Abbildung 4.5: Die Standardabweichung beeinflusst die Breite der Glockenkurve 4.4.5 Kennzahlen der Population vs. Kennzahlen von Stichproben Wie oben ausgeführt, beschreibt das Normalverteilungsmodell die Verteilung der Daten in der Population. Um Stichprobenkennzahlen und Populationparameter leicht zu unterschieden, ist es gebräuchlich, Populationskennzahlen mit griechischen Buchstaben und Stichprobenkennzahlen mit römischen Buchstaben anzugeben. Daher wird ein Populationsmittelwert mit dem griechischen Symbol \\(\\mu\\) und eine Populationsstandardabweichung stets mit dem griechischen Symbol \\(\\sigma\\) angegeben. Üblicherweise sind \\(\\mu\\) und \\(\\sigma\\) einer Population jedoch unbekannt, da es in der Regel unmöglich ist, eine gesamte Population zu messen. Wir können jedoch Zufallsstichproben ziehen um diese Parameter zu schätzen. Die Stichprobenkennzahlen, die als Punktschätzer (engl. point estimate) für die Populationsparameter dienen, werden mit den Symbolen \\(\\bar{x}\\) für den Stichprobenmittelwert und \\(s\\) für die Stichprobenstandardabweichung angegeben. (Aus technischen Gründen wird in Grafiken für den Stichprobenmittelwert oft der Buchstabe \\(M\\) verwendet) 4.4.6 Eigenschaften von Normalverteilungen Trotz ihrer unterschiedlichen Formen haben alle Normalverteilungen folgende gemeinsamen Eigenschaften: Alle Normalverteilungen sind symmetrisch. Median und Mittelwert sind identisch. Eine Hälfte der Werte liegt unter und eine Hälfte über dem Mittelwert. Die 68-95-99.7 Regel erlaubt es, den Anteil der Werte innerhalb einer bestimmten Distanz vom Mittelwert zu bestimmen. 4.4.7 Die 68  95  99.7  Regel Die 68-95-99.7 Regel ist eine empirische Regel der angewandten Statistik, die einen anschaulichen Zusammenhang zwischen Mittelwert und Standardabweichung eines normalverteilten Zufallsereignisses ermöglicht. Sie gibt an, wie viel Prozent der Daten innerhalb einer, zwei bzw. drei Standardabweichungen \\(\\sigma\\) vom Mittelwert \\(\\mu\\) entfernt sind. Als Faustregel gilt: Mittelwert +/- 1 Standardabweichung: 68% der Daten Mittelwert +/- 2 Standardabweichungen: 95% der Daten Mittelwert +/- 3 Standardabweichungen: 99.7% der Daten Abbildung 4.6: 68-95-99.7-Regel Beispiel: Dein Lieblingspizzakurier wirbt damit, dass er innerhalb von durchschnittlich \\(\\bar{x}\\) = 30 Minuten, mit einer Standardabweichung von \\(s\\) = 5 Minuten die bestellte Pizza liefern kann. Unter Anwendung der 68-95-99.7-Regel bedeutet dies, dass die Auslieferung in 68% der Bestellungen innerhalb von 25 bis 35 Minuten, in 95% der Bestellungen innerhalb von 20 bis 40 Minuten und in 99.7% der Bestellungen innerhalb von 15 bis 45 Minuten erfolgt. 4.4.8 Die Standardnormalverteilung Wenn wir beliebige, normalverteilte Merkmale messen, werden wir immer wieder neue Normalverteilungen mit jeweils ihrem eigenen Mittelwert und ihrer eigenen Standardabweichung erhalten. D.h. die Normalverteilungskurve wird manchmal breiter, manchmal schmaler, manchmal höher, manchmal tiefer sein. Jedes Merkmal weist seine charakteristische Verteilung auf. In der Statistik interessieren wir uns oft für die Wahrscheinlichkeit, dass ein bestimmtes Ereignis eintritt (z.B. das Ereignis, dass eine Studentin 168 cm gross ist). Bei Daten aus normalverteilten Populationen erfolgt die Berechnung von Wahrscheinlichkeiten über die Berechnung von Flächeninhalten unter der Normalverteilungskurve. Allerdings ist diese Berechnung von Flächen unter Kurven eine nicht ganz triviale Angelegenheit (Schule Analysis!). Um diese Berechnungen zu erleichtern, wurde die Standardnormalverteilung erfunden. Diese ist eine Normalverteilung mit dem Mittelwert \\(\\mu\\) = 0 und der Standardabweichung \\(\\sigma\\) = 1. Jede beliebige Normalverteilung kann durch Transformation in eine Standardnormalverteilung umgewandelt werden, was Flächenberechnungen erheblich erleichtert. Eine bestimmte Merkmalsausprägung in der Standardnormalverteilung wird als \\(z\\)-Wert bezeichnet. Der \\(z\\)-Wert gibt an, um wieviel Standardabweichungen diese Merkmalsausprägung vom Mittelwert entfernt ist. Ist der \\(z\\)-Wert negativ, liegt der Wert links vom Mittelwert, d.h. er ist kleiner als der Mittelwert. Ist der \\(z\\)-Wert positiv, liegt der Wert rechts vom Mittelwert und ist somit grösser. Der Mittelwert selber hat stets den \\(z\\)-Wert 0. 4.4.9 Berechnung von \\(z\\)-Werten (\\(z\\)-Transformation) Um Stichprobendaten zu standardisieren, müssen die Rohdaten in \\(z\\)-Werte umgerechnet werden. Die Umwandlung einer beliebigen Normalverteilung in die Standardnormalverteilung erfolgt nach der Formel: \\[z_n=\\frac{x_n - \\bar{x}}{s}\\] Beispiel: Du hast zwei Äpfel, der eine wiegt 85g, der andere wiegt 110 g. Das durchschnittliche Gewicht von Äpfeln beträgt \\(\\bar{x}\\) = 100g mit einer Standardabweichung \\(s\\) = 10 g. z-Wert für den 85g-Apfel: \\(z_{85}=\\frac{85-100}{10} = -1.5\\) z-Wert für den 110g-Apfel: \\(z_{110}=\\frac{110-100}{10} = 1\\) Abbildung 4.7: Gewicht von Äpfeln (g), roh und standardisiert Abbildung 4.8: \\(z\\)-Werte der beiden Äpfel Der \\(z\\)-Wert für den 85g Apfel ist negativ da er leichter ist als ein durchschnittlicher Apfel. Um wie viel leichter? Um -1.5 Standardabweichungen = 15g. Der \\(z\\)-Wert für den 110g-Apfel ist positiv, d.h. er ist schwerer als ein durchschnittlicher Apfel. Um wie viel schwerer? Um 1 Standardabweichung = 10g. 4.4.10 Interpretation von z-Werten Uns interessiert die Frage: Wie wahrscheinlich ist es, dass ein Apfel 85g schwer oder leichter ist? Abbildung 4.9: Wahrscheinlichkeit für \\(z\\) gleich -1.5 oder kleiner Die blaue Fläche unter der Kurve in Abbildung 4.9 entspricht der Wahrscheinlichkeit für \\(z \\leq -1.5\\). Normalerweise verwenden wir den Computer, um Wahrscheinlichkeiten unter der Normalverteilungskurve zu berechnen. Vor dem Computerzeitalter erlaubte die z-Werte-Tabelle für beliebige Normalverteilungen beliebige Flächeninhalte und somit Wahrscheinlichkeiten zu berechnen. z-Werte-Tabelle Mit der Funktion pnorm() (R Core Team 2021) können wir in R/jamovi (The Jamovi Project 2021) diese Arbeit machen lassen: pnorm(-1.5) ## [1] 0.0668072 R/jamovi gibt eine Wahrscheinlichkeit von \\(p\\) = 0.067 für \\(z \\leq -1.5\\) an. Das bedeutet, dass wir erwarten können, dass die Wahrscheinlichkeit einen Apfel von 85g oder einen leichteren Apfel zu erhalten bei 6.7% liegt. Umgekehrt heisst es auch, dass die Wahrscheinlichkeit, einen Apfel zu erhalten, der schwerer als 85g ist, ist gleich \\(p = 1-0.067 = 0.933\\) bzw 93.3%. Auch folgende Frage können wir stellen: Wie wahrscheinlich ist es, dass Ein Apfel 110g oder mehr wiegt? Abbildung 4.10: Wahrscheinlichkeit für \\(z\\) = 1 oder grösser Die blaue Fläche in Abbildung 4.10 entspricht der Wahrscheinlichkeit für \\(z\\geq1\\). Wiederum hilft uns die z-Werte-Tabelle oder die Funktion pnorm() in R/jamovi: ## [1] 0.8413447 Aber dieses Ergebnis kann nicht richtig sein! Die Wahrscheinlichkeit \\(p\\) muss kleiner als 50% sein, da ja nicht die ganze Fläche rechts vom Mittelwert blau eingefärbt ist. Der Fehler kommt daher, dass die Funktion pnorm() stets die Fläche unterhalb des angegebenen \\(z\\)-Werts, also die Fläche links vom \\(z\\)-Wert, berechnet. Daher müssen wir in diesem Fall eine kleine Anpassung vornehmen und wir ziehen den \\(p\\)-Wert einfach von 1 ab: ## [1] 0.1586553 Unsere Berechnungen haben ergeben, dass die Wahrscheinlichkeit \\(p\\), einen Apfel von 110g oder schwerer zu erhalten bei 15.8% liegt. Zum Schluss noch folgende Übung: Wie gross ist die Wahrscheinlichkeit dafür, dass das Gewicht eines Apfels zwischen 85g und 110g liegt (c)? Auch diese Berechnung ist kein Problem: Zuerst berechnen wir, wie gross die Wahrscheinlichkeit ist, dass ein Apfel 110g schwer ist (a) und ziehen von diesem Wert die Wahrscheinlichkeit ab, dass ein Apfel 85g oder leichter ist (b). Die Berechnung in R/jamovi folgt genau diesem Prinzip: a &lt;- pnorm(1) # Wahrscheinlichkeit für z &lt;= 1 b &lt;- pnorm(-1.5) # Wahrscheinlichkeit für z &lt;= -1.5 a - b # Wahrscheinlichkeit für -1.5 &lt;= z &lt;= 1 ## [1] 0.7745375 Die Wahrscheinlichkeit, dass ein Apfel zwischen 85g und 110g wiegt beträgt 77.5% (\\(p = 0.775\\)). 4.4.11 Prüfung auf Normalverteilung Üblicherweise ist die die Verteilung der Daten in der Populationsdaten unbekannt Daher müssen wir anhand von Stichprobendaten abschätzen, ob eine Normalverteilung zu Grunde liegt. Dazu existieren mehrere Verfahren: Visuelle Verfahren zur Prüfung auf Normalverteilung Histogramm Boxplot QQ-Plot Mathematische Verfahren Vergleich von Mittelwert und Median QQ-Plot Der QQ-Plot (Quantile-Quantile-Plot) ist ein wichtiges visuelles Hilfsmittel um zwei Wahrscheinlichkeitsverteilungen miteinander zu vergleichen. Wenn diese beiden Verteilungen identisch sind, liegen im QQ-Plot alle Punkte auf einer Linie. Im QQ-Plot für Normalverteilung werden auf der x-Achse die Quantile einer Normalverteilung (theoretisch erwartete Werte) eingetragen und auf der y-Achse die Quantile der beobachteten Daten (Stichprobendaten). Abbildung 4.11: Histogramm, Boxplot und QQ-Plot für eine Normalverteilung. Liegt Normalverteilung vor hat das Histogramm annähernd die Form einer symmetrischen Glockenkurve. ist der Boxplot symmetrisch, Median und Mittelwert (roter Punkt) sind annähernd identisch. Liegen die Punkte im QQ-Plot annähernd auf einer Geraden. Abbildung 4.12: Histogramm und QQ-Plot für eine rechtssteile Verteilung. Beispiel für eine linksschiefe Verteilung: Im Histogramm sind die Daten linksschief verteilt. Der Boxplot ist asymmetrisch, der Mittelwert (roter Punkt) ist kleiner als der Median. Der QQ-Plot weist eine deutliche, nach oben konvexe Krümmung auf. Abbildung 4.13: Histogramm und QQ-Plot für eine linkssteile Verteilung. Beispiel für eine rechtsschiefe Verteilung: Im Histogramm sind die Daten rechtsschief verteilt. Der Boxplot ist asymmetrisch, der Mittelwert (roter Punkt) ist grösser als der Median. Der QQ-Plot weist eine deutliche, nach unten konvexe Krümmung auf. Die Interpretation von QQ-Plots für kleine Stichproben ist schwierig und nicht immer ganz eindeutig möglich. Abbildung 4.14: QQ-Plots für Stichproben (n = 28) aus einer perfekten Normalverteilung In der Abbildung 4.14 wurden zehn Stichproben im Umfang von \\(n\\) = 28 aus einer perfekt normalverteilten Population gezogen. Die Grafiken 3, 6 und 8 könnten auch zur Einschätzung führen, dass die Daten nicht normal verteilt sind. Abbildung 4.15: . Diese Abbildung 4.15 zeigt reale Daten zur Körpergrösse aus einer Stichprobe \\(n\\) = 50 Personen. Obwohl wir theoretisch wissen, dass Körpergrösse eine normalverteilte Variable ist, würden wir aus den Stichprobendaten vermutlich einen anderen Schluss ziehen. Wenn wir mit den Grafiken gar nicht weiterkommen, kann der Shapiro-Wilk-Test weiter helfen. Dieser Test ist ein Hypothesentest (s. Kapitel Grundlagen der Inferenzstatistik) auf Normalverteilung. Die Nullhypothese des Shapiro-Tests ist, dass die Population normalverteilt ist. Wenn der p-Wert des Tests gleich oder kleiner als 0.05 ist, dann wird die Normalitätshypothese durch den Shapiro-Test abgelehnt. Das heisst, dass die Daten mit mindestens 95%iger Sicherheit nicht der Normalverteilung entsprechen. Ist der p-Wert des Tests grösser als 0.05 ist der Test bestanden und es besteht keine Evidenz für eine signifikante Abweichung von der Normalverteilung. 4.5 Die \\(t\\)-Verteilung Die \\(t\\)-Verteilung wird hier eingeführt, weil Statistikprogramme wie R oder jamovi bei den Hypothesentests als Teststatistik nicht einen \\(z\\)-Wert angeben, sondern einen \\(t\\)-Wert, was bei den Studierenden immer wieder zu Verwirrung führt. Es würde für diesen Kurs zu weit gehen, die \\(t\\)-Verteilung detailliert zu besprechen. Die \\(t\\)-Verteilung ist eine Variante der Normalverteilung, die in der Statistik eine grosse Rolle spielt William S. Gosset, Pseudonym: Student hatte festgestellt, dass die standardisierte Schätzfunktion des Stichproben-Mittelwerts normalverteilter Daten nicht mehr normalverteilt, sondern eben \\(t\\)-verteilt ist, wenn die zur Standardisierung des Mittelwerts benötigte Varianz des Merkmals in der Population unbekannt ist und mit der Stichprobenvarianz geschätzt werden muss. Seine \\(t\\)-Verteilung erlaubt  insbesondere für kleine Stichprobenumfänge  die Berechnung der Verteilung der Differenz vom Mittelwert der Stichprobe zum wahren Mittelwert der Grundgesamtheit. Abbildung 4.16: t-Verteilung für df = 1, 2, 4 und 8; Normalverteilung rot Was ist wichtig? Für die praktische Arbeit gilt, dass die \\(t\\)-Verteilung als Anpassung der Normalverteilung für kleine Stichprobenumfänge aufgefasst werden kann. Ab einem Stichprobenumfang von n &gt; 30 entspricht sie nahezu der Normalverteilung. Der \\(t\\)-Wert, den Statistikprogramme berechnen, wird gleich wie ein \\(z\\)-Wert interpretiert. Die Form der \\(t\\)-Verteilung ist abhängig vom Stichprobenumfang \\(n\\). Dieser wird in Freiheitsgraden (degrees of freedom, \\(df\\) angegeben), wobei \\(df = n1\\). Je grösser die Anzahl Freiheitsgrade \\(df\\) ist, desto mehr nähert sich die \\(t\\)-Verteilung der Normalverteilung an. Aktuelle Statistikprogramme verwenden, unabhängig vom Stichprobenumfang, als Testsstatistik \\(t\\)-Werte anstelle von \\(z\\)-Werten. Wie für die \\(z\\)-Werte können auch Flächen für \\(t\\)-Werte unter der Kurve bestimmt werden. Dafür existieren Tabellen, z.B. hier Tabelle T-Verteilung. Genauer sind Internet-Rechner, z.B. hier Internet-Rechner T-Verteilung oder Statistikprogramme wie R/jamovi. References "],["grundlagen-der-inferenzstatistik.html", "5 Grundlagen der Inferenzstatistik 5.1 Einleitung 5.2 Lernziele 5.3 Grundbegriffe 5.4 Methoden der Inferenzstatistik 5.5 Stichprobenumfang und Fehlergrenze 5.6 Standardfehler (engl. standard error, Abk. SE) 5.7 Konfidenzintervalle (auch Vertrauensintervalle, engl. confidence intervalls, Abk. \\(CI\\)) 5.8 Hypothesen in der Statistik 5.9 Der p-Wert 5.10 Einseitige und zweiseitige Hypothesentests 5.11 Hypothesentests Schritt für Schritt 5.12 Statistische Signifikanz versus praktische Relevanz", " 5 Grundlagen der Inferenzstatistik 5.1 Einleitung Heres some shocking information for you - sample statistics are always wrong!  Jim Frost Deskriptive Statistik und Inferenzstatistik sind die zwei Hauptkategorien in der Statistik. Deskriptive Statistik  dient der Beschreibung von Daten in einen Datensatz, der z.B. durch eine Zufallsstichprobe entstanden ist. Die Ergebnisse werden nicht verallgemeinert. berechnet Kennzahlen zu den Daten aus einem Datensatzes und stellt die Daten grafisch dar; verwendet zur Beschreibung der Daten Kennzahlen wie Mittelwert, Median, Standardabweichung, Quartilsabstand oder Korrelationskoeffizient. arbeitet nur mit den vorliegenden Daten im Datensatz; daher besteht keine Unsicherheit im Hinblick auf die Gültigkeit von Kennzahlen. Inferenzstatistik  arbeitet mit Daten, die durch die Untersuchung einer Zufallsstichprobe aus einer grösseren Population ermittelt wurden. Ihre Aufgabe ist es, Rückschlüsse auf die Population zu ziehen, aus der diese Daten stammen. Die Ergebnisse der Stichprobe werden also auf eine grössere Gruppe oder Population übertragen. benötigt als Grundlage eine repräsentative Stichprobe aus der Population. Am besten gelingt das, indem die Beobachtungseinheiten für die Stichprobe zufällig aus der Population ausgewählt werden (Zufallsstichprobe). schätzt die wahren Kennzahlen in der Population auf Grundlage der Stichproben-Kennzahlen. Da Schätzungen immer mit einer gewissen Ungenauigkeit verbunden sind interessiert die Frage «Wie sicher können wir sein, dass der geschätzte Mittelwert \\(\\bar{x}\\) dem wahren Populationsmittelwert \\(\\mu\\) entspricht?». liefert Angaben, bis zu welchem Grad bzw. mit welcher Wahrscheinlichkeit wir unseren Schätzungen vertrauen können. Die diesem Kapitel vorgestellten Grundlagen der Inferenzstatistik sind absolut essentiell für das Verständnis der nachfolgenden Themen. Es lohnt sich daher, für das Verständnis dieser Inhalte genügend Zeit zu investieren. 5.2 Lernziele Verwende eine Stichprobenkennzahl als Schätzung für einen Populationsparameter, z.B. wird der Stichprobenmittelwert verwendet um den Populationsmittelwert zu schätzen; beachte dass Punktschätzer und Stichprobenkennzahl synonym sind. Beachte, dass Punktschätzer (wie z.B. der Stichprobenmittelwert) von Stichprobe zu Stichprobe variieren. Diese Variablilität wird als Stichprobenvariation bezeichnet. Eine Punktschätzung auf Grund einer Stichprobe wird in der Nähe des Populationsparameters liegen, aber es ist sehr unwahrscheinlich, dass sie diesen exakt trifft. Diese Abweichung wird als Stichprobenfehler: bezeichnet. Berechne die Stichprobenvariation des Mittelwerts, den Standardfehler SE mit der Formel (\\(\\sigma\\) ist die Standardabweichung des Populationsparameters) \\[SE = \\frac{\\sigma}{\\sqrt{n}}\\] Wenn die Populationsstandardabweichung \\(\\sigma\\) nicht bekannt ist, was meist der Fall ist, verwenden wir die Standardabweichung \\(s\\) der Stichprobe, um SE zu schätzen: \\(SE = \\frac{s}{\\sqrt{n}}\\). Unterscheide zwischen Standardabweichung (\\(s\\) oder \\(\\sigma\\)) und Standardfehler \\(SE\\): Die Standardabweichung misst die Variabilität in den Stichprobendaten, während der Standardfehler die Variabilität von Punktschätzungen aus verschiedenen Stichproben der gleichen Grösse und aus der gleichen Population misst. Mit anderen Worten: Der Standardfehler ist ein Mass für die die Stichprobenvariation. Erwarte, dass mit steigendem Stichprobenumfang die Stichprobenvariation abnimmt, da in der Formel zur Berechnung des Standardfehlers der Stichprobenumfang \\(n\\) im Nenner ist. Intepretiere ein Konfidenzintervall (engl. confidence interval) als glaubhaften Wertebereich für einen Populationsparameter. Interpretiere das Konfidenzniveau (engl. confidence level) als den prozentualen Anteil von Zufallsstichproben, die Vertrauensintervalle ergeben, welche den wahren Populationsparameter enthalten. Beachte, dass der zentrale Grenzwertsatz eine Aussage zur Verteilung von Punktschätzern erlaubt und dass diese Verteilung normal ist, wenn die Voraussetzungen erfüllt sind. Diese Voraussetzungen sind: Normalverteilung der Daten in der Population. Wenn die Verteilung in der Population unbekannt ist, kann diese Bedingung anhand eines Histogramms, eines Boxplots oder QQ-Plots überprüft werden. Stichprobenumfang \\(n\\) &gt; 30. Je grösser der Stichprobenumfang \\(n\\), desto unbedeutender wird die Verteilung, d.h. wenn \\(n\\) sehr gross ist, wird die Stichprobenverteilung nahezu normal sein, unabhängig von der Form der Verteilung in der Population. Unabhängigkeit der Beobachtungseinheiten in einer Stichprobe: Die Unabhänigkeit der Beobachtungseinheiten kann sicher gestellt werden, indem diese zufällig ausgewählt werden (random sampling) und zufällig zu Gruppen zugeordnet werden (random assignment). Merke, dass die Normalverteilung der Punktschätzer bedeutet, dass ein Konfidenzintervall berechnet werden kann: \\[Punktschätzer \\pm z_{1-\\frac{\\alpha}{2}} \\times SE\\] wobei \\(z_{1-\\frac{\\alpha}{2}}\\) den Grenzen der Standardnormalverteilung entspricht, innerhalb derer \\(1-\\alpha\\) % der Daten liegen, wobei \\(1-\\alpha\\) % dem erwünschten Konfidenzniveau entspricht. Für einen Mittelwert ist dies: \\(CI_{1-\\alpha} = \\bar{x} \\pm z_{1-\\frac{\\alpha}{2}} \\times SE\\) Beachte, dass \\(z_{1-\\frac{\\alpha}{2}}\\) immer positiv ist! Definiere bei der Berechnung des Konfidenzintervalls den Fehlerbereich (engl. margin of error, Abk. ME) als Abstand in beide Richtung vom Punktschätzer, d.h. \\[ME = z_{1-\\frac{\\alpha}{2}} \\times SE\\] * Beachte, dass dies genau einer Hälfte der Breite des Vertrauensintervalls ist. Interpretiere ein Konfidenzintervall als Wir können zu XX% darauf vertrauen, dass der wahre Populationsparameter innerhalb dieses Intervalls liegt, wobei XX% das gewünschte Vertrauensniveau ist. Beachte, dass deine Interpretation immer im Kontext der Daten erfolgen sollte; erwähne immer, auf welche Population und welchen Parameter sich eine Aussage bezieht. Erkläre, inwiefern das Prinzip von Hypothesentests mit dem Vorgehen am Gericht vergleichbar ist. Denke daran, dass wir bei Hypothesentests immer zwei sich gegenseitig ausschliessende Aussagen untersuchen: Die Nullhypothese \\(H_0\\) steht für den skeptischen Standpunkt (kein Unterschied). Die Alternativhypothese \\(H_A\\) ist die Gegenhypothese zur Nullhypothese (es gibt einen Unterschied). Beachte bei der Hypothesenbildung: Hypothesen beziehen sich immer auf Populationsparameter (z.B. Populationsmittelwert, \\(\\mu\\)) und nicht auf die Stichprobenkennzahlen (z.B. Stichprobenmittelwert, \\(\\bar{x}\\)). Es ist absurd, bezüglich der Stichprobenkennzahl eine Hypothese zu bilden, da diese ja aus der Stichprobe bekannt ist. Verstehe den Nullwert als den Wert eines Populationsparameters, welcher der Nullhypothese entspricht. Beachte, dass die Alternativhypothese \\(H_A\\) entweder einseitig (\\(\\mu\\) &gt; Nullwert oder \\(\\mu\\) &lt; Nullwert) oder zweiseitig formuliert werden kann (\\(\\mu \\neq\\) Nullwert). Die Wahl hängt von der konkreten Fragestellung ab. Wenn kein spezieller Grund für eine einseitige Alternativhypothese vorliegt, wähle stets eine zweiseitige Alternativhypothese. Um die Abweichung einer Stichprobe von der angenommenen Grundgesamtheit im Rahmen eines Hypothesentests zu messen, wird eine Teststatistik (engl.: test statistic) berechnet. Definiere den \\(p\\)-Wert als die Wahrscheinlichkeit  unter der Bedingung, dass die Nullhypothese in Wirklichkeit gilt  den beobachteten Wert der Teststatistik oder einen in Richtung der Alternative extremeren Wert zu erhalten. \\[ p-Wert = P(beobachteter~oder~noch~extremerer~Wert~der~Prüfgrösse~|~H_0~wahr)\\] Berechne einen \\(p\\)-Wert als Fläche unter der Normalverteilungskurve (entweder auf eine Seite oder auf beide Seiten abhängig von der Alternativhypothese). Verwende zu diesem Zweck einen \\(z\\)-Wert oder einen \\(t\\)-Wert. Verwerfe die Nullhypothese zugunsten der Alternativhypothese, wenn ein Konfidenzintervall den Nullwert nicht enthält. Vergleiche den \\(p\\)-Wert mit dem Signifikanzniveau \\(\\alpha\\) (typischerweise \\(\\alpha = 0.05\\)), um zwischen den Hypothesen zu entscheiden: Verwerfe die Nullhypothese zugunsten der Alternativhypothese, wenn der \\(p\\)-Wert kleiner als das Signifikanzniveau ist, da dies bedeutet, dass es sehr unwahrscheinlich ist, eine mindestens so extreme Teststatistik rein durch Zufall zu erhalten. Interpretiere das Ergebnis in dem Sinn, dass die Daten Evidenz für die Alternativhypothese liefern. Verwerfe die Nullhypothese nicht, wenn der \\(p\\)-Wert grösser als das Signifikanzniveau ist, da dies bedeutet, dass es rein auf Zufall beruhen kann, eine mindestens so extreme Teststatistik zu erhalten. Interpretiere das Ergebnis so, dass die Daten keine Evidenz für die Alternativhypothese liefern. Merke: Die Nullhypothese kann nie angenommen oder bewiesen werden, da das Prinzip von Hypothesentests dies nicht erlaubt. Denke daran, dass es immer möglich ist, einen Entscheidungsfehler zu begehen: Ein Fehler 1. Art bedeutet, dass die Nullhypothese verworfen wird, obwohl sie in Wirklichkeit wahr ist. Mit einem Signifikanzniveau von \\(\\alpha = 0.05\\) nehmen wir in Kauf, dass dies bei 1 von 20 Entscheidungen der Fall ist. Ein Fehler 2. Art bedeutet, dass wir die Nullhypothese aufrechterhalten, obwohl in Wirklichkeit die Alternativhypothese wahr ist. Damit verpassen wir die Erfassung eines Effektes, wo einer in Wahrheit vorhanden ist. Beachte, dass die Wahrscheinlichkeit, einen Fehler 1. Art zu begehen dem Signifikanzniveau entspricht. Wähle das Signifkanzniveau so, dass es den Folgerisiken entspricht, die mit einem Fehler 1. oder 2. Art verbunden ist: Wähle ein kleineres \\(\\alpha\\), wenn das Risiko einen Fehler 1. Art zu begehen, minimiert werden soll. Wähle ein grösseres \\(\\alpha\\), wenn das Risiko einen Fehler 2. Art zu begehen, minimiert werden soll. Definiere einen Effekt als Auswirkung oder als Folge einer Ursache. Wenn wir z.B. zwei Stichproben von Probanden mit und ohne Schlafmittel vergleichen und sich herausstellt, dass die Probanden mit dem Schlafmittel im Durchschnitt 1.5 Stunden länger schlafen, dann bezeichnen wir diese Differenz in der Schlafdauer zwischen den Gruppen als Effekt mit der Effektgrösse 1.5 Stunden. Beachte, dass ein statistisch signifikanter Effekt nicht zwingend auch praktische Relevanz (Bedeutung) hat. 5.3 Grundbegriffe 5.3.1 Population Im alltäglichen Sprachgebrauch besteht eine Population meist aus Menschen, z.B. die Einwohner:innen von Basel, Primarschüler:innen in einer Stadt oder Diabetiker:innen. In der Forschung können Populationen jedoch auch Objekte, Ereignisse, Firmen usw. sein. Zum Beispiel: Die Sterne der Milchstrasse Ein bestimmter Microchip für Handys Coronaviren SARS-CoV-2 Hefekulturen in einer Brauerei Je nach Fragestellung muss die Population sehr genau definiert werden, wenn man eine Studie durchführt. Dieser Aspekt wird im wissenschaftlichen Arbeiten bei der Behandlung der PICO-Fragestellung ausführlich besprochen. Eine Subpopulation ist eine Untergruppe einer Population. So kann man die Population Bürger:innen der Schweiz in die Subpopulationen «Mann», «Frau» oder «höchster Schulabschluss» oder «sozialer Status» etc. oder Covid-19-Viren in die Subpopulationen Alpha (England), Beta (Südafrika), Gamma (Brasilien) und Delta (Indien) unterteilen. Die Einteilung in Subpopulationen ist v.a. dann von Bedeutung, wenn zwischen den Untergruppen systematische Unterschiede bestehen, wie das z.B. bei der Körpergrösse von Männern und Frauen der Fall ist (5.1. Abbildung 5.1: Körpergrösse einmal gemeinsam, einmal nach Geschlecht getrennt 5.3.2 Populationsparameter vs. Stichprobenkennzahl Ein Parameter ist ein Wert, der ein Merkmal einer ganzen Population beschreibt, z.B. ein Populationsmittelwert. Da es in der Regel nicht möglich ist, alle Beobachtungseinheiten einer Population zu messen, kennen wir Populationsparameter meist nicht. Obwohl wir Populationsparameter nicht messen können, existieren sie. Z.B. die durchschnittliche Körpergrösse aller Frauen in der Schweiz ist ein exakter Parameter, nur kennen wir diesen einfach nicht! Mass Populationsparameter Stichprobenkennzahl Umfang \\(N\\) \\(n\\) Mittelwert \\(\\mu\\) \\(\\bar{x}\\) Standardabweichung \\(\\sigma\\) \\(s\\) Korrelation \\(\\rho\\) \\(r\\) In der Inferenzstatistik dient die Stichprobenkennzahl dazu, den Populationsparameter zu schätzen. Folgende Schätzer (engl. estimate) für Populationsparameter kommen zum Einsatz: Ein Punktschätzer verwendet eine Stichprobenkennzahl als beste Schätzung für einen Populationsparameter. Z.B. ist der Stichprobenmittelwert der beste Schätzer für den Populationsmittelwert. Wegen dem Stichprobenfehler sind leider Punktschätzer immer ungenau und die Grösse der Abweichung vom wahren Wert bleibt unbekannt. Ein Intervallschätzer umfasst einen Wertebereich, der mit einer gewissen Wahrscheinlichkeit den Populationsparameter enthält. Solche Wertebereiche beinhalten eine Fehlergrenze (Fehlerbereich, engl. margin of error, Abk. ME) und berücksichtigen auf diese Weise die Ungenauigkeit eines Punktschätzers. Wenn wir statistische Resultate lesen, sollten wir uns immer fragen, wie gross diese Ungenauigkeit ist. Leider wird in den Medien dieser Fehlerbereich sehr oft nicht angegeben, wodurch eine falsche Genauigkeit suggeriert wird, die fakisch gar nicht vorhanden ist. 5.4 Methoden der Inferenzstatistik In diesem Kurs lernen wir drei Methoden der Inferenzstatistik kennen: Hypothesentests verwenden Stichprobendaten um Fragen zu Punktschätzern zu beantworten. Z.B. ist der Populationsparameter grösser oder kleiner als ein bestimmter Wert oder unterscheiden sich die Parameter von zwei Populationen voneinander (Bsp. klinische Studie mit Interventions- und Kontrollgruppe). Konfidenzintervalle (engl. confidence intervalls, Abk. CI) dienen der Bestimmung von Populationsparametern und berücksichtigen die Unsicherheit (Ungenauigkeit) als Folge des Stichprobenfehlers. Sie geben einen Wertebereich an, in den der wahre Parameter mit einer gewissen Wahrscheinlichkeit fällt. Z.B. Ein Konfidenzintervall [176; 186] gibt an, dass wir darauf vertrauen können, dass der wahre Populationsparameter innerhalb dieses Intervalls liegt. Die Korrelations- und Regressionsanalyse beschreibt den Zusammenhang zwischen einer oder mehreren unabhängigen Variablen und einer abhängigen Variablen. Diese Analyse umfasst Hypothesentests, welche die Entscheidung ermöglichen, ob ein Zusammenhang zwischen zwei oder mehr Variablen in einer Stichprobe effektiv auch in der Population besteht. 5.5 Stichprobenumfang und Fehlergrenze Inferenzstatistik ist ein mächtiges Werkzeug, das uns erlaubt, aus relativ kleinen Stichproben etwas über eine ganze Population zu erfahren. Leider ist es jedoch so, dass auch wenn eine Studie akribisch genau durchgeführt wird, die Ergebnisse immer etwas falsch sein werden (bezogen auf die wahren Populationsparameter). Weil eine Stichprobe eben nicht die gesamte Population ist, können Stichprobendaten nie zu 100% präzis sein. Das primäre Ziel der Inferenzstatistik ist es, von einer Stichprobe auf die Population zu verallgemeinern. Grosse Stichproben repräsentieren die Vielfalt einer Population besser als kleine Stichproben. Wenn wir zum Beispiel eine Studie zum Intelligenzquotienten durchführen und wir haben nur fünf Probanden zum testen, dann wird ein aussergewöhnlich hoher oder tiefer Wert den Stichprobenmittelwert erheblich beeinflussen. Wenn wir 50 Probanden untersuchen können, haben einzelne Extremwerte einen viel geringeren Einfluss. 5.5.1 Verteilung von Stichprobenkennzahlen (Stichprobenverteilungen, engl. sampling distributions) Für das Verständnis der Denkweise in der Statistik ist es ausserordentlich wichtig sich vor Augen zu halten, dass wenn wir eine Zufallsstichprobe aus einer Population ziehen, diese Stichprobe nur eine von einer grossen Zahl möglicher Stichproben ist. Zur Illustration führen wir ein simuliertes Experiment durch: Wir wissen, dass der IQ normalverteilt ist und dass der Populationsmittelwert des IQ-Scores bei \\(\\mu = 100\\) und die Standardabweichung bei \\(\\sigma = 15\\) liegt. Jetzt ziehen wir 1000 Stichproben aus der Population im Umfang \\(n = 5\\), \\(n = 25\\), \\(n = 100\\) und stellen die ermittelten Stichprobenmittelwerte als Histogram dar. Abbildung 5.2: Stichprobenvariabilität für Mittelwerte von jeweils 1000 Stichproben Was lernen wir aus diesem Experiment? Jeder Stichprobenmittelwert liegt in der Nähe des wahren Populationsmittelwertes, aber es ist wenig wahrscheinlich, dass ein Stichprobenmittelwert exakt den wahren Populationsmittelwert trifft. Je grösser die Stichprobe \\(n\\), desto näher liegen die geschätzten Mittelwerte beim wahren Populationsmittelwert. Mit anderen Worten: Je grösser der Stichprobenumfang \\(n\\), desto mehr können wir dem Stichprobenmittelwert vertrauen, dass er den wahren Populationsparameter repräsentiert. Die Variabilität dieser Verteilungen \\(SE\\) entspricht dem Stichprobenfehler in Abhängigkeit vom Stichprobenumfang \\(n\\). Grössere Stichprobenumfänge weisen einen kleineren Fehlerbereich auf. Die Stichprobenmittelwerte mehrerer Stichproben sind normalverteilt. Was wir an unserem Beispiel nicht erkennen können ist, dass die Stichprobenverteilung der Mittelwerte selbst dann normalverteilt ist, wenn die zu Grunde liegende Verteilung der Populationsdaten nicht normal ist. Tipp: Die Online-App Central Limit Theorem for Means ermöglicht es, interaktiv verschiedene Szenarios durchzuspielen. Im Experiment zum IQ-Score wird eine Verteilung für die Mittelwerte mehrerer Stichproben erstellt. Eine solche Stichprobenverteilung zeigt die Verteilung von Stichprobenkennzahlen (hier von Mittelwerten) mehrerer gleich grosser Stichproben aus einer bestimmten Population. Wie weiter unten erläutert, kann mit Hilfe eines mathematischen Tricks solche Stichprobenverteilungen aus einer einzigen Stichprobe geschätzt werden. Diese Verfahren bilden die theoretische Grundlage für Hypothesentests und Konfidenzintervalle. Tipp: Bunnies, Dragons and the Normal World 5.6 Standardfehler (engl. standard error, Abk. SE) Die einzelnen Stichprobenmittelwerte in unserem Experiment liegen mehr oder weniger in der Nähe des wahren Populationsmittelwerts. Die Streuung der einzelnen Werte einer Stichprobenverteilung kann mit Hilfe der Standardabweichung quantifiziert werden. Die Standardabweichung eines Stichprobenmittelwerts beschreibt, wie weit typischerweise eine bestimmte Kennzahl vom wahren Populationsparameter entfernt ist oder mit anderen Worten, den Fehler dieser Schätzung. Die Standardabweichung einer Punktschätzung wird als Standardfehler bezeichnet. Der Standardfehler ist ein Mass für die Ungenauigkeit, die auf Grund der Stichprobenvariation mit unserer Punktschätzung verbunden ist. Was genau ist jetzt aber der Unterschied zwischen Standardabweichung und Standardfehler? Sowohl der Standardfehler als auch die Standardabweichung befassen sich mit dem Mittelwert einer Stichprobe, das ist das Gemeinsame, aber   der Standardfehler gibt Auskunft über die mittlere Abweichung des Mittelwerts einer Stichprobe vom tatsächlichen Mittelwert der Population; er beschreibt also die Beziehung zwischen Stichprobenkennzahl und Populationsparameter!  die Standardabweichung gibt uns Auskunft darüber, wie sehr die einzelnen Werte der Stichprobe um ihren Mittelwert streuen. Üblicherweise steht, v.a. aus ökonomischen Gründen, nur eine einzige Stichprobe zur Verfügung und es ist auf den ersten Blick nicht offensichtlich, wie der Standardfehler \\(SE\\) aus einer einzigen Stichprobe berechnet werden kann. Wenn wir uns noch einmal den drei Experimenten oben zuwenden, stellen wir fest, dass \\(SE\\) mit zunehmendem Stichprobenumfang kleiner wird: 6.89 bei n = 5, 2.9 bei n = 25 und 1.94 bei n = 100. Es besteht demnach eine Beziehung zwischen der Grösse des Standardfehlers SE und dem Stichprobenumfang \\(n\\). Bei einem Stichprobenumfang \\(n\\) aus einer Population mit der Standardabweichung \\(\\sigma\\), ist der Standardfehler des Stichprobenmittelwerts gleich \\[SE = \\frac{\\sigma}{\\sqrt{n}}\\] Da die Standardabweichung einer Population üblicherweise unbekannt ist, werd sie mit der Standardabweichung der vorhandenen Stichprobe geschätzt: Anstelle von \\(\\sigma\\) setzen wir \\(s\\) als Punktschätzer für \\(\\sigma\\) ein: \\[SE = \\frac{s}{\\sqrt{n}}\\] 5.6.1 Das Wurzel-n-Gesetz Der Formel für die Berechnung des Standardfehlers \\(SE\\) ist zu entnehmen, dass sich dieser umgkehrt proportional zur Quadratwurzel des Stichprobenumfangs \\(n\\) verändert. Um also den Standardfehler beispielsweise zu halbieren, müsste daher den Stichprobenumfang vervierfacht werden. s n SE 16 16 4 16 64 2 5.7 Konfidenzintervalle (auch Vertrauensintervalle, engl. confidence intervalls, Abk. \\(CI\\)) Die Kennzahl aus einer Stichprobe, z.B. der Mittelwert, liefert uns eine einzige Schätzung für einen Populationsparameter. Wie wir gesehen haben, sind solche Punktschätzungen eigentlich nie perfekt und wir würden gerne wissen, in welchem Mass wir auf diesen Wert vertrauen können, um unser Ergebnis korrekt interpretieren zu können. Hier kommen die Vertrauensintervalle ins Spiel. Es liegt eigentlich nahe, dass wir an Stelle einer Punktschätzung ein Werteintervall angeben können, in dem der wahre Populationsparameter mit grosser Wahrscheinlichkeit liegt. Das wäre dann zwar scheinbar weniger präzis, dafür etwas zuverlässiger (siehe unten Präzision versus Sicherheit). Da ein Punktschätzer aus einer Stichprobe der überzeugendste Wert für einen gesuchten Populationsparameter ist, macht es Sinn, dass ein Konfidenzintervall um diese Schätzung herum konstruiert wird. Der Standardfehler, als Mass für die Ungenauigkeit des Punktschätzers, liefert die Angabe, wie breit das Konfidenzintervall konstruiert werden soll. Der Standardfehler ist die Standardabweichung der Punktschätzung. Aus der 68-95-99.7-Regel wissen wir, dass ca. 95% der Daten innerhalb von zwei Standardabweichungen liegen. Damit können wir davon ausgehen, dass in ca. 95% der Fälle, der Punktschätzer innerhalb von plus/minus 2 Standardfehlern des Populationsparameters liegt. Wenn also die Breite eines Konfidenzintervalls plus/minus 2 Standardfehler zum Punktschätzer umfasst, dürfen wir zu 95% darauf vertrauen, dass dieses den wahren Populationsparameter enthält. \\[CI_{95} = Punktschätzung \\pm 2 \\times SE\\] Was bedeutet aber zu 95% darauf vertrauen können? Wenn viele Stichproben mit dem gleichen Stichprobenumfang aus einer Population gezogen werdne und für jede Stichprobe das 95%-Konfidenzintervall bestimmt wird, dann werden im Durchschnitt ca. 95% aller dieser Konfidenzintervalle den wahren Populationsparamter enthalten. Kommen wir auf unser IQ-Score-Experiment zurück. Wir ziehen nochmals 25 Stichproben im Umfang \\(n\\) = 50 und konstruieren für jede Stichprobe das 95%-Konfidenzintervall für den IQ-Score. Abbildung 5.3: IQ-Score: 95%-Vertrauensintervalle für 25 Zufallsstichproben, \\(n\\) = 50 Von den 25 Stichproben enthalten in Abbildung 5.3 zwei (= 8%) den wahren Populationsmittelwert nicht. Da der Standardfehler \\(SE\\) mit zunehmendem Stichprobenumfang \\(n\\) abnimmt, hat der Stichprobenumfang \\(n\\) einen grossen Einfluss auf die Breite von Konfidenzintervallen. Tipp: Web-App Seeing Theory: Confidence Intervalls. Wähle \\(Normal\\) für Normalverteilung Stelle mit dem Regler das Konfidenzniveau \\(1-\\alpha\\) = 0.95 Beachte den Einfluss des Stichprobenumfangs auf die Breite der Konfidenzintervalle. Welchen Einfluss hat die Veränderung des Konfidenzniveaus \\(1-\\alpha\\) auf die Breite der Konfidenzintervalle? Erkenntnis: Je höher der Stichprobenumfang pro Stichprobe ist, desto schmaler werden die Konfidenzintervalle. Je höher das Konfidenzniveau wird, desto breiter werden die Konfidenzintervalle. 5.7.1 Anpassung des Konfidenzniveaus Konfidenzintervalle haben eine untere und eine obere Grenze. In der Mitte steht die Stichprobenkennzahl, z.B. \\(\\bar{x}\\). Die untere Grenze des Vertrauensintevalls wird berechnet als \\(\\bar{x} - Fehlerbereich ~ME\\) und die obere Grenze \\(\\bar{x} + Fehlerbereich~ ME\\). \\[ME = z \\times SE\\] In der Formel zum 95%-Konfidenzintervall haben wir \\(z = 2\\) eingesetzt. Möglicherweise sind aber 95%-Vertrauensintervalle zu unsicher (z.B. wenn wir die Festigkeit von Schweissnähten in einem Atomkraftwerk prüfen würden) und man möchte eine grössere Zuverlässigkeit haben. In diesem Fall wird das Konfidenzniveau auf z.B. 99% erhöht. Es kann jedoch sein, dass keine so grosse Zuverlässigkeit erforderlich ist, dann kann das Konfidenzniveau auf z.B. 90% gesenkt werden. Das gewünschte Konfidenzniveau hat einen Einfluss auf den Fehlerbereich ME, der toleriert wird und somit auf den Faktor, mit dem der Standardfehler multipliziert werden muss. Allgemein formuliert: \\[CI_{1-\\alpha} =\\bar{x} \\pm z_{1-\\frac{\\alpha}{2}} \\times SE\\] Das \\(z\\) erinnert an die \\(z\\)-Werte der Standardverteilung und effektiv ist es das auch. Aus der 68-95-99.7-Regel wissen wir, dass wenn wir für \\(z\\) = 1 einsetzen ca. 68%, wenn wir für \\(z\\) = 2 einsetzen ca. 95% und für \\(z\\) = 3 ca. 99.7% der Daten enthalten sind. Üblich sind Konfidenzintervalle von 90%, 95% und 99%. \\(\\alpha/2\\) Vertrauensniveau \\(1-\\alpha\\) \\(z_{1-\\frac{\\alpha}{2}}\\) .05 .9 = 90% 1.645 .025 .95 = 95% 1.96 .005 .99 = 99% 2.58 Anmerkungen: Eine Erklärung zur Bedeutung des Signifikanzniveaus \\(\\alpha\\) folgt weiter unten. Man kann hier schon ahnen, dass \\(\\alpha\\) etwas mit dem Fehler zu tun hat, den wir bereit sind, in Kauf zu nehmen. Zur Schätzung des 95%-Bereichs kann in der Praxis der Faktor 2 verwendet werden, genauer ist aber 1.96. Abbildung 5.4: Flächen für 95%-CI und 99%-CI Die Abbildung 5.4 zeigt, dass mit grösserem \\(z\\) die Fläche zwischen \\(-z\\) und \\(+z\\) grösser wird. Für das 99% Konfidenzintervall wurde \\(z\\) so gewählt, dass 99% der Fläche unter der Kurve zwischen \\(-z\\) und \\(+z\\) liegt. 5.7.2 Präzision versus Sicherheit Es besteht ein direkter Zusammenhang zwischen der Genauigkeit eines Konfidenzintervalls und seiner Zuverlässigkeit. Schmale Konfidenzintervalle bedeuten hohe Präzision. Wenn wir die Formel zur Berechnung von Konfidenzintervallen betrachten, erkennen wir, dass drei Variablen die Grösse des Fehlerbereichs ME bestimmen: die Standardabweichung \\(s\\) der Stichprobenkennzahl: je grösser \\(s\\), desto breiter das Konfidenzintervall. der Stichprobenumfang \\(n\\): je grösser \\(n\\), desto kleiner ist das Konfidenzintervall. die Wahl von \\(z\\): die Wahl eines kleineren \\(z\\)-Werts ergibt ein kleineres Konfidenzintervall als die Wahl eines grösseren \\(z\\)-Werts. Allerdings ist das Konfidenzniveau bei einem kleineren \\(z\\)-Wert auch geringer als bei einem grösseren \\(z\\)-Wert. Wählen wir z.B. einen \\(z\\)-Wert von 1.645 können wir nur zu 90% darauf vertrauen, dass der wahre Populationsparameter im Konfidenzintervall liegt. Wählen wir jedoch \\(z\\) = 1.96, wird zwar der Fehlerbereich grösser (weniger Präzision), dafür steigt das Konfidenzniveau auf 95% (mehr Zuverlässigkeit). 5.7.3 Voraussetzungen Wichtige Voraussetzungen dafür, dass die Stichprobenverteilung von \\(\\bar{x}\\) normalverteilt ist und dass die Schätzung für den Standardfehler SE genügend genau ist, sind: Die einzelnen Beobachtungseinheiten der Stichprobe sind unabhängig voneinander. Der Stichprobenumfang ist gross: \\(n &gt; 30\\) ist eine gute Faustregel Die Populationsdaten sind nicht allzu stark schief verteilt. Die Beurteilung dieser Bedingung ist im Einzelfall nicht immer ganz einfach. Wie kann man sicher sein, dass die Beobachtungseinheiten in der Stichprobe voneinander unabhängig sind? Wenn die Beobachtungseinheiten aus einer Zufallsstichprobe (randomisierte Zuteilung) stammen und weniger als 10% der Gesamtpopulation umfassen, dann sind sie unabhängig. Beobachtungseinheiten in einer Studie gelten als unabhängig, wenn sie randomisiert den Gruppen (z.B. Interventions- und Kontrollgruppen) zugeteilt werden. 5.7.4 Interpretation von Konfidenzintervallen Aufmerksamen Leser:innen mag aufgefallen sein, dass die sprachliche Formulierung von Konfidenzintervallen etwas holprig tönt: Wir können zu XX% darauf vertrauen, dass der wahre Populationsparameter zwischen  und  liegt. De facto bedeutet dies, dass wenn wir 100 Stichproben mit dem gleichen Stichprobenumfang aus einer Population ziehen, werden im Durchschnitt XX Stichproben den wahren Populationsparameter enthalten. Bei der Formulierung von Konfidenzintervallen kommt es häufig zu zwei typischen Fehlern: Zu sagen, dass ein Konfidenzintervall mit einer Wahrscheinlichkeit von XX% den Populationsparameter enthält ist nicht korrekt. Das Konfidenzintervall enthält den Populationsparameter oder nicht, wir wissen es einfach nicht, aber wir können zu XX% darauf vertrauen. Das ist ein sehr subtiler sprachlicher Fehler. Zu sagen, dass XX% der Populationsdaten in das Konfidenzintervall fallen, ist falsch. Das Konfidenzintervall bezieht sich ausschliesslich auf den gesuchten Populationsparameter und nicht auf die Populationsdaten! 5.8 Hypothesen in der Statistik Wir beginnen mit der Frage, ob Studierende heute öfter ins Krafttrainig gehen als vor 10 Jahren. Es liegen uns Daten von Studien aus den Jahren 2010 und 2020 vor, welche u.a. die Frage bearbeitet haben Wie oft pro Woche gehen Studierende ins Krafttraining. Unsere Hypothesen könnten lauten: \\(H_0:\\) Die durchschnittliche Anzahl Krafttrainings der Studierenden ist in den Jahren 2010 und 2020 die gleiche. Es gibt keinen Unterschied in der durchschnittlichen Anzahl Krafttrainings pro Woche zwischen den Studierenden 2010 und 2020. \\(H_A:\\) Die durchschnittliche Anzahl Krafttrainings der Studierenden ist in den Jahren 2010 und 2020 nicht gleich. Es gibt einen Unterschied in der durchschnittlichen Anzahl Krafttrainings pro Woche zwischen den Studierenden 2010 und 2020. \\(H_0\\) bezeichnen wir als Nullhypothese, \\(H_A\\) als Alternativhypothese. In der Regel, steht die Nullhypothese für einen skeptisch-konservativen Standpunkt: Es gibt keinen Unterschied. Die Alternativhypothese ist dagegen der Standpunkt der eine neue Perspektive eröffnet und die Möglichkeit in Betracht zieht, dass ein Unterschied besteht. Die wissenschaftliche Position ist grundsätzlich eine skeptische. Das bedeutet, dass die Nullhypothese \\(H_0\\) nicht verworfen wird, es sei dann es bestehe starke Evidenz für die Alternativhypothese \\(H_A\\). In diesem Fall wird \\(H_0\\) zu Gunsten von \\(H_A\\) verworfen. Dieses Prinzip wird auch in der Rechtssprechung angewandt. Ein Angeklagter gilt so lange als unschuldig (\\(H_0\\) = Unschuldsvermutung), bis mit ausreichender Evidenz das Gegenteil (\\(H_A\\)) bewiesen ist. Auch wenn ein Angeklagter frei gesprochen wird (\\(H_0\\) wird nicht verworfen) ist es möglich, dass er schuldig ist, aber die Beweislage war in diesem Fall ungenügend. Daher gilt Auch wenn wir die Nullhypothese nicht verwerfen können, heisst das nicht, dass wir sie als wahr akzeptieren. Keine starke Evidenz für die Alternativhypothese zu finden bedeutet daher nicht, dass wir die Nullhypothese akzeptieren. 5.8.1 Mathematische Formulierung von Hypothesen Damit Hypothesen mit statistischen Methoden überprüft werden können, müssen sie zuerst mathematisch formuliert werden. Im Beispiel zur Trainingshäufigkeit von Studierenden haben wir die Null- und die Alternativhypothese bereits sprachlich formuliert und können sie jetzt im Hinblick auf die statistische Auswertung mathematisch formulieren: Nullhypothese: \\(H_0: \\mu_{Training2020}=\\mu_{Training2010}\\) bzw. \\(H_0: \\mu_{Training2020}-\\mu_{Training2010} = 0\\) Alternativhypothese: \\(H_A: \\mu_{Training2020}\\neq\\mu_{Training2010}\\) bzw. \\(H_A: \\mu_{Training2020}-\\mu_{Training2010} \\neq 0\\) (In jeweils der Formulierung (\\(=0,~\\neq0\\)) erkennen Sie, warum das Ganze Nullhypothese genannt wird) Ein Fehler, der häufig bei der mathematischen Formulierung von \\(H_0\\) und \\(H_A\\) gemacht wird ist: \\(H_0: \\bar{x}_1 = \\bar{x}_2\\) \\(H_A: \\bar{x}_1 \\neq \\bar{x}_2\\) Warum ist das falsch? Weil bei der Formulierung der Hypothesen nicht für die Stichprobenmittelwerte interessieren, sondern die Populationsparameter! Für die Stichprobenmittelwerte brauchen wir ja keine Hypothesen, die sind bekannt: entweder sind die beiden Stichprobenkennzahlen identisch oder sie sind es nicht. In der Umgangssprache und in der medizinischen Diagnostik hat der Begriff Hypothese eine etwas andere Bedeutung: Wir verwenden ihn, wenn wir eine Vermutung oder eine Annahme über die Ursache eines Zustands oder Ereignisses haben. Aus der Perspektive der Statistik handelt es sich dabei typischerweise um eine Alternativhypothese. Im Unterschied zu Hypothesen im Alltag muss eine Hypothese in der Wissenschaft prüfbar, d.h. falsifizierbar sein. In der statistischen Praxis empfiehlt es sich daher, die Null- und Alternativhypothese immer mathematisch zu formulieren. 5.8.2 Hypothesen mittels Konfidenzintervallen prüfen Betrachten wir die Ergebnisse der Studien aus den Jahren 2010 und 2020. An wie vielen Tagen haben die Studierenden in den beiden Stichproben (n = 92) pro Woche durchschnittlich trainiert? Tabelle 5.1: Mittelwert (M) und Standardabweichung (s) für Anzahl Trainingstage 2010 und 2020 name n M s training_2010 92 3.01 2.46 training_2020 92 2.79 2.60 2010 haben die Studierenden durchschnittlich an 3.01 Tagen und 2020 an 2.79 Tagen trainiert. Es sieht demnach so aus, dass die Studierenden 2020 im Durchschnitt etwas seltener ins Training gingen, als die Studierenden in 2010. \\(H_0: \\mu_{2020} = \\mu_{2010}\\) \\(H_A: \\mu_{2020} \\neq \\mu_{2010}\\) Der Mittelwert aus 2010 ist in dieser Fragestellung Nullwert (Die Nullhypothese ist gültig wenn \\(\\mu_{2020} - \\mu_{2010 = 0}\\)) \\(H_0: \\mu_{2020} = 3.01\\) \\(H_A: \\mu_{2020} \\neq 3.01\\) Die Berechnung des 95%-Konfidenzintervalls für den Mittelwert aus 2020 ergibt: \\(CI_{95} = \\bar{x} \\pm 1.96 \\times \\frac{s}{\\sqrt{n}}\\) \\(CI_{95} = 2.79 \\pm 1.96 \\times \\frac{2.6}{\\sqrt{92}}\\) ### R-Code nullvalue &lt;- 3.01 m &lt;- 2.79 s &lt;- 2.6 n &lt;- 92 SE &lt;- s/sqrt(n) z &lt;- 1.96 ME &lt;- z * SE ci &lt;- m + c(-1, 1) * ME ci &lt;- round(ci, 2) print(paste(&quot;95%-CI [&quot;, ci[1], &quot;; &quot;, ci[2], &quot;]&quot;, sep = &quot;&quot;)) ## [1] &quot;95%-CI [2.26; 3.32]&quot; Abbildung 5.5: 95%-CI für Trainingstage pro Woche Intepretation: Das 95%-Konfidenzintervall für den Stichprobenmittelwert 2020 ist [2.26; 3.32]. Wir können zu 95% darauf vertrauen, dass die durchschnittliche Anzahl Trainings, welche die Studierenden von 2020 besuchten zwischen 2.26 und 3.32 lag. Dieses Vertrauensintervall beinhaltet den Mittelwert aus der Stichprobe von 2010 (Nullwert). Das heisst, dieser Wert ist auch für die Studierenden von 2020 durchaus plausibel. Es liegt daher keine Evidenz dafür vor, dass \\(H_0\\) verworfen werden kann. Merke: Wenn ein Konfidenzintervall den Nullwert beinhaltet, liegt keine ausreichende Evidenz dafür vor, dass \\(H_0\\) verworfen werden kann. 5.8.3 Entscheidungsfehler Kommen wir noch einmal zurück zum Beispiel am Gericht: Die Aufgabe des Gerichts ist es, ein Urteil über den Angeklagten zu fällen. Auf Grund der Unschuldsvermutung gilt: \\(H_0:\\) Der Angeklagte ist unschuldig. \\(H_A:\\) Der Angeklagte ist schuldig. Die Anklage wird im Laufe des Verfahrens Hinweise auf die Schuld des Angeklagten präsentieren. Sein Verteidiger wird entlastende Argumente vorbringen. Irgendwann kommt dieses Argument- und Gegenargument-Spiel zu Ende und das Gericht muss ein Urteil fällen. Da in vielen Fällen die Fakten nicht ganz eindeutig sind (man nennt das juristisch einen Indizienfall), besteht die Möglichkeit, dass das Gericht zu einem Fehlurteil kommt. Vier verschiedene Urteile sind möglich: H0 nicht verwerfen H0 zugunsten HA verwerfen H0 ist wahr okay Fehler 1. Art HA ist wahr Fehler 2. Art okay Ist der Angeklagte in Wahrheit  unschuldig und wird vom Gericht freigesprochen, ist das Urteil korrekt. schuldig und wird vom Gericht verurteilt, ist das Urteil korrekt. unschuldig, wird aber vom Gericht verurteilt, ist das ein Fehlurteil (Fehler 1. Art). schuldig, wird aber vom Gericht freigesprochen, ist das ein Fehlurteil (Fehler 2. Art). Wie im Gericht müssen in der Statistik Entscheide getroffen werden, auch wenn die Datenlage meist nicht eindeutig ist. Unser Wissen ist immer unsicher, weil wir nie alle Daten haben, und es ist, wie am Gericht, nahezu unvermeidbar, dass wir Fehlentscheide treffen. Fehler 1. Art, \\(\\alpha\\)-Fehler: \\(H_0\\) wird zugunsten \\(H_A\\) verworfen, obwohl \\(H_0\\) wahr ist. Es besteht vermutlich Einigkeit darüber, dass dies ein schwerwiegender Fehler ist. Er bedeutet am Gericht, dass ein Unschuldiger eine Strafe verbüssen muss. In der Medizin kann das bedeuten, dass eine teure Therapie, die in Wirklichkeit völlig nutzlos ist, eine Zulassung erhält und die Gesundheitskosten belastet. Fehler 2. Art, \\(\\beta\\)-Fehler: \\(H_0\\) wird nicht verworfen, obwohl \\(H_A\\) wahr ist. Auch dieser Fehlerentscheid ist unschön, aber wir stimmen Sir William Blackstone vermutlich zu, dass er weniger schwerwiegende Folgen hat, als ein Fehler 1. Art. 5.8.4 Signifkanzniveau Jeder Entscheid birgt das Risiko eines Fehlentscheids. Bei der Erläuterung der Hypothesentests haben wir etwas schwammig formuliert, dass \\(H_0\\) verworfen wird, wenn starke Evidenz für \\(H_A\\) vorliegt. Was aber bedeutet stark? Als Faustregel gilt, dass wir bereit sind, in nicht mehr als 5% der Fälle, bei denen \\(H_0\\) effektiv wahr ist, die Nullhypothese fälschlicherweise zurückzuweisen. Oder anders formuliert: Wir erlauben uns einen Fehler 1. Art bei 5% der Entscheidungen bezüglich \\(H_0\\). Diese (willkürlich) festgelegte Grenze wird als Signifikanzniveau bezeichnet. Oft wird das Signifikanzniveau mit dem griechischen Buchstaben \\(\\alpha\\) angegeben und wir schreiben: \\(\\alpha = 0.05\\). Das Signifikanzniveau, gibt an, wie hoch das Risiko ist, das man bereit ist einzugehen, einen Fehler 1. Art zu begehen. In den meisten Studien im Gesundheitsbereich wird ein Wert für \\(\\alpha=0.05\\) verwendet. Diese Entscheidungsgrenze bei der Entwicklung der Studienmethodik festgelegt und ist gewissermassen willkürlich. Je nach Fragestellung kann auch \\(\\alpha=0.1\\) oder \\(\\alpha=0.01\\) festgelegt werden. Wenn wir bei einem Hypothesentest, bei dem \\(H_0\\) wahr ist, ein 95%-Konfidenzintervall verwenden, können wir einen Entscheidungsfehler begehen, wenn ein Punktschätzer &gt; 1.96 Standardabweichungen vom Mittelwert entfernt ist. Bei \\(\\alpha=0.05\\) passiert uns das in ca. 5% der Fälle (2.5% auf beiden Seiten der Kurve). Abbildung 5.6: Nullhypothese: 5%-Verwerfungsbereich &amp; 95% Annahmebereich Die Kurve in Abbildung 5.6 zeigt die Verteilung der Daten unter \\(H_0\\). Die beiden Flächen am Ende der Kurve ergeben zusammen einen Verwerfungsbereich für \\(H_0\\) von 5%. Der Annahmebereich beträgt 95%. Liegt der Punktschätzer im Verwerfungsbereich (roter Punkt \\(z\\) = -2.2, violetter Punkt \\(z\\) = +3), verwerfen wir die \\(H_0\\) und begehen einen Fehler 1. Art. Liegt der Punktschätzer im Annahmebereich (grüner Punkt) wird \\(H_0\\) nicht verworfen. Abbildung 5.7: Starke Evidenz gegen die Nullhypothese Im abgebildeten Fall (Abb. ?? liegt der Punktschätzer 5 Standardfehler vom Mittelwert der Verteilung unter der Nullhypothese entfernt. Dies bedeutet starke Evidenz gegen \\(H_0\\). Die Wahrscheinlichkeit ist gering, einen Fehler 1. Art zu begehen, wenn \\(H_0\\) in diesem Fall verworfen wird. 5.9 Der p-Wert Der letzte Abschnitt schloss mit der Feststellung, dass wir starke Evidenz gegen die Nullhypothese haben. Aber wie stark ist stark? Hier kommt jetzt der \\(p\\)-Wert ins Spiel, dem wir in fast allen Studien begegnen. Der p-Wert ist eine Möglichkeit, die Stärke der Evidenz gegen die \\(H_0\\) zugunsten der \\(H_A\\) zu quantifizieren. Formell betrachtet ist der \\(p\\)-Wert eine bedingte Wahrscheinlichkeit (p steht als Abkürzung für probability). Der \\(p\\)-Wert gibt die Wahrscheinlichkeit für das Auftreten eines Ereignisses oder eines noch extremeren Ereignisses an, unter der Annahme, dass die Nullhypothese wahr ist. Zu technisch? Dann vielleicht so: Wenn wir einen statistischen Test durchführen, können wir folgende Frage beantworten: Wenn meine Intervention (ein Medikament, eine Behandlung etc.) absolut keinen Effekt hat (Nullhypothese), wie gross ist dann die Wahrscheinlichkeit, dass ich ein bestimmtes Resultat in meiner Studie erhalte? Der \\(p\\)-Wert gibt diese Wahrscheinlichkeit an. Nehmen wir das Beispiel aus der letzten Abbildung: Der beobachtete Stichprobenmittelwert \\(\\bar{x}\\) liegt 5 Standardfehler vom Nullwert (Mittelwert der Verteilung unter der Nullhypothese) entfernt. Wie gross ist die Wahrscheinlichkeit, dass ein solches Ereignis eintritt, wenn die \\(H_0\\) wahr ist? Minus 5 SE bedeutet \\(z\\) = -5. Leider ist es so, dass keine \\(z\\)-Tabelle so extreme \\(z\\)-Werte darstellt, weil solche Werte unter der Nullhypothese sehr unwahrscheinlich sind. Wir können aber mit einer einfachen Funktion in R die Frage beantworten: ### R-Code # die Funktion pnorm(z-Wert) berechnet die Fläche der Normalverteilung # links vom z-Wert. pnorm(-5) ## [1] 2.866516e-07 Interpretation: Die Wahrscheinlichkeit für unser Ereignis ist p = 0.000000029, d.h. 0.0000029%. Zugegeben, das ist sehr unwahrscheinlich und wir können guten Gewissens \\(H_0\\) zugunsten der \\(H_A\\) verwerfen, insbesondere wenn wir \\(\\alpha=0.05\\) als Entscheidungsgrenze definiert haben. Ist der p-Wert kleiner als unser Signifikanzniveau, spricht man in der Statistik von einem signifikanten Ergebnis. Man bringt damit zum Ausdruck, dass das Ergebnis nicht auf purem Zufall bzw. natürlicher Variation beruht, sondern dass ein echter Unterschied zwischen der Population der Nullhypothese (z.B. der Kontrollgruppe) und der beobachteten Population (z.B. der Interventionsgruppe) besteht. Häufige Fehlinterpretationen des \\(p\\)-Werts: Der \\(p\\)-Wert ist nicht die Wahrscheinlichkeit, dass die Nullhypothese stimmt. die Wahrscheinlichkeit, dass die Alternativhypothese falsch ist. die Wahrscheinlichkeit, dass das Ergebnis nur durch Zufall entstanden ist. eine Quantifizierung der (klinischen) Relevanz der Ergebnisse. eine Quantifizierung der Stärke eines Effekts. Zusammenfassung Die Nullhypothese ist Ausdruck einer skeptischen Position; sie geht davon aus, dass es keinen Unterschied gibt. Diese Position wird nur verworfen, wenn ausreichend Evidenz für die Alternativhypothese (= es gibt einen Unterschied) vorliegt. Ein kleiner \\(p\\)-Wert bedeutet, dass eine kleine Wahrscheinlichkeit für das Ergebnis einer Punktschätzung (oder noch ein extremeres Ergebnis) besteht, wenn die Nullhypothese wahr ist. Wir interpretieren das als starke Evidenz zugunsten der Alternativhypothese. Wir verwerfen die Nullhypothese, wenn der \\(p\\)-Wert kleiner als unser Signifikanzniveau \\(\\alpha\\) (üblicherweise 0.05) ist. Andernfalls halten wir die Nullhypothese aufrecht. Wir formulieren die Schlussfolgerung eines Hypothesentests stets so, dass auch Nichtstatistiker:innen diese verstehen können. 5.9.1 Statistische Macht (Power) Statistische Macht (auch Power, Trennschärfe) ist die Wahrscheinlichkeit, dass ein Effekt entdeckt wird, wenn der Effekt auch tatsächlich existiert. Statistische Macht ist definiert als die Wahrscheinlichkeit, korrekterweise eine falsche Nullhypothese zurückzuweisen. Wenn die statistische Power hoch ist, sinkt die Wahrscheinlichkeit, einen Typ-II-Fehler zu begehen oder festzustellen, dass es keinen Effekt gibt, wenn es tatsächlich einen gibt. Damit ist sie gleich 1  \\(\\beta\\), wobei \\(\\beta\\) die Wahrscheinlichkeit ist, einen Fehler 2. Art zu begehen. \\[Power = 1 - \\beta\\] Die statistische Macht \\((1-\\beta)\\) wird grösser  mit wachsender Grösse des wahren Unterschieds oder Effekts: Ein großer Unterschied zwischen zwei Teilpopulationen wird seltener übersehen als ein kleiner Unterschied mit kleiner werdender Merkmalsstreuung \\(\\sigma\\): Dies kann z.B. durch die Unterteilung in homogenere Subpopulationen erreicht werden. mit wachsendem Stichprobenumfang, da der Standardfehler \\(SE\\) kleiner wird. mit grösser werdendem Signifikanzniveau \\(\\alpha\\). Wichtig für die statistische Macht bzw. Power ist auch die Art des statistischen Tests: Parametrische Tests wie zum Beispiel der \\(t\\)-Test haben, falls die Verteilungsannahme stimmt, bei gleichem Stichprobenumfang stets eine höhere Trennschärfe als nichtparametrische Tests. Power-Analysen machen eine Aussage darüber, wie hoch die statistische Macht für ein Studiendesign ist. Sie werden entweder vor der eigentlichen Datenerhebung durchgeführt, um abzuschätzen wie viele Versuchspersonen für die Durchführung der Studie nötig sind, oder nach der eigentlichen Datenerhebung  dann meist aber wenn die Studie keine signifikanten Ergebnisse geliefert hat. In einem solchen Fall kann eine Power-Analyse Aufschluss darüber geben, wie viele Versuchsteilnehmer:innen noch nötig gewesen wären, damit der Effekt doch ein signifikantes Ergebnis geliefert hätte. Beim designen einer Studie, legt man gewöhnlicherweise das Powerniveau genauso fest, wie man es auch mit dem Signifikanzniveau macht. Oft wird eine statistische Power von 80 % gewählt, so dass ein echter Unterschied in 20% der der Fälle nicht erkannt wird. Dies ist, wie oft in der Statistik, ein Kompromiss. Eine Erhöhung der Power auf beispielsweise 90 % würde auch mit einer Erhöhung des Stichprobenumfangs um etwa 30 % einhergehen, bei einer Erhöhung auf 95 % müsste man den Stichprobenumfang sogar um 60 % erhöhen, was in beiden Fällen die Kosten für die Studie erheblich erhöhen würde. 5.10 Einseitige und zweiseitige Hypothesentests 5.10.1 Einseitige Hypothesentests Eine Studie der National Sleep Foundation hat herausgefunden, dass Schüler:innen im Durchschnitt 7 Stunden pro Nacht schlafen. Lehrer:innen an einer lokalen Schule mit über 2000 Schüler:innen waren überzeugt, dass diese im Durchschnitt länger als sieben Stunden schlafen. Ihre Fragestellung lautete: Schlafen Schüler:innen an unserer Schule länger als 7 Stunden? Als erstes formulierten wir die mathematischen Hypothesen: \\(H_0:~\\mu = 7\\), Schüler:innen an dieser Schule schlafen im Durchschnitt 7 Stunden (Nullwert). \\(H_A:~\\mu &gt; 7\\), Schüler:innen an dieser Schule schlafen im Durchschnitt länger als 7 Stunden. Dies ist ein Beispiel für einen einseitigen Hypothesentest. Es interessiert bei dieser Fragestellung nicht, ob Schüler:innen weniger als 7 Stunden schlafen. Die Lehrer:innen zogen eine Zufallsstichprobe von n = 110 Schüler:innen an ihrer Schule und fragten sie nach der üblichen Schlafdauer. Als Signifikanzniveau legten Sie \\(\\alpha=0.05\\) fest. Die Erhebung ergab folgendes Resultat: Tabelle 5.2: Kennzahlen zur Schlafdauer (h) n M s median 110 7.42 1.75 7.04 Abbildung 5.8: Schlafdauer (h) bei 110 Studierenden Bevor das Normalmodell für den Stichprobenmittelwert bei der Berechnung des 95%-Vertrauensintervalls verwendet werden darf, muss überprüft werden, ob die Voraussetzungen erfüllt sind: Da es eine Zufallstichprobe von weniger als 10% der Studierenden ist, sind die Beobachtungen unabhängig. Die Stichprobengrösse ist genügend gross (n &gt; 30). Die Daten sind auf Grund der beiden Ausreisser bei 12 und 15 Stunden linkssteil verteilt. Bei einer Stichprobengrösse von 110 darf dies jedoch vernachlässigt werden. Da die Voraussetzungen weitgehend erfüllt sind, darf angenommen werden, dass die Populationsdaten normalverteilt sind. Prüfung mit dem 95%-Konfidenzintervall: Das 95%-Vertrauensintervall für die durchschnittliche Schlafdauer der Schüler:innen beträgt [7.09; 7.75], d.h. wir können zu 95% darauf vertrauen, dass die durchschnittliche Schlafdauer 7.42 [7.09; 7.75] Stunden beträgt. Der Nullwert von 7 Stunden ist in diesem Vertrauensintervall nicht enthalten und wir verwerfen die \\(H_0\\) zugunsten der \\(H_A\\). Abbildung 5.9: 95%-CI für die Schlafdauer der Schüler:innen, n = 110 Prüfung mit dem p-Wert: Wir überprüfen, ob unsere Daten mit der \\(H_0\\) vereinbar sind. Wir zeichnen die Verteilung unter der Nullhypothese (kann man auch von Hand skizzieren, ist sehr zu empfehlen) und berechnen den \\(z\\)-Wert für den Mittelwert unserer Stichprobe. \\[z = \\frac{\\bar{x} - Nullwert}{SE} = \\frac{7.42 - 7}{0.17} = 2.47\\] Abbildung 5.10: Einseitiger Hypothesentest: Der z-Wert 2.47 liegt im 5%-Verwerfungsbereich (blau) In der Abbildung 5.10 ist der obere 5%-Verwerfungsbereich blau markiert. Wenn \\(H_A\\) einseitig \\(\\mu_1 &gt; \\mu_0\\) formuliert ist und ein Wert in den oberen 5%-Bereich der Verteilung unter der Nullhypothese fällt, entscheiden wir für einen signifikanten Unterschied (auf der Entscheidungsgrundlage \\(\\alpha\\) = 0.05). Den \\(p\\)-Wert für \\(z\\) = 2.47 kann in einer \\(z\\)-Werte-Tabelle abgelesen werden oder - einfacher und genauer - mittels R berechnet werden. ### R-Code pnorm(2.47) ## [1] 0.9932443 Die Fläche unter der Kurve links von unserem Stichprobenmittelwert ist 0.993. Somit ist die verbleibende Fläche 1 - 0.993 = 0.007. ### R-Code 1 - pnorm(2.47) ## [1] 0.006755653 Abbildung 5.11: Einseitiger Hypothesentest: Die Fläche rechts vom z-Wert 2.47 (blau) beträgt 0.7% der Gesamtfläche unter der Kurve Interpretation: Wenn die Nullhypothese wahr ist, dann liegt die Wahrscheinlichkeit für einen Stichprobenmittelwert von 7.42 oder mehr Stunden für eine Stichprobe von 110 Schülerinnen bei nur \\(p\\) = 0.007, bzw. 0.7%. Wenn die Nullhypothese wahr wäre, würden wir ein solches Ergebnis nur sehr selten antreffen. Weil der p-Wert kleiner als das festgelegte Signifikanzniveau \\(\\alpha = 0.05\\) ist, verwerfen wir die Nullhypothese zugunsten der Alternativhypothese und kommen zum Schluss, dass die Schülerinnen an dieser Schule im Durchschnitt länger als 7 Stunden schlafen. 5.10.2 Zweiseitige Hypothesentests In einseitigen Tests interessieren wir uns für den Bereich der Verteilung in der Richtung der Alternativhypothese. Im vorangehenden Beispiel war dies \\(H_A: \\mu &gt; 7\\). Somit liegt unser Verwerfungsbereich rechts vom Mittelwert unter \\(H_0\\). Die Alternativhypothese kann auch in die andere Richtung zeigen \\(H_A: \\mu &lt; 7\\), dann liegt unser Verwerfungsbereich links vom Mittelwert unter \\(H_0\\). Bei zweiseitigen Tests, interessieren uns beide Seiten der Verteilung und die Alternativhypothese ist symmetrisch formuliert \\(H_A: \\mu \\neq 7\\). Diese Formulierung lässt offen, ob unsere der Populationsmittelwert gemäss unserer Stichproben nach oben oder nach unten abweicht. Die Frage lautet dann: Unterscheidet sich unserer Mittelwert von dem der Population \\(H_0\\)? wobei der Mittelwert aus der Stichprobe sowohl kleiner als auch grösser als der Mittelwert unter \\(H_0\\) sein kann. Wie wir gesehen haben, hat die National Sleep Foundation festgestellt, dass Schülerinnen im Durchschnitt 7 Stunden schlafen. Eine andere Forschungsgruppe wollte wissen, ob sich die Schlafdauer der Schülerinnen an ihrer Schule von dieser Norm unterscheidet. Sie formulierten die Hypothesen: \\(H_0: \\mu = 7\\), die durchschnittliche Schlafdauer beträgt 7 Stunden. \\(H_A: \\mu \\neq 7\\), die durchschnittliche Schlafdauer unterscheidet sich von 7 Stunden. Diese zweite Gruppe hat randomisiert 122 Schülerinnen zu ihrer Schlafdauer befragt. Das Ergebnis war, dass die Schülerinnen an dieser Schule im Durchschnitt \\(\\bar{x}=6.83\\) Stunden schlafen (s = 1.8 Stunden). Haben wir damit Evidenz gegen die Nullhypothese (\\(\\alpha = 0.05\\))? Prüfen der Voraussetzungen: (1) Eine Zufallsstichprobe von weniger als 10% der Schülerinnen bedeutet, dass die Beobachtungen unabhängig sind. (2) Der Stichprobenumfang ist grösser als 30. (3) Aufgrund der Überlegungen im letzten Beispiel können wir davon ausgehen, dass der Stichprobenumfang ausreichen gross ist, damit die Stichprobenmittelwerte normal verteilt sind. Den Standardfehler SE berechnen: ### R-Code n &lt;- 122 m &lt;- 6.83 s &lt;- 1.8 SE &lt;- s/sqrt(n) SE ## [1] 0.1629643 Eine Skizze erstellen: Abbildung 5.12: Zweiseitiger Hypothesentest: Der 5%-Verwerfungsbereich (blau) verteilt sich auf die beiden Enden der Verteilung Da wir unsere Alternativhypothese zweiseitig formuliert haben, wird der Verwerfungsbereich auf 2.5% am unteren und 2.5% am oberen Ende der Verteilung aufgeteilt. Die Grenze zu den Verwerfungsbereichen liegt bei z=-1.96 und z=1.96. Berechnung des \\(z\\)-Werts: \\[z = \\frac{6.83 - 7}{0.16} = -1.06\\] Abbildung 5.13: Zweiseitiger Hypothesentest: Der z-Wert für den Stichprobenmittelwert liegt im Nichtverwerfungsbereich Der \\(p\\)-Wert für die linke Fläche bei \\(z\\) = -1.06 ist 0.145. Weil das Normalmodell symmetrisch ist, muss die rechte Hälfte die selbe Fläche haben wie die linke Fläche. Der \\(p\\)-Wert wird daher für die Summe beider Flächen berechnet: ### R-Code linke_flaeche &lt;- pnorm(-1.06) # Fläche &lt;= -1.06 rechte_flaeche &lt;- 1-pnorm(1.06) # Fläche &gt;= 1.06 p &lt;- linke_flaeche + rechte_flaeche p ## [1] 0.2891446 Ein p-Wert von 0.29 ist relativ gross (grösser als \\(\\alpha = 0.05)\\) und wir wir haben keine Evidenz gegen \\(H_0\\). Das heisst, wenn \\(H_0\\) wahr ist, ist es nicht aussergewöhnlich, wenn man einen Mittelwert erhält, der sich so wenig von 7 Stunden unterscheidet. Die Ursache für die geringe Abweichung des Mittelwerts von 7 Stunden kann alleine auf der Variabilität der Stichprobenmittelwerte beruhen. 5.10.3 Einseitige vs. zweiseitige Hypothesentests 5.10.4 Einseitige vs. zweiseitige Hypothesentests Wir bevorzugen grundsätzlich die Verwendung von zweiseitigen Arbeitshypothesen. Warum? Einseitige Hypothesentests verdoppeln das Risiko, einen Fehler 1. Art zu begehen. Es ist unlautere wissenschaftliche Praxis, wenn nach der Datenerhebung eine zweiseitige Alternativhypothese zu einer einseitigen Alternativhypothese geändert wird, mit der Absicht, statistisch signifikante Effekte zu erhalten, weil solche eher publiziert werden als nicht signifikante Resultate. Deshalb müssen die Hypothesen bei der Registrierung von Studien immer vor der Datenerhebung deklariert werden. 5.11 Hypothesentests Schritt für Schritt Notiere die Hypothesen in Umgangssprache. Übersetze sie dann in mathematische Notation. Identifiziere die korrekte Prüfgrösse für die Fragestellung. Prüfe die Voraussetzungen für die Durchführung der Tests (Unabhängigkeit, \\(n\\) &gt; 30, Normalverteilung) Berechne die Kennzahlen und den Standardfehler. Erstelle eine Skizze für die Verteilung unter \\(H_0\\). Markiere die Verwerfungsbereiche. Berechne den \\(z\\)-Wert und den zugehörigen p-Wert. Berechne das 95%-Konfidenzintervall für den Populationsparameter. Schreibe eine Schlussfolgerung in einer Sprache, sie auch für Nichtstatistiker:innen verständlich ist. Vermeide es, nur einen \\(p\\)-Wert ohne Kennzahlen für Punktschätzer und 95%-Konfidenzintervall anzugeben. 5.12 Statistische Signifikanz versus praktische Relevanz Eine Konsequenz des Wurzel-n-Gesetzes ist es, dass es bloss eine Frage des Stichprobenumfangs ist, ob auch kleine Effekte statistisch signifikant werden. Die Aussage, dass ein Ergebnis statistisch signifikant ist, bedeutet nicht, dass es auch von praktischer Bedeutung ist. In den Gesundheitsberufen müssen wir einen Effekt immer in Bezug zur MCID (minimal clinical important difference) setzen, sofern dieser bekannt ist. Beispiel: In einer Studie wird der Effekt einer neuen Behandlung auf das subjektive Schmerzempfinden bei Rückenschmerzpatienten gemessen. Die Intervention ist vielversprechend aber auch wesentlich teurer, als die bisherige Standardbehandlung. Das Studiendesign entspricht einer randomisierten kontrollierten Studie (RCT). Die Kontrollgruppe erhält die bisherige Standardbehandlung, die Interventionsgruppe erhält die neue Behandlung. Gemessen wird der Effekt der Behandlungen auf die subjektiven Schmerzen auf einer VAS-Skala von 0 bis 10. Die Studie kommt zum Schluss, dass die Intervention im Durchschnitt eine signifikante Verbesserung bei der Interventionsgruppe gegenüber der Kontrollgruppe von VAS -1.5 [-1.7 -1.3] mit p &lt; 0.05 ergibt. Auf Grund dieser Ergebnisse stellt sich die Frage, ob die alte Behandlung aufgegeben und durch die neue ersetzt werden muss. Um diese Frage zu beantworten, müssen wir wissen, wie gross der Effekt einer Behandlung sein muss, damit die Patientinnen subjektiv eine Verbesserung ihrer Schmerzen wahrnehmen. Eine Suche in der Literatur ergibt, dass die MCID (minimal clinical important difference) bei einer Reduktion der VAS um -2 liegt. Mit anderen Worten: Die neue Intervention mag zwar eine statistisch signifikante Verbesserung von VAS -1.5 bewirken, für die Patient:innen ist das aber nicht von Bedeutung (nicht klinisch relevant), weil sie subjektiv erst ab einer Reduktion der VAS um -2 einen Effekt und damit eine Verbesserung ihrer Lebensqualität wahrnehmen. Vor allem in Anbetracht der zusätzlichen Kosten der neuen Intervention, besteht keine Evidenz dafür, dass diese die bisherige Standardtherapie ersetzen sollte. "],["korrelation-und-linearer-zusammenhang.html", "6 Korrelation und linearer Zusammenhang 6.1 Einleitung 6.2 Lernziele 6.3 Korrelation 6.4 Zusammenfassung 6.5 Korrelation in R/jamovi", " 6 Korrelation und linearer Zusammenhang 6.1 Einleitung In diesem Kapitel beschäftigen wir uns mit Zusammenhängen zwischen Variablen. Beispiele für Zusammenhänge von Variablen aus dem Alltag sind: Je länger jemand joggt, desto grösser ist sein Kalorienverbrauch. Je weniger Geld ich für die Werbung für meine Firma ausgebe, desto weniger Kunden habe ich. Je höher die Aussentemperatur ist, desto mehr Eis verkaufen die Eisstände. Je öfter es regnet, desto teurer werden die Regenschirmpreise. Je mehr Zeit jemand ins Krafttraining investiert, desto stärker wird er. Je schneller ein Zug fährt, desto kürzer wird die Reisezeit. Je länger der Winter dauert, desto höher werden die Heizkosten. Den linearen Zusammenhang zwischen zwei Variablen bezeichnen wir als Korrelation. Wenn man die Beziehung zwischen zwei Variablen kennt, können wir den Wert der einen Variablen verwenden um den Wert der anderen Variablen vorherzusagen. 6.2 Lernziele Beschreibe die Eigenschaften des Zusammenhangs von zwei Variablen mit folgenden Begriffen Richtung: Ein positiver Zusammenhang besteht dann, wenn sich bei einer Erhöhung von x auch y erhöht; wenn sich bei einer Erniedrigung von x der Wert von y erhöht, sprechen wir von einem negativen Zusammenhang. Form: Ein Zusammenhang ist linear oder nicht-linear Stärke: Ein Zusammenhang ist stark, wenn die Streuung der Daten um die zugrundeliegende Beziehung gering ist und schwach, wenn die Streuung der Daten gross ist. Definiere eine Korrelation als lineare Beziehung zwischen zwei quantitativen Variablen. Beachte, dass der Korrelationskoeffizient \\(r\\) folgende Eigenschaften aufweist: der (absolute) Wert des Korrelationskoeffizienten misst die Stärke der linearen Beziehung zwischen zwei quantitativen Variablen. das Vorzeichen (+ oder -) des Korrelationskoeffizienten beschreibt die Richtung des Zusammenhangs. der Korrelationskoeffizient liegt immer zwischen -1 und 1. -1 bedeutet perfekter negativer linearer Zusammenhang, + 1 bedeutet perfekter positiver linearer Zusammenhang und 0 bedeutet kein linearer Zusammenhang. der Korrelationskoeffizient ist dimensionslos. der Korrelationskoeffizient von X mit Y ist der selbe wie von Y zu X. der Korrelationskoeffizient nach Pearson \\(r\\) ist empfindlich für Ausreisser. Der Rangkorrelationskoeffizient nach Spearman \\(r_s\\) misst den monotonen Zusammenhang und ist robust gegen Ausreisser. Korrelation bedeutet nicht, dass ein ursächlicher Zusammenhang besteht! Correlation does not imply causation! 6.3 Korrelation Eine Korrelation beschreibt eine Beziehung zwischen zwei oder mehreren quantitativen Merkmalen (Variablen). Dabei muss diese Beziehung nicht kausal sein, d.h. die Variablen müssen sich nicht gegenseitig beeinflussen und der Zusammenhang kann völlig zufällig sein. Beispiel: Gibt es einen Zusammenhang zwischen der Laufgeschwindigkeit und dem Kalorienverbrauch pro Stunde? Wir verwenden die Stichprobendaten von \\(n\\) = 11 durchschnittlich 59 kg schweren Läuferinnen: Tabelle 6.1: 11 Läuferinnen km/h kCal/h 8.0 472 8.4 531 9.7 590 10.8 649 11.3 679 12.1 738 12.9 797 13.9 826 14.5 885 16.1 944 17.5 1062 Der Tabelle entnehmen wir, dass mit zunehmender Laufgeschwindigkeit auch der Kalorienverbrauch zunimmt. Zusammenhänge zwischen zwei quantitativen Variablen können gut mit Hilfe eines Streudiagramms (engl. scatterplot) visualisiert werden. Abbildung 6.1: Kalorienverbrauch nach Laufgeschwindigkeit, n = 11 Jeder Punkt im Streudiagramm @rer(fig:running-scatp-fig) repräsentiert eine Kombination von Geschwindigkeit (x-Achse) und Kalorienverbrauch (y-Achse). Wenn wir die Punkte visuell miteinander verbinden, entsteht eine - nicht ganz perfekte - Gerade. In diesem Fall sprechen wir von einem linearen Zusammenhang. 6.3.1 Eigenschaften von Zusammenhängen Die folgenden acht Punktdiagramme zeigen verschiedene Zusammenhänge zwischen der X- und der Y-Variablen. Abbildung 6.2: Zusammenhänge identifizieren Interpretation: Starker nicht-linearer Zusammenhang zwischen X und Y. Perfekter positiver linearer Zusammenhang zwischen X und Y. Starker positiver linearer Zusammenhang zwischen X und Y: Wenn X grösser wird, wird auch Y grösser: positiver Zusammenhang. Die Punkte liegen etwa parallel zu einer gedachten Geraden: linearer Zusammenhang. Die Punkte streuen wenig um eine gedachte Linie: starker Zusammenhang. Schwacher positiver linearer Zusammenhang, die Punkte streuen stark. Moderater Zusammenhang zwischen X und Y, der Zusammenhang ist nicht-linear. Perfekter negativer linearer Zusammenhang. Starker negativer linearer Zusammenhang: Wenn X grösser wird, wird Y kleiner: negativer Zusammenhang Die Punkte liegen nahe bei einer gedachten Gerade: starker linearer Zusammenhang. Kein Zusammenhang zwischen X und Y. 6.3.2 Korrelationskoeffizient \\(r\\) Der Korrelationskoeffizient nach Pearson \\(r\\) ist ein Mass dafür, wie stark der lineare Zusammenhang zwischen zwei Variablen ist. Stehen zwei Variablen miteinander in Zusammenhang, kann man Aussagen darüber treffen, wie sich die Werte der einen Variable verhalten, wenn die Werte der anderen Variable ansteigen oder abfallen. Interpretation von \\(r\\) Der Korrelationskoeffizient \\(r\\) kann Werte zwischen -1 und 1 annehmen. Je näher \\(r\\) bei 1 (bzw. bei -1) liegt, desto stärker ist der Zusammenhang der Variablen. Bei \\(r\\) = 1 liegen alle Punkte der Daten auf einer steigenden Geraden; entsprechend bei -1 auf einer fallenden Geraden. \\(r &gt; 0\\): Ist der Korrelationskoeffizient grösser als null, liegt eine positive Korrelation vor: Je grösser die Werte der einen Variablen, desto grösser sind die Werte der anderen Variablen. \\(r &lt; 0\\): Ist der Korrelationskoeffizient kleiner als null, liegt eine negative Korrelation vor: Je grösser die Werte der einen Variablen, desto kleiner sind die Werte der anderen Variablen. \\(r \\approx 0\\): Liegt der Korrelationskoeffizient nahe 0, gibt es keinen linearen Zusammenhang zwischen den Variablen. Es ist keine Aussage darüber möglich, wie sich die Werte der einen Variablen verändern, wenn die Werte der anderen Variablen steigen oder sinken. Beachte, dass der Korrelationskoeffizient nur lineare Zusammenhänge abbildet. Es kann sein, dass die Variablen zusammenhängen, nur eben nicht linear, z.B. quadratisch oder exponentiell. Ein Korrelationskoeffizient nahe bei 0 bedeutet daher nicht, dass überhaupt kein Zusammenhang besteht. Es bedeutet nur, dass kein linearer Zusammenhang besteht. Als Faustregel für die Beurteilung der Stärke einer Korrelation kann man sich an folgender Tabelle orientieren: Korrelation Stärke Richtung -1.0 to -0.8 stark Negativ -0.8 to -0.5 moderat Negativ -0.5 to 0 schwach Negativ 0 to 0.5 schwach Positiv 0.5 to 0.8 moderat Positiv 0.8 to 1.0 stark Positiv 6.3.3 Berechnung von \\(r\\) Die Details zur Berechnung des Korrelationskoeffizienten ersparen wir uns. Das übernimmt die Statistiksoftware. Die Funktion in R (R Core Team 2021) für die Berechnung des Korrelationskoeffizienten ist ### R-Code cor(x, y) # Korrelationskoeffizient nach Pearson 6.3.4 Hypothesentest für \\(r\\) Auch für den Korrelationskoeffizienten exisitiert ein Hypothesentest. Wie bei jedem Hypothesentest wird auch hier aus Stichprobendaten auf die Population, aus der die Stichprobe stammt, geschlossen. Für den Korrelationskoeffizienten nach Pearson \\(r\\) lauten die Hypothesen: \\(H_0: \\rho = 0\\) Es besteht kein linearer Zusammenhang zwischen zwei Variablen. \\(H_A: \\rho \\neq 0\\) Es besteht ein linearer Zusammenhnag zwischen zwei Variablen. \\(\\rho\\) (gr. Rho) ist der Korrelationskoeffizient auf Populationsebene. Die Funktion in R für diesen Hypothesentest ist ### R-Code cor.test(x, y) 6.3.5 Interpretation des Beispiels für Laufgeschwindigkeit und Kalorienverbrauch Abbildung 6.3: Zusammenhang von Kalorienverbrauch und Laufgeschwindigkeit Wir sehen, dass eine sehr starke positive lineare Korrelation zwischen der Laufgeschwindigkeit und dem Kalorienverbrauch besteht. Der Korrelationskoeffizient nach Pearson \\(r\\) ist 0.997. ### R-Code cor.test(running$kmh, running$kg59) ## ## Pearson&#39;s product-moment correlation ## ## data: running$kmh and running$kg59 ## t = 37.892, df = 9, p-value = 3.082e-11 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.9875851 0.9992189 ## sample estimates: ## cor ## 0.9968805 Der Hypothesentest in Rergibt einen p-Wert von \\(3.082 \\times 10^{-11}\\). Dies ist ein extrem kleiner p-Wert, der unter dem üblichen Signifikanzniveau von \\(\\alpha = 0.05\\) liegt. Wir schliessen daraus, dass wir die Nullhypothese zugunsten der Alternativhypothese verwerfen können und dass ein statistisch signifikanter Zusammenhang zwischen Laufgeschwindigkeit und Kalorienverbrauch besteht. Die Stichprobendaten liefern Evidenz dafür, dass ein nahezu perfekter positiver linearer Zusammenhang zwischen Laufgeschwindigkeit und Kalorienverbrauch in der Population (59kg schwere Frauen) besteht, \\(r\\) = 0.997 [0.988; 0.999], p &lt; 0.001. 6.3.6 Datenmuster und \\(r\\) Korrelationskoeffizienten sind unter Forscher:innen beliebt, weil sie den Zusammenhang zwischen zwei Variablen in einer einzigen Zahl zusammenfassen. Allerdings kann ein bestimmter Korrelationskoeffizient eine Vielzahl von Mustern zwischen zwei Variablen repräsentieren und ohne zusätzliche Information - idealerweise in Form eines Streudiagramms - wissen weder die Forscher:innen noch die Leser:innen, um welche Art von Zusammenhang es sich handelt. Die folgenden 16 Streudiagramme zeigen, was sich alles hinter einem Korrelationskoeffizienten von \\(r = 0.8\\) (n = 50) verbergen kann. (Quelle und Erläuterungen: https://janhove.github.io/teaching/2016/11/21/what-correlations-look-like) Abbildung 6.4: 16 Varianten von Zusammenhängen, alle \\(r\\) = 0.8 Ohne im einzelnen auf die Streudiagramme in Abbildung 6.4 einzugehen, ist leicht zu erkennen, dass ganz unterschiedliche Muster des Zusammenhangs zwischen zwei Variablen mit dem gleichen Korrelationskoeffizienten \\(r\\) vorhanden sein können. Betrachten wir das Beispiel 12 aus der Abbildung 6.4 etwas genauer: Abbildung 6.5: Einfluss eines Ausreissers auf \\(r\\) Wir sehen links zwischen x = -2 und x = 2.8 eine Punktewolke, die einen starken positiven linearen Zusammenhang zwischen x und y zeigt. Bei x = 10, y = 6.2 befindet sich ein Ausreisser. Der Korrelationskoeffizient für alle Daten beträgt \\(r = 0.8\\). Wenn wir den Ausreisser entfernen, erhöht sich der Korrelationskoeffizient auf \\(r = 0.925\\), was vermutlich eher dem wahren Zusammenhang zwischen den Variablen entspricht. Unsere Schlussfolgerung: Der Korrelationskoeffizient nach Pearson \\(r\\) ist empfindlich für Ausreisser! 6.3.7 Rangkorrelationskoeffizient nach Spearman Der Rangkorrelationskoeffizient nach Spearman \\(r_s\\) ist ähnlich wie der Korrelationskoeffizient nach Pearson \\(r\\) eine Methode, um Zusammenhänge zwischen Variablen zu quantifizieren. Dabei handelt es sich um einen nicht-parametrischen Test, bei dem die Korrelation anhand zuvor vergebener Ränge berechnet wird. Der Vorteil des Rangkorrelationskoeffizienten nach Spearman ist, dass er robust gegen Ausreisser ist und - in gewissem Umfang - auch nicht-lineare Zusammenhänge beschreiben kann. Die Interpretation von \\(r_S\\) ist genau gleich, wie für \\(r\\). Der Rangkorrelationskoeffizient nach Spearman \\(r_s\\) quantifiziert den monotonen Zusammenhang der Variablen und nicht den linearen Zusammenhang. Monotoner Zusammenhang bedeutet, wenn X steigt, steigt Y in der Tendenz auch bzw. wenn X steigt, sinkt Y in der Tendenz. Abbildung 6.6: Zwei perfekte monotone Zusammenhänge Die Funktion in R für die Berechnung von \\(r_S\\) ist ### R-Code cor(x, y, method = &quot;spearman&quot;) Die Berechnung von \\(r_s\\) für das Beispiel 12 (alle Daten inkl. Ausreisser) ergibt \\(r_S = 0.938\\). Der Wert von \\(r_s\\) liegt nahe am Wert für \\(r = 0.925\\) für die Daten ohne den Ausreisser. 6.3.8 Scheinkorrelationen Das folgende Beispiel soll zeigen, dass bei der Interpretation von Korrelationen Vorsicht geboten ist. Frage: Besteht ein Zusammenhang zwischen der Schuhgrösse und dem Einkommen? Wir überprüfen diese Frage anhand der Angaben einer Stichprobe von \\(n\\) = 1000. Die Proband:innen wurden nach ihrer Schuhgrösse (nur ganze Grössen) und ihrem monatlichen Bruttoeinkommen befragt. Abbildung 6.7: Einkommen nach Schuhgrösse, n = 1000 Die Analyse ergibt einen moderaten positiven linearen Zusammenhang zwischen der Schuhgrösse und dem monatlichen Einkommen; mit zunehmender Schuhgrösse nimmt auch das monatliche Bruttoeinkommen zu (\\(r\\) = 0.609, p &lt; 0.001). Aber ist diese Schlussfolgerung auch korrekt oder haben wir etwas übersehen? Die Analyse der Daten nach Geschlecht getrennt ergibt folgendes Resultat: Abbildung 6.8: Einkommen nach Schuhgrösse Wenn wir die Daten nach Geschlecht getrennt analysieren, verschwindet der Effekt vollständig. Wir haben keine Evidenz mehr dafür, dass ein Zusammenhang zwischen Schuhgrösse und Einkommen besteht (Frauen \\(r\\) = -0.061, p = 0.179; Männer \\(r\\) = -0.009, p = 0.839). Wie können wir dieses Ergebnis interpretieren? Männer haben typischerweise eine grössere Schuhgrösse als Frauen. Zudem haben Männer im Durchschnitt - nach wie vor - ein höheres Einkommen als Frauen. Es ist demnach das Geschlecht, das einen Einfluss auf das Einkommen hat, denn wir wissen intuitiv, dass die Schuhgrösse definitiv nichts mit dem Einkommen zu tun haben kann. In diesem Fall sprechen wir von einer Scheinkorrelation, die einen Zusammenhang feststellt, wo - zumindest kausal - keiner vorhanden ist. Das Geschlecht ist im vorliegenden Fall ein Störfaktor (engl. confounder), der sowohl das Einkommen als auch die Schuhgrösse bestimmt. Unter Confounding versteht man eine systematische Verzerrung, hervorgerufen durch einen oder mehrere Störfaktoren, die mit beiden Variablen zusammenhängen und bei der Untersuchung nicht berücksichtigt werden. Weitere Beispiele für Scheinkorrelationen findet man in diesem Video unter diesem Link. 6.4 Zusammenfassung Pearsons Korrelationskoeffizient ist für viele Dinge nützlich, hat aber den Nachteil, dass er nur die Stärke einer linearen Korrelation zwischen zwei Variablen messen kann. Mit anderen Worten misst er, in welchem Mass die Daten auf eine perfekte gerade Linie fallen. Er ist empfindlich gegenüber Ausreissern. Für Variablen, deren Zusammenhang nicht linear ist (was man am besten an einem Streudiagramm beurteilt), eignet sich der Rangkorrelationskoeffizient nach Spearman besser. Er ist in der Lage, nicht-lineare Zusammenhänge zu messen und er ist robust gegen Ausreisser. Aus den 16 Grafiken haben wir gelernt, dass ein Zusammenhang zwischen zwei Variablen immer zuerst visuell am Streudiagramm und erst in zweiter Linie anhand des Korrelationskoeffizienten beurteilt werden muss! 6.5 Korrelation in R/jamovi 6.5.1 R Code und Output Pearsonss Korrelationskoeffizient ### R-Code # Simulierte Daten x &lt;- c(-2, -1.5, -.5, 0, 1, 3, 4) y &lt;- c(5, 4.5, 6, 5.5, 6, 6.5, 7.5) # Streudiagramm erstellen plot(x, y) # Pearson&#39;s Korrelationskoeffizient cor(x, y) ## [1] 0.9262154 # Hypothesentest für Pearson&#39;s Korrelationskoeffizient cor.test(x, y) ## ## Pearson&#39;s product-moment correlation ## ## data: x and y ## t = 5.4937, df = 5, p-value = 0.002729 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.5724094 0.9892662 ## sample estimates: ## cor ## 0.9262154 Rangkorrelationskoeffizient nach Spearman ### R-Code # Simulierte Daten x &lt;- c(-2, -1.5, -.5, 0, 1, 3, 4) y &lt;- c(5, 4.5, 6, 5.5, 6, 6.5, 7.5) # Streudiagramm erstellen plot(x, y) # Rangkorrelationskoeffizient nach Spearman cor(x, y, method = &quot;spearman&quot;) ## [1] 0.9009375 # Hypothesentest für Rangkorrelationskoeffizienten nach Spearman cor.test(x, y, method = &quot;spearman&quot;) ## ## Spearman&#39;s rank correlation rho ## ## data: x and y ## S = 5.5475, p-value = 0.005621 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.9009375 6.5.2 jamovi Output jamovi\\..\\Regression\\Correlation Matrix Pearsons Korrelationskoeffizient Im Menü unter Additional Options &gt; Report significance und Confidence intervals wählen. jamovi-Output Pearson Rangkorrelationskoeffizient nach Spearman Im Menü unter Correlation Coefficients &gt; Spearman und unter Additional Options &gt; Report significance wählen. Es kann kein Vertrauensintervall für \\(r_s\\) berechnet werden. jamovi-Output Spearman References "],["einfache-lineare-regression.html", "7 Einfache lineare Regression 7.1 Lernziele 7.2 Eine Bücherbestellung 7.3 Unabhängige und abhängige Variable 7.4 Einfache lineare Regression 7.5 Einfache lineare Regression in R/jamovi 7.6 Voraussetzungen für die Gültigkeit des linearen Modells", " 7 Einfache lineare Regression Hat man einen linearen Zusammenhang zwischen zwei Variablen entdeckt, möchte man diesen Zusammenhang präzise beschreiben und quantifizieren. Das Ziel der Regressionsanalyse ist es, die Gerade anzugeben, die den linearen Zusammenhang am besten beschreibt. Im Unterschied zur Korrelation wird hier ein gerichteter Zusammenhang untersucht. Wir möchten eine Variable y, in unserem Beispiel der Kalorienverbrauch, durch eine Variable x, die Laufgeschwindigkeit vorhersagen. 7.1 Lernziele Definiere die erklärende Variable als unabhängige Variable (Prädiktor) und die Antwortvariable als abhängige Variable. Erstelle Streudiagramme so, dass die unabhängige Variable auf der x-Achse und die abhängige Variable auf der y-Achse liegt. Wenn x die unabhängige und y die abhängige Variable ist, wird das lineare Regressionsmodell gebildet als \\[y = \\beta_0 + \\beta_1x\\] wobei \\(\\beta_0\\) den Schnittpunkt mit der y-Achse (Achsenabschnitt, engl. intercept) und \\(\\beta_1\\) die Steigung der Geraden beschreibt. Die Punktschätzungen (aus den beobachteten Daten) für \\(\\beta_0\\) und \\(\\beta_1\\) sind \\(b_0\\) bzw. \\(b_1\\). Definiere Residuen \\(e\\) als Differenz zwischen den beobachteten \\(y\\) und den durch das Modell vorhergesagten \\(\\hat{y}\\) Werten der abhängigen Variablen. Definiere die Kleinstquadratlinie (Regressionsgerade) als die Linie, welche die Summe der quadrierten Residuen minimiert. Du kannst die Bedingungen dafür nennen, dass die Kleinstquadratlinie gültig ist: Linearität Normalverteilung der Residuen Konstante Variabilität (Homoskedastizität) Interpretiere die Steigung \\(b_1\\) wie folgt Für jede Einheit um die sich der Wert x erhöht erwarten wir, dass y im Durchschnitt um \\(|b_1|\\) Einheiten grösser bzw. kleiner wird. Beachte dass es vom Vorzeichen von \\(b_1\\) abhängig ist, ob der Wert der abhängigen Variable zu- oder abnimmt. Beachte, dass die Kleinstquadratlinie stets durch den Mittelwert der abhängigen \\(\\bar{y}\\) und der unabhängigen Variable \\(\\bar{x}\\) verläuft. Interpretiere \\(b_0\\) (intercept) folgendermassen: Wenn x = 0, erwarten wir dass y im Durchschnitt den Wert von \\(b_0\\) annimmt. Berechne den Wert der abhängigen Variablen für einen bestimmten Wert der unabhängigen Variablen, \\(x^*\\), durch Einsetzen von \\(x^*\\) in das lineare Modell: \\[\\hat{y} = b_0 + b_1x^*\\] Verwende nur Werte für \\(x^*\\), die in der Variationsbreite der beobachteten Daten liegen. Extrapoliere nicht über die Variationsbreite hinaus, ausser du bist dir sicher, dass das lineare Muster darüber hinaus gültig ist. Definiere das Bestimmtheitmass \\(R^2\\) als prozentualer Anteil der Variabilität der abhängigen Variablen, der durch die unabhängige Variable erklärt wird. Für ein gutes Modell erwarten wir, dass dieser Wert nahe bei 1 (100%) liegt. Das Bestimmtheitsmass wird berechnet als das Quadrat des Korrelationskoeffizienten nach Pearson: \\(R^2 = r^2\\) Entscheide anhand des Outputs im Statistikprogramm (t-Wert und p-Wert), ob die unabhängige Variable ein signifikanter Prädiktor für die abhängige Variable ist. 7.2 Eine Bücherbestellung Ein Buchhändler muss jeweils einen Monat bevor das Semester beginnt die Statistik-Bücher für die Studierenden im Statistik-Kurs bestellen. Er geht davon aus, dass die Anzahl Statistik-Bücher, die er in diesem Semester verkaufen wird, davon abhängt, wieviele Studierende für den Statistik-Kurs angemeldet sind. Aus den vergangenen 12 Semestern besitzt der Buchhändler die Listen mit der Anzahl der eingeschriebenen Studierenden und mit der Anzahl der pro Semester verkauften Bücher. Tabelle 7.1: Buchhandlung Semester Studierende Buecher 1 36 32 2 28 29 3 35 34 4 39 35 5 30 29 6 30 30 7 31 30 8 38 38 9 36 34 10 38 33 11 29 29 12 26 26 Für das kommende Semester haben sich 33 Studierende für den Statistikkurs angemeldet. Um möglichst nicht zu viele oder zu wenige Bücher zu bestellen, bittet er uns um Hilfe. 7.3 Unabhängige und abhängige Variable Im vorliegenden Fall können wir davon ausgehen, dass ein kausaler Zusammenhang zwischen der Anzahl der Studierenden und der Anzahl der verkauften Bücher vorliegt: Der Wert der Variablen Studierende erlaubt eine Vorhersage über den Wert der Variablen Buecher oder m.a.W. der Wert der Variablen Buecher hängt vom Wert der Variablen Studierendeab. Damit können wir die Variable Buecherals abhängige Variable und die Variable Studierende als unabhängige Variable bzw. als Prädiktor bezeichnen. 7.3.1 Zusammenhang zwischen den Variablen Wie bereits gewohnt, formulieren wir zuerst die Hypothesen: \\(H_0: \\rho = 0\\) Es gibt keinen Zusammenhang zwischen der Anzahl Studierender und der verkauften Anzahl Bücher. \\(H_A: \\rho \\neq 0\\) Es gibt einen Zusammenhang zwischen der Anzahl Studierender und der verkauften Anzahl Bücher. Als nächstes erstellen wir ein Streudiagramm: Wenn ein kausaler Zusammenhang vermutet wird, wird die unabhängige Variable auf der x-Achse und die abhängige Variable auf der y-Achse dargestellt. Abbildung 7.1: Zusammenhang Anzahl verkaufte Bücher und Anzahl Studierende Die Daten zeigen einen moderaten bis starken positiven linearen Zusammenhang zwischen der abhängigen und der unabhängigen Variablen. Mit der Berechnung des Korrelationskoeffizienten können wir die Stärke des Zusammenhangs quantifizieren (das Signifikanzniveau legen wir auf \\(\\alpha = 0.05\\) fest): ### R-Code cor.test(bookstore$Studierende, bookstore$Buecher) ## ## Pearson&#39;s product-moment correlation ## ## data: bookstore$Studierende and bookstore$Buecher ## t = 7.3326, df = 10, p-value = 2.504e-05 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7279819 0.9771876 ## sample estimates: ## cor ## 0.9182485 Die Daten liefern Evidenz für einen signifikanten, starken, positiven und linearen Zusammenhang zwischen der Anzahl an Studierenden und der Anzahl verkaufter Bücher (\\(r\\) = 0.918, p &lt; 0.001) 7.4 Einfache lineare Regression Mit der Korrelation konnten wir die Annahme eines Zusammenhangs zwischen Anzahl Studierender und der Anzahl verkaufter Bücher bestätigen. Die Frage ist allerdings nicht beantwortet, wieviele Bücher der Buchhändler für dieses Semester, an dem 33 Studierende für den Statistik-Kurs eingeschrieben sind, bestellen muss. Es wäre ideal, wenn wir auf Grundlage der vorliegenden Daten ein funktionelles Modell erstellen könnten, das uns bei der Schätzung der Anzahl Bücher helfen würde. Die Regressionsanalyse liefert das Werkzeug dafür: Sie liefert uns ein Modell - nämlich eine Gerade und die zugehörige Gleichung - welches unsere Daten so gut wie möglich beschreibt. Im vorliegenden Fall hilft uns die Gleichung vorherzusagen, wieviele Bücher wir für jede zusätzliche Studierende verkaufen werden. 7.4.1 Die Regressionsgerade 7.4.1.1 Kurzes Repe Mathematik - Lineare Funktion: Gerade Eine lineare Funktion kann grafisch durch eine Gerade dargestellt werden. Die allgemeine Formel für eine Gerade im zweidimensionalen Koordinatensystem lautet: \\(y = ax + b\\). \\(a\\) = Steigung: Um wieviel steigt y, wenn x um 1 Einheit grösser wird? \\(b\\) = Achsenabschnitt: Wo schneidet die Gerade die y-Achse wenn x = 0? Abbildung 7.2: Geradengleichung Wir sehen, dass wenn x um eine Einheit zunimmt (\\(\\Delta x\\)), nimmt y um zwei Einheiten zu (\\(\\Delta y\\)), d.h. \\[a = \\frac{\\Delta y}{\\Delta x} = \\frac{2}{1} = 2\\] Wenn x = 0 ist y = 4, d.h. \\(b = 4\\). Unsere Geradengleichung lautet somit: \\[y = 2x + 4\\] 7.4.2 Lineares Modell Lineare Regression ist die statistische Methode, eine Gerade für zwei Variablen X und Y zu konstruieren, wenn die Beziehung dieser beiden Variablen einigermassen linear ist, also durch eine Gerade beschrieben werden kann. Die Gerade dient als Modell und wird so konstruiert, dass sie die Daten möglichst passend beschreibt. Die allgemeine Formel für ein lineares Modell lautet: \\[y = \\beta_0 + \\beta_1x\\] \\(\\beta_0\\) und \\(beta_1\\) sind die Parameter des Modells. Diese werden in der Regel mit Stichprobendaten geschätzt und wir schreiben wir die Formel als \\[y = b_0 + b_1x\\] \\(b_0\\) Achsenabschnitt, gibt den Wert für y an, wenn x = 0 (in Statistikprogrammen als intercept bezeichnet). \\(b_1\\) gibt die Steigung der Geraden an. 7.4.3 Die Kleinst-Quadrat-Linie Leider ist es in Wirklichkeit selten so, dass die Daten so genau einem linearen Modell entsprechen und es stellt sich die Frage, auf welche Weise eine Gerade konstruiert werden kann, welche die Daten zwar nicht perfekt, aber doch möglichst genau modelliert. Betrachten wir noch einmal das Streudiagramm unseres Buchhändlers: Wie würden Sie die Gerade einzeichnen, welche die Daten am ehesten repräsentieren? Welche der vorgeschlagenen Geraden würden Sie als das am besten zutreffende Modell wählen? Abbildung 7.3: Welche Gerade ist ein optimales Modell? Die Gerade beschreibt keinen linearen Zusammenhang. Die Gerade beschreibt keinen linearen Zusammenhang. Mögliches Modell, allerdings liegen mehr Punkte über als unter der Geraden. Mögliches Modell, allerdings liegen mehr Punkte unter als über der Geraden. Optimales Modell Die Gerade beschreibt einen negativen linearen Zusammenhang, das ist Unsinn. Die Abbildung zeigt die Gerade (e), die den funktionalen Zusammenhang zwischen Studierenden und verkauften Büchern modelliert. Die blauen Punkte sind die Anzahl effektiv verkaufter Bücher pro Studierendenanzahl und die roten Punkte sind die Anzahl der Bücher, die unser Modell vorhersagt. Die roten Punkte sind die vom Modell berechneten Werte (fitted values) und wir sehen, dass die Gerade die meisten blauen Punkte verfehlt. Die senkrechten Linien zwischen den gemessenen Werten (blau) und den gefitteten Werten (rot) bezeichnen wir als Residuen. Definition Residuum: Senkrechte Differenz zwischen dem Modell vorhergesagten Wert \\(\\hat{y}\\) (gefitteter Wert) und dem tatsächlich beobachteten Wert \\(y\\). Das Residuum \\(e_i\\) der i-ten Beobachtung ist die Differenz zwischen dem beobachteten Wert \\(y_i\\) und dem vom Modell vorhergesagten Wert \\(\\hat{y_i}\\). \\[e_i = y_i-\\hat{y_i}\\] \\(\\hat{y_i}\\) berechnen wir durch Einsetzen von \\(x_i\\) in die Regressionsgleichung. Nun stellt sich die Frage: Was ist ein objektives Mass um die beste Gerade zu finden? Aus mathematischer Sicht möchten wir eine Linie, die möglichst kleine Residuen ergibt. Die erste Option ist, eine Linie zu finden, bei der die Summe der Absolutwerte der Residuen minimal ist: \\[|e_1| + |e_2| + ... + |e_n|=minimal\\] Dies wäre eine durchaus eine Möglichkeit, die üblichere Praxis ist allerdings, dass eine Gerade berechnet wird, bei der die Summe der quadrierten Residuen minimal ist (sog. Kleinst-Quadrat-Methode): \\[e_1^2 + e_2^2 + ... + e_n^2 = minimal\\] Vorteile der Kleinst-Quadrat-Methode Es ist die übliche Methode. Jede Statistiksoftware berechnet die Regressionsgerade standardmässig mit dieser Methode. Durch das Quadrieren erhalten grosse Abweichungen ein stärkeres Gewicht als kleine Abweichungen; diese Methode bestraft das Modell, wenn grosse Abweichungen vorkommen. Die ersten beiden Gründe sind reine Konvention, der letzte Grund rechtfertigt die Methode jedoch aus mathematischer Sicht. Abbildung 7.4: Universitäre Unterstützung nach Familieneinkommen Die Grafik zeigt die universitäre Unterstützung in Abhängigkeit vom Familieneinkommen (Quelle Çetinkaya-Rundel et al. 2021). Die gestrichelte Linie wurde mit der Methode der Summe der Absolutwerte der Residuen und die ausgezogene Linie mit der Kleinst-Quadrat-Methode berechnet. Beide Varianten würden ein plausibles Modell ergeben, aber die Kleinst-Quadrat-Methode hat sich als Standard etabliert. Die Berechnung der Geradengleichung überlassen wir i.d.R. R. Hier die Formeln für die Berechnung von Hand für die einfache lineare Regression: Berechnung der Steigung \\[\\beta_1 = \\frac{s_y}{s_x}r\\] wobei \\(s_y\\) die Standardabweichung von \\(y\\), \\(s_x\\) die Standardabweichung von \\(y\\) und \\(r\\) der Korrelationskoeffizient nach Pearson ist. Berechnung des Achsenabschnitts \\[\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}\\] wobei \\(\\bar{y}\\) der Mittelwert von \\(y\\) und \\(\\bar{x}\\) der Mittelwert von \\(x\\) ist. in R benutzen wir die Funktion lm(): ### R-Code lm_bookstore &lt;- lm(Buecher ~ Studierende, data = bookstore) summary(lm_bookstore) ## ## Call: ## lm(formula = Buecher ~ Studierende, data = bookstore) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.01515 -0.72083 -0.02424 0.56894 2.98485 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.9333 3.1148 2.868 0.0167 * ## Studierende 0.6864 0.0936 7.333 2.5e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.388 on 10 degrees of freedom ## Multiple R-squared: 0.8432, Adjusted R-squared: 0.8275 ## F-statistic: 53.77 on 1 and 10 DF, p-value: 2.504e-05 Für unser Beispiel berechnet R für die Koeffizienten \\(\\beta_0\\) = 8.93 (Intercept) \\(\\beta_1\\) = 0.69 eingesetzt in die lineare Gleichung resultiert \\[\\widehat{Buecher} = 8.93 + 0.69 \\times Studierende\\] Interpretation \\(\\beta_0\\) Achsenabschnitt: wenn keine Studierenden den Statistikkurs belegen (x = 0) \\(\\beta_1\\) Steigung: Pro zusätzliche Studierende steigt der Buchverkauf um 0.69 Bücher. Unser Modell ermöglicht uns, eine Vorhersage zu machen für Werte, die wir so bisher noch gar nicht beobachtet haben. Wir können jetzt die Anzahl Bücher schätzen, die der Buchhändler im nächsten Semester, in dem 33 Studierende eingeschrieben sind, verkaufen wird, indem wir die Zahl 33 für x einsetzen. \\[\\widehat{Buecher} = 8.93 + 0.69 \\times 33 = 31.7\\] Unser Modell sagt voraus, dass der Buchhändler 32 (31.7) Statistikbücher im nächsten Semester verkaufen wird. Abbildung 7.5: Buchhandlung: Vorhersage für 33 Stud. 7.4.4 Warum man nicht über die gemessenen Daten hinaus extrapolieren sollte Die Regressionsgleichung ist nur für den gemessenen Datenbereich gültig. Was dabei herauskommt, wenn man die Vorhersage über den gemessenen Datenbereich hinaus extrapoliert zeigt das folgende Beispiel. Im September 2004 publizierte das Magazin Nature einen Artikel, in dem die Entwicklung der olympischen Siegerzeiten über 100m Sprint zwischen Männern und Frauen seit 1900 verglichen wurden. Die Autoren machten die Vorhersage, dass im Jahre 2156 die Frauen die 100m-Distanz schneller laufen werden als die Männer. Abbildung 7.6: Olympische Zeit für 100m-Sprint Die Steigung bei den Frauen ist etwas stärker negativ als bei den Männern (\\(\\beta_{1, f}\\) = -0.02, \\(beta_{1,m}\\) = -0.01). Das heisst, dass die Frauen in den Jahren 1928 bis 2004 ihre Geschwindigkeit schneller steigern konnten als die Männer: Frauen wurden im Durchschnitt pro Jahr um 0.02 Sekunden schneller, Männer um 0.01 Sekunden. Abbildung 7.7: Zeit für 100m-Sprint Frauen extrapoliert Die Autoren des Artikels haben nun berechnet, wie sich die Laufzeiten in Zukunft entwickeln werden. Extrapoliert man die Regressionsgleichung der olympischen Zeiten für 100m-Sprint über den Messzeitraum hinaus, überschneiden sich die Regressionsgeraden im Jahr 2156. Ab dann überholen die Frauen die Männer! Man kann die Extrapolation jedoch noch weiter treiben: Wenn die Regressionsgleichung über den Messzeitraum hinaus gültig wäre, würden Frauen ab dem Jahr 2637 weniger als 0 Sekunden für den 100m-Lauf benötigen und in der Zeit zurück reisen! Abbildung 7.8: Zeit für 100m-Sprint Frauen bis ins Jahr 2800 extrapoliert Wir lernen daraus, dass die Regressionsgerade immer nur für den effektiv gemessenen Datenbereich gültig ist. 7.4.5 Das Bestimmtheitsmass \\(R^2\\) Das Bestimmtheitsmass \\(R^2\\)  sagt uns, wieviel Prozent der Streuung der abhängigen Variable y durch die unabhängige Variable x erklärt wird. Anders formuliert: Wieviel Prozent der Änderung in y von einem Datenpunkt zum anderen durch x erklärbar ist. kann Werte zwischen 0 und 1 annehmen (0 bis 100%). ist bei der einfachen linearen Regression das Quadrat des Korrelationskoeffizienten nach Pearson: \\(R^2 = r^2\\). ist umso grösser, je geringer Daten um die Regressionsgerade streuen. Eine Variable y kann folglich umso besser durch die Variable x erklärt werden, je größer die Korrelation \\(r\\) zwischen beiden Variablen dem Betrag nach ist. Anders formuliert: Je größer \\(R^2\\) ist, desto besser ist die Anpassung der Regressionsgeraden an die Daten. 7.5 Einfache lineare Regression in R/jamovi 7.5.1 R Modell erstellen und Output interpretieren Zur Erläuterung des R-Outputs verwenden wir die Fragestellung aus der Buchhandlung. Es werden nur die wichtigsten Angaben erläutert. Eine detaillierte Beschreibung des Outputs findet man z.B. hier R Output Einfaches lineares Modell Erläuterung zum Nullhypothesentest für die Koeffizienten Es interessiert die Frage, ob die Steigung von 0 verschieden ist (Steigung = 0 bedeutet kein Zusammenhang). Die Hypothesen zu dieser Frage sind: \\(H_0: \\beta_1 = 0\\) \\(H_A: \\beta_1 \\neq 0\\) Das Statistikprogramm führt immer einen t-Test für eine einfache Stichprobe durch und ermittelt den \\(t\\)-Wert und den \\(p\\)-Wert für die Koeffizienten. Ist der \\(p\\)-Wert kleiner als das Signifikanzniveau, das meist auf \\(\\alpha\\) &lt; 0.05 festgelegt wird, liegt Evidenz dafür vor, dass die Nullhypothese, dass kein Zusammenhang zwischen abhängiger und unabhängiger Variable vorlieg, verworfen werden kann. Meist interessiert nur der \\(p\\)-Wert für die Steigung \\(b_1\\). Im vorliegenden Fall ist \\(p &lt; 0.001\\), was uns schlussfolgern lässt, dass ein signifikanter Zusammenhang zwischen der Anzahl verkaufter Bücher und der Anzahl Studierenden vorliegt. 7.5.2 jamovi Modell erstellen und Output interpretieren jamovi\\Analyses\\Regression\\Linear Regression Dependent Variable: Bücher Covariates: Studierende R Output Einfaches lineares Modell 7.6 Voraussetzungen für die Gültigkeit des linearen Modells Die Residuen sind voneinander unabhängig (schwierig zu prüfen, abhängig vom Studiendesign) Die Residuen sind normalverteilt mit dem Mittelwert 0 und der Streuung \\(\\sigma\\). Die Streuung \\(\\sigma\\) der Residuen ist über den Bereich von x konstant (Homoskedastizität). Achtung: Die lineare Regression macht keinerlei Annahmen bezügliche der Verteilung der Variablen selber! die Annahme einer Normalverteilung bezieht sich nur auf die Residuen! 7.6.1 Diagnostische Plots Die Verteilung der Residuen wird anhand eines QQ-Plots der Residuen geprüft. Die Streung der Residuen anhand eines Plots, der die gefitteten Werte auf der x-Achse und die Residuen auf der y-Achse darstellt. In R kann über die Funktion plot(model) eine Serie von 4 diagnostischen Plots ausgegeben werden. Der erste Plot erlaubt die Beurteilung der Homoskedastizität, der zweite Plot ist ein QQ-Plot. ### R-Code # Modell erstellen, wenn nicht schon gemacht model &lt;- lm(Buecher ~ Studierende, data = bookstore) # über &#39;which&#39; wählen wir die ersten beiden Plots plot(model, which = c(1, 2)) Im jamovi-Dialogfenster zur Linearen Regression kann unter Assuption Checks ein Q-Q-Plot der Residuen (Q-Q plot of residuals) gewählt werden. Jamovi erstellt ein Streudiagramm in dem auf der x-Achse die theoretischen Quantile einer Normalverteilung dargestellt werden und auf der y-Achse die Quantile der standardisierten Residuen. Weiter kann unter Assuption Checks &gt; Residual Plots gewählt werden. Jamovi erstellt mehrere Streudiagramme, von denen uns nur das erste interessiert: Auf der y-Achse werden die Residuen dargestellt und auf der x-Achse die gefitteten Werte. Wenn die Punkte gleichmässig verteilt sind, liegt Homoskedastizität vor. ## ## LINEAR REGRESSION ## ## Model Fit Measures ## ----------------------------------- ## Model R R² ## ----------------------------------- ## 1 0.9182485 0.8431803 ## ----------------------------------- ## ## ## MODEL SPECIFIC RESULTS ## ## MODEL 1 ## ## Model Coefficients - Buecher ## ------------------------------------------------------------------- ## Predictor Estimate SE t p ## ------------------------------------------------------------------- ## Intercept 8.9333333 3.11482444 2.868005 0.0167258 ## Studierende 0.6863636 0.09360400 7.332632 0.0000250 ## ------------------------------------------------------------------- ## ## ## ASSUMPTION CHECKS 7.6.2 Interpretation der Plots: QQ-Plot: Die Punkte sind einigermassen auf der Linie und wir entscheiden auf Normalverteilung der Residuen. (Bei kleinen Stichproben wie im vorliegenden Fall ist die Entscheidung meist nicht ganz sicher möglich) Residuen vs. gefittete Werte: Die Streuung der Residuen wird von links nach rechts, d.h. mit zunehmender geschätzter Zahl an verkauften Büchern grösser. Damit ist die Voraussetzung nicht erfüllt, dass die Streuung der Residuen über den gesamten Messbereich gleich ist und es liegt Heteroskedastizität vor. 7.6.3 Was bedeutet es, wenn die Voraussetzungen nicht erfüllt sind? Signifikanztests und Konfidenzintervalle für die Koeffizienten haben nicht die erwarteten Eigenschaften und werden dadurch schlecht interpretierbar. Die Koeffizienten sind immer noch gültig! 7.6.4 Beispielplots zu Homo- und Heteroskedastizität Nur Abb. c) erfüllt die Bedingung für Homoskedastizität. In Abb. a) bilden die Residuen ein Muster, was die Annahme verletzt, dass die Residuen zufällig um die Null-Linie herum streuen. In Abb. b) und d) ist die Verteilung heteroskedastisch; mit zunehmendem x nimmt auch die Streuung der Residuen um die Null-Linie herum zu. References "],["vergleich-von-mittelwerten.html", "8 Vergleich von Mittelwerten 8.1 Lernziele 8.2 T-Tests 8.3 T-Verteilung versus Normalverteilung 8.4 T-Test für eine einfache Stichprobe 8.5 T-Test für verbundene Stichproben 8.6 Zweistichproben-T-Test für unabhängige Stichproben 8.7 Nicht-parametrische Tests", " 8 Vergleich von Mittelwerten Dass die Sonne morgen aufgehen wird, ist eine Hypothese; und das heisst: wir wissen nicht, ob sie aufgehen wird.  Ludwig Wittgenstein (Tractatus logico-philosophicus, 6.36311) 8.1 Lernziele Identifiziere Daten als gepaart bzw. verbunden, wenn zu jeder Beobachtungseinheit zwei Messungen der gleichen Variable vorliegen. Beispiele sind Prä-Post-Messungen (Messwiederholungen) bei einer Interventionsstudie oder die Preise für ein Buch in verschiedenen Buchhandlungen. Berechne bei gepaarten Daten stets die Differenz zwischen den Datenpaaren (paarweise Differenzen). Dies ist die Prüfgrösse, mit der anschliessend statistische Tests durchgeführt werden können. Identifiziere Daten als unabhängig, wenn die Werte einer Stichprobe keine Informationen über die Werte der anderen Stichprobe enthalten. Dies ist z.B. bei kontrollierten Studien der Fall, bei denen Daten von Interventions- und Kontrollgruppen miteinander verglichen werden: Die Daten der Interventionsgruppe sind unabhängig von den Daten der Kontrollgruppe und enthalten keine Information über die Kontrollgruppe. Beachte, dass beim Vergleich der Differenz von zwei Parametern, die Interpretation von Vertrauensintervallen stets eine vergleichende Aussage beinhaltet; erwähne, welche Gruppe den grösseren Parameterwert hat. Verwerfe die Nullhypothese, wenn ein Vertrauensintervall für eine Differenz zwischen zwei Parametern den Wert 0 enthält. Verwende nichtparametrische Testverfahren, wenn der Stichprobenumfang klein ist (n &lt; 30, Ausnahme gepaarter t-Test möglich ab n &gt; 12) und/oder Hinweise vorliegen, dass die Populationsdaten nicht normal verteilt sind. Gehe bei Hypothesentests stets systematisch vor: Lege die Prüfgrösse und das Signifikanzniveau fest, formuliere die Hypothesen und berechne die Kennzahlen. Prüfe die Voraussetzungen (1) Unabhängigkeit der Daten, (2) Normalverteilung der Prüfgrösse und wähle je nach Ergebnis den richtigen Test aus. Berechne das Vertrauensintervall für die Prüfgrösse. Berechne die Teststatistik t (t-Test), W (Wilcoxon-Vorzeichen-Test) oder U (Mann-Whitney-U-Test) und den p-Wert. Formuliere eine Schlussfolgerung in leicht verständlicher Sprache. 8.2 T-Tests T-Tests sind die klassischen Hypothesentests. Sie gehören zur Gruppe der sog. parametrischen Tests. Damit parametrische Tests durchgeführt werden können, müssen die Daten in der annähernd normalverteilt sein. Wenn diese Voraussetzung nicht erfüllt ist, können alternativ nicht-parametrische Tests verwendet werden. Sie werden auch als verteilungsfreie Tests bezeichnet, da sie keine Annahme über die Verteilung der Daten voraussetzen. Nichtparametrische Tests sind in mehr Situationen zulässig als parametrische Tests. Warum sollen wir dann überhaupt parametrische Tests einsetzen? Parametrische Tests haben eine grössere Teststärke (Power) als nicht-parametrische Tests. Mit anderen Worten: Wenn tatsächlich ein Effekt in der Population vorliegt, haben parametrische Tests bessere Chancen, diesen Effekt auch nachzuweisen. Zudem prüfen nicht-parametrische Tests typischerweise eine etwas andere Nullhypothese als die parametrischen Tests. Im Zweifel gilt deshalb: Wenn wir Evidenz für normalverteilte Daten haben, verwenden wir einen parametrischen Test. Wenn die Verteilung der Daten aber den Voraussetzungen eines parametrischen Tests widerspricht, weichen wir auf nichtparametrische Tests aus. Nichtparametrische Testverfahren werden am Ende dieses Kapitels vorgestellt. 8.3 T-Verteilung versus Normalverteilung Wie am Ende des Kapitels zu den Wahrscheinlichkeitsverteilungen beschrieben, verwenden Statistikprogramme für die Berechnung der Teststatistik die t-Verteilung und nicht die Normalverteilung, um Wahrscheinlichkeiten für Ereignisse zu bestimmen. Der Grund dafür ist u.a., dass die t-Verteilung für kleinere Stichproben (n &lt; 30) zuverlässigere Resultate liefert. Alles was wir zur Interpretation von z-Werten gelernt haben, gilt auch für t-Werte: Wie die z-Werte zeigen auch die t-Werte, um wieviel Standardfehler die Stichprobenkennzahl vom Populationsparameter entfernt ist. 8.4 T-Test für eine einfache Stichprobe (Im folgenden Beispiel wird auch die Berechnung von Vertrauensintervallen für t-verteilte Daten besprochen. Der eigentliche T-Test ist der letzte Schritt 4.) Beispiel: Werden Volksläufer über die Jahre eher schneller oder langsamer? Für die Bearbeitung diese Frage liegen die Daten des Cherryblossom-Volkslaufs der jeweils im Frühjahr in Washington, DC durchgeführt wird, vor. Die Laufstrecke ist 16.1 km (10 Meilen) lang www.cherryblossom.org. Die durchschnittliche Laufzeit für alle Läufer:innen, die den Lauf 2006 beendet haben betrug 93.29 Minuten. Zum Vergleich liegt uns eine Zufallsstichprobe von 100 Läufer:innen vor, die am Lauf im Jahre 2012 teilgenommen haben (die Teilnehmerzahl betrug im Jahr 2012 16924 Läufer:innen). Uns interessiert, ob die Läufer:innen zwischen 2006 und 2012 im Durchschnitt schneller oder langsamer geworden sind. 8.4.1 Vorgehen 1. Hypothesen formulieren Der Vergleichswert aus dem Jahr 2006 ist in diesem Fall der sog. Nullwert: \\(\\mu_0 = 93.29\\). \\(H_0: \\mu_{2012} = 93.29\\), es gibt keinen Unterschied in der durchschnittlichen Laufzeit zwischen 2006 und 2012. \\(H_A: \\mu_{2012} \\neq 93.39\\), es gibt einen Unterschied in der durchschnittlichen Laufzeit zwischen 2006 und 2012. Ist das eine einseitige oder eine zweiseitige \\(H_A\\)? 2. Test-Voraussetzungen prüfen Wir bestimmen Mittelwert und Standardabweichung und erstellen ein Histogramm für die Laufzeit. Tabelle 8.1: Cherryblossom-Run 2012, n = 100 n m s Median 100 95.87 16.66 95.01 Abbildung 8.1: Cherryblossom-Run 2012: Laufzeiten für die Stichprobe n = 100 Unabhängigkeit: Eine Zufallsstichprobe von 100 aus 16924 ist kleiner als 10%, die Beobachtungseinheiten sind unabhängig. Die Verteilung der Daten im Histogramm ist nahezu normal (evtl. etwas linkssteil). Mit welchen Verfahren könnten Sie zusätzlich auf Normalverteilung prüfen? Abbildung 8.2: QQ-Plot fpr Cherryblossom-Run 2012, n = 100 3. Berechnung des 95%-Vertrauensintervalls für \\(\\bar{x}\\) \\[SE = \\frac{s}{\\sqrt{n}} = \\frac{16.66}{\\sqrt{100}}=1.66\\] \\[CI_{95} = \\bar{x} \\pm t_{df} \\times SE\\] Wir verwenden hier für die Berechnung des 95%-Intervalls den t-Wert für die Anzahl Freiheitsgrade df = (100 - 1) = 99. Am einfachsten finden Sie den t-Wert mit dem Internet-Rechner Students T-Verteilung. Die Berechnung in R/jamovi: ### R-Code # die Funktion qt() berechnet eine Quantile für eine bestimmte Fläche und # einen bestimmten Freiheitsgrad (s. unten) qt(.975, df = 99) ## [1] 1.984217 Das 95%-Vertrauensintervall für die durchschnittliche Laufzeit 2012 ist [92.56; 99.18]. Es beinhaltet den Durchschnittswert von 2006 von 93.29 Minuten und wir haben keine Evidenz dafür, die Nullhypothese zu verwerfen. 4. Berechnung des p-Werts: Ein-Stichproben-T-Test Die Berechnung des t-Werts erfolgt gleich wie für den z-Wert: \\[t = \\frac{\\bar{x} - \\mu_0}{SE}\\] ### R-Code n &lt;- 100 # Stichprobenumfang der Stichprobe 2012 m &lt;- 95.87 # Stichprobenmittelwert 2012 s &lt;- 16.66 # Standardabweichung 2012 mu &lt;- 93.29 # Nullwert 2006 SE &lt;- s/sqrt(n) # Standardfehler für den Stichprobenmittelwert 2012 t_wert &lt;- (m - mu)/SE # Berechnung des t-Werts t_wert &lt;- round(t_wert, 3) # t-wert auf drei Stellen runden Der \\(t\\)-Wert für unsere Punktschätzung ist \\(t = 1.549\\). Den p-Wert können wir wieder mit dem Internet-Rechner Students T-Verteilung oder mit R/jamovi berechnen. ### R-Code p_wert &lt;- 2 * (1-pt(t_wert, df = 99)) # Berechnung p-Wert für eine zweiseitige Hypothese p_wert &lt;- round(p_wert, 3) # berechneten p-Wert auf 3 Nachkommastellen runden p_wert # berechneten p-Wert anzeigen ## [1] 0.125 Ein \\(p\\)-Wert von \\(p\\) = 0.125 bedeutet, dass unter der Annahme, dass \\(H_0\\) wahr ist, ein Ergebnis wie in unserer Stichprobe oder ein noch extremeres Ergebnis mit einer Wahrscheinlichkeit von 12.5 % vorkommt. \\(p\\) = 0.12 ist grösser als unser Signifikanzniveau \\(\\alpha\\) = 0.05 und wir verwerfen die \\(H_0\\) nicht. 5. Schlussfolgerung formulieren Untersucht wurde die Frage, ob sich die durchschnittliche Laufzeit von Volksläufer:innen über die Jahre geändert hat. Als Nullwert wurde die durchschnittliche Laufzeit von 2006 von 93.29 Minuten angenommen. In einer Zufallsstichprobe n = 100 der Läufer:innen am Cherryblossom Run 2012 betrug die durchschnittliche Laufzeit 95.87 [92.56, 99.18] Minuten, \\(t(99)\\) = 1.549, \\(p\\) = 0.125. Die vorliegenden Daten liefern keine Evidenz dafür, dass sich die durchschnittlichen Laufzeiten zwischen 2006 und 2012 verändert haben. 8.4.2 Vertrauensintervall für einen Mittelwert Schritt-für-Schritt: Vorbereitung: Berechne den \\(\\bar{x}\\), \\(s\\) und \\(n\\) und lege das Vertrauensniveau fest (üblicherweise 95% = 0.95) Voraussetzungen: Prüfe, ob die Voraussetzungen erfüllt sind, dass die Daten aus einer Normalverteilung stammen (QQ-Plot). Berechnung: Wenn die Voraussetzungen erfüllt sind, berechne SE und finde \\(t_{df}\\), um das Intervall zu berechnen. Schlussfolgerung: Interpretiere das Vertrauensintervall im Zusammenhang mit der Fragestellung. Code-Tipp: \\(t_{df}\\) lässt sich in R/jamovi einfach berechnen: ### R-Code # Copy-Paste in R-Konsole: für df muss jeweils n - 1 eingetragen werden # für ein 95%-Vertrauensintervall qt(.975, df) # für ein 99%-Vertrauensintervall qt(.995, df) # für ein 90%-Vertrauensintervall qt(.95, df) 8.4.3 Ein-Stichproben-T-Test Schritt-für-Schritt: Vorbereitung: Identifiziere den für die Frage relevanten Parameter (die Prüfgrösse), formuliere die Hypothesen, lege das Signifikanzniveau \\(\\alpha\\) fest und berechne \\(\\bar{x}\\), \\(s\\) und \\(n\\). Voraussetzungen: Prüfe, ob die Voraussetzungen erfüllt sind, dass die Daten aus einer Normalverteilung stammen (QQ-Plot). Wenn die Voraussetzungen erfüllt sind, berechne SE, den \\(t_{df}\\)-Wert und den p-Wert. Schlussfolgerung: Beurteile den Hypothesentest, indem du den \\(p\\)-Wert mit dem Signifkanzniveau \\(\\alpha\\) vergleichst. Formuliere eine Schlussfolgerung im Zusammenhang mit der Fragestellung in leicht verständlicher Sprache. Code-Tipp: Der \\(p\\)-Wert lässt sich in R/jamovi einfach berechnen: ### R-Code # p-Wert für eine zweiseitige Hypothese berechnen 2 * (1 - pt(t_wert, df = n - 1)) # n - 1 = Stichprobenumfang - 1 8.4.4 R/jamovi R-Code und Output ### R-Code t.test(x = sample$time, # sample$time = daten$variable mu = 93.29, # mu = Nullwert alternative = &quot;two.sided&quot;) # zweiseitige Alternativhypothese ## ## One Sample t-test ## ## data: sample$time ## t = 1.5489, df = 99, p-value = 0.1246 ## alternative hypothesis: true mean is not equal to 93.29 ## 95 percent confidence interval: ## 92.56457 99.17743 ## sample estimates: ## mean of x ## 95.871 jamovi-Output jamovi\\..\\T-Tests\\One Sample T-Test jamovi-Output One Sample T-Test 8.5 T-Test für verbundene Stichproben Von verbundenen bzw. gepaarten Daten sprechen wir dann, wenn zwei Variablen voneinander abhängig sind: Dies bedeutet, dass die Werte der einen Messung die Werte der anderen Messung beeinflussen. Das ist der Fall, wenn wir z.B. die Preise für ein Buch in verschiedenen Läden vergleichen oder wenn wir Messungen bei Individuen zu verschiedenen Zeitpunkten, z.B. vor und nach einer Intervention (Prä-Post-Messungen), durchführen. Beispiel: In einer Studie wird untersucht, ob die Testpersonen mit einem neuen Schlafmittel länger schlafen als ohne Schlafmittel. Die Studie wird mit 20 Personen durchgeführt. Zuerst wird die Schlafdauer ohne Medikament (Baseline-Messung), dann die Schlafdauer mit Medikament (Follow-Up-Messung) gemessen. Die Tabelle zeigt die Daten zu den ersten vier Probanden: Tabelle 8.2: Schlafmitteldaten, erste 4 Zeilen Proband ohne_Med mit_Med 1 5.28 5.83 2 5.69 4.69 3 4.81 4.43 4 5.90 6.49 Jedem Probanden entsprechen zwei Messungen (Variablen): Eine für die Schlafdauer ohne und eine für die Schlafdauer mit Medikament. In diesem Fall liegen gepaarte Daten vor, da für jede Beobachtungseinheit zwei Messzeitpunkte vorliegen, die miteinander verglichen werden. Abbildung 8.3: Zusammenhang zwischen Schlafdauer mit und ohne Medikament Das Punktediagramm zeigt, dass die Schlafdauer mit Medikament in einem Zusammenhang mit der Schlafdauer ohne Medikament steht: Probanden, die ohne Medikament länger schlafen, schlafen auch mit Medikament länger. Wenn wir den Effekt einer Intervention bei gepaarten Daten untersuchen, ist die Prüfgrösse die Differenz der Datenpaare, die sog. paarweisen Differenzen. Im vorliegenden Beispiel ist dies die Differenz zwischen der Schlafdauer mit und ohne Medikament. Wenn die Differenzen bei der Datenerhebung noch nicht berechnet wurden, erstellt man eine neue abgeleitete Variable und berechnet für jeden Probanden die paarweisen Differenzen. Dabei ist es wichtig eine konsistente Ordnung einzuhalten: Wenn wir uns für den Effekt des Medikamentes interessieren, berechnen wir die paarweisen Differenzen durch Subtraktion der Schlafdauer ohne Medikament von der Schlafdauer mit Medikament. \\[paarweise.Differenz = Schlafdauer.mit.Medi - Schlafdauer.ohne.Medi\\] Wenn das Medikament einen positiven Effekt auf die Schlafdauer hat, erhalten wir eine positive Differenz, wenn das Medikament die Schlafdauer verkürzt, erhalten wir eine negative Differenz. Für die Durchführung des T-Tests für gepaarte Daten verwenden wir als Prüfgrösse den Mittelwert der paarweisen Differenzen. Der Mittelwert der paarweisen Differenzen ist das Mass für den Effekt des Medikaments. Die Prüfgrösse bei gepaarten Daten ist der Mittelwert der paarweisen Differenzen \\(\\mu_{d}\\). Tabelle 8.3: Schlafmittel-Daten mit paarweisen Differenzen Proband ohne_Med mit_Med paarweise.Differenzen 1 5.28 5.83 0.55 2 5.69 4.69 -1.00 3 4.81 4.43 -0.38 4 5.90 6.49 0.59 Mit dem Mittelwert für paarweise Differenzen als Prüfgrösse haben wir die gleiche Situation, wie beim Einstichproben-Test, nämlich einen Mittelwert den wir gegen einen Nullwert vergleichen, und das weitere Vorgehen ist wie beim Einstichproben-T-Test. 8.5.1 Vorgehen 1. Hypothesen formulieren Prüfgrösse definieren: Mittelwert der paarweisen Differenzen = \\(\\bar{x}_{d}\\) Hypothesen formulieren \\(H_0: \\mu_{d} = 0\\), es gibt keinen Unterschied, die Differenzen ergeben 0 \\(H_A: \\mu_{d} \\neq 0\\), es gibt einen Unterschied, die Differenzen ergeben nicht 0 Signifikanzniveau \\(\\alpha\\) festlegen, üblicherweise \\(\\alpha = 0.05\\) \\(\\bar{x}\\), \\(s\\) und \\(n\\) berechnen Tabelle 8.4: Kennzahlen zu Schlafmittel-Daten Variable n m s paarweise.Differenzen 20 0.395 0.672 ohne_Med 20 5.376 0.574 mit_Med 20 5.771 0.953 2. Test Voraussetzungen prüfen: Prüfe, ob die Voraussetzungen erfüllt sind, dass \\(\\bar{x}_{d}\\) aus einer annähernd normal verteilten Population stammt. Prüfung auf Unabhängigkeit: Es handelt sich um eine Zufallsstichprobe, n &lt; 10% der Population Prüfung der Prüfgrösse auf Normalverteilung (QQ-Plot unten) Stichprobenumfang: Wenn die Prüfgrösse paarweise Differenzen sind, kann der T-Test ab n &gt; 12 angewendet werden, wenn die Daten annähernd normalverteilt sind. Ab n &gt; 100 ist der T-Test nahezu unbeschränkt durchführbar, unabhängig von der zugrundeliegenden Verteilung. Abbildung 8.4: Histogramm und QQ-Plot für paarweise Differenzen Im Histogramm sind die Daten leicht rechtssteil verteilt. Im QQ-Plot liegen die Punkte weitgehend auf einer Linie. Daher entscheiden wir für normalverteilte Daten. 3. SE, \\(t_{df}\\)-Wert p-Wert und 95%-Konfidenzintervall berechnen. \\[SE = \\frac{0.672}{\\sqrt{20}} = 0.15\\] \\[t_{19} = \\frac{0.395-0}{0.150} = 2.629\\] Den p-Wert für t und df = 20-1 können wir wieder mit dem Internet-Rechner Students T-Verteilung oder mit R/jamovi berechnen. ### R-Code 2 * (1-pt(t, df = 20-1)) # p-Wert für zweiseitige Hypothese, t-Verteilung, df = 19 Mit \\(p\\) = 0.017 ist die Wahrscheinlichkeit für den beobachteten Effekt oder einen stärkeren Effekt kleiner als unser Signifkanzniveau \\(\\alpha = 0.05\\) und wir haben Evidenz dafür, dass wir die Nullhypothese zugunsten der Alternativhypothese verwerfen können. \\[CI_{95} =0.395 \\pm t_{0.975, df=19} \\times 0.15\\] ### R-Code # 95%-Konfidenzintervall: Quantile für t = 0.975 und df = 20- 1 qt(.975, 19) ## [1] 2.093024 ### R-Code n &lt;- 20 s &lt;- .672 m &lt;- .395 SE &lt;- s/sqrt(n) t &lt;- (.395 - 0)/SE p_wert &lt;- 2 * (1-pt(t, df = 20-1)) p_txt &lt;- paste(&quot;p-Wert =&quot;, round(p_wert, 3)) CI95 &lt;- m + c(-1, 1) * qt(.975, 19) * SE CI95 &lt;- round(CI95, 3) Die Berechnung ergibt ein 95%-Konfidenzintervall für den Mittelwert der Differenz in der Schlafdauer von 0.395 [0.08; 0.71] Stunden. Das 95%-Konfidenzintervall enthält den Nullwert nicht und wir verwerfen die Nullhypothese zugunsten der Alternativhypothese. 4. Schlussfolgerung formulieren Untersucht wurde der Einfluss eines Medikaments auf die Schlafdauer bei 20 Probanden. Das Medikament hat die Schlafdauer durchschnittlich um 0.395 [0.08 0.71] Stunden signifikant verlängert, \\(t(19)\\) = 2.629, \\(p\\) = 0.017. 8.5.2 R/jamovi R Code und Output ### R-Code # Variante 1: Als T-Test für gepaarte Stichproben t.test(x = medi_data$mit_Med, # Baseline-Data y = medi_data$ohne_Med, # Follow-Up-Data paired = TRUE, # gepaarte Daten alternative = &quot;two.sided&quot;) # zweiseitige Alternativhypothese ## ## Paired t-test ## ## data: medi_data$mit_Med and medi_data$ohne_Med ## t = 2.6237, df = 19, p-value = 0.01672 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.07978913 0.70921087 ## sample estimates: ## mean of the differences ## 0.3945 # Variante 2: Als Einstichproben-T-Test mit der Variable paarweise.Differenzen t.test(x = medi_data$paarweise.Differenzen, mu = 0, alternative = &quot;two.sided&quot;) ## ## One Sample t-test ## ## data: medi_data$paarweise.Differenzen ## t = 2.6237, df = 19, p-value = 0.01672 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 0.07978913 0.70921087 ## sample estimates: ## mean of x ## 0.3945 Der T-Test für gepaarte Stichproben berechnet zuerst die paarweisen Differenzen und ermittelt anschliessend die Teststatistik. Wenn man die paarweisen Differenzen im Datensatz vorhanden sind, kann der Einstichproben-T-Test durchgeführt werden. Beide Varianten kommen zum exakt gleichen Ergebnis. jamovi-Output Wähle jamovi\\..\\T-Tests\\Paired Samples T-Test jamovi-Output Paired Samples T-Test 8.6 Zweistichproben-T-Test für unabhängige Stichproben In diesem Abschnitt beschäftigen wir uns mit der Differenz von zwei Populationsmittelwerten \\(\\mu_1 - \\mu_2\\) unter der Voraussetzung, dass die Daten nicht gepaart sind. Typisch sind Vergleiche zwischen zwei Gruppen bzw. Stichproben, z.B. kontrollierte Studien in denen Interventionsgruppe und Kontrollgruppe verglichen werden oder der Vergleich des Gewichts von Neugeborenen von rauchenden und nicht-rauchenden Müttern. Die Formeln in diesem Abschnitt werden etwas komplizierter. In der Regel lassen wir die Software die Berechnungen durchführen und müssen nicht mit ihnen arbeiten. Sie stehen hier als Hintergrundinformation und für diejenigen, die von Hand rechnen wollen. 8.6.1 Konfidenzintervall für einen Mittelwertsunterschied Im Folgenden werden zuerst die theoretischen Grundlagen erarbeitet, anschliessend folgt ein Schritt-für-Schritt Beispiel für die Durchführung des Zweistichproben-T-Tests für unabhängige Stichproben. Beispiel: Hat die Behandlung mit embryonalen Stammzellen (ESC) einen Effekt auf die Pumpfunktion des Herzens nach einem Herzinfarkt? Die folgende Tabelle enthält die Kennzahlen aus einem Experiment, bei dem der Effekt von ESC bei Schafen, die einen Herzinfarkt erlitten hatten, geprüft wurde. Jedes dieser Schafe wurde randomisiert der Gruppe ESC oder der Kontrollgruppe zugewiesen, dann wurde ihre Herzkapazität (Auswurffraktion) gemessen. Details zur Studie hier The Lancet. Ein positiver Wert entspricht einer Steigerung der Auswurffraktion, was einer besseren Erholung entspricht. Unsere erste Aufgabe ist es, das 95%-Konfidenzintervall für den Effekt der ESCs auf die Herzfunktion im Vergleich zur Kontrollgruppe zu berechnen. Codebook: Datensatz stemcell.csv Variable Beschreibung trtm Behandlung: ctrl = Kontrolle, esc= embryonale Stammzellen before Baseline: Auswurffraktion vor der Behandlung after Follow-Up: Auswurffraktion nach der Behandlung Tabelle 8.5: Datensatz der ESC-Studie trmt before after ctrl 35.25 29.50 ctrl 36.50 29.50 ctrl 39.75 36.25 ctrl 39.75 38.00 ctrl 41.75 37.50 ctrl 45.00 42.75 ctrl 47.00 39.00 ctrl 52.00 45.25 ctrl 52.00 52.25 esc 29.00 31.00 esc 29.50 43.75 esc 34.00 36.00 esc 35.00 41.50 esc 35.25 39.50 esc 42.50 40.00 esc 44.00 45.75 esc 49.25 55.25 esc 53.75 51.00 Nach dem Erstellen einer abgeleiteten Variable Differenz = after - before berechnen wir die Kennzahlen für den Effekt der Behandlung. Tabelle 8.6: ESC-Daten: Effekt der Behandlung trmt n m s ctrl 9 -4.33 2.76 esc 9 3.50 5.17 Die Kennzahlen zeigen, dass die Auswurffraktion in der Kontrollgruppe CTRL um durchschnittlich -4.33% abgenommen und in der Interventionsgruppe ESC um 3.5% zugenommen hat. Die Prüfgrösse bei unabhängigen Daten ist die Differenz der Mittelwerte \\(\\mu_1 - \\mu_2\\). Die Prüfgrösse für die Differenz in der Herzleistung zwischen ESC- und Kontrollgruppe lässt sich berechnen als \\[\\bar{x}_{esc} - \\bar{x}_{ctrl} = 3.5 - (-4.33) = 7.83\\] Für die Prüfung, ob wir für diese Differenz die t-Verteilung anwenden können, müssen wir die bisher verwendeten Voraussetzungen etwas erweitern: Unabhängigkeit: Die Daten müssen sowohl zwischen den Stichproben als auch innerhalb der Stichproben unabhängig sein. Dies wird dadurch sichergestellt, dass die Beobachtungseinheiten randomisiert aus der Population ausgewählt und randomisiert den Gruppen Intervention oder Kontrolle zugeteilt werden. Normalverteilung: Die Daten müssen in beiden Stichproben normalverteilt sein. Die Berechnung des Standardfehlers \\(SE\\) und der Anzahl Freiheitsgrade \\(df\\) ist relativ komplex und wird normalerweise von der Statistiksoftware übernommen. Diejenigen, die von Hand rechnen wollen, können diese - vereinfachte - Formel verwenden: \\[SE_{\\bar{x_2}-\\bar{x_1}} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\\] Als Freiheitsgrad df für die t-Verteilung verwenden wir den kleineren Wert von \\(n_1 - 1\\) und \\(n_2 - 1\\) (die genaue Berechnung von \\(df\\) ist komplex und wir verwenden hier eine konservative Vereinfachung). \\[df = min(n_1-1, n_2-1)\\] Prüfung der Voraussetzungen Unabhängigkeit ist gegeben, da die Schafe randomisiert ausgewählt und den Gruppen Intervention oder Kontrolle zugeordnet wurden. Prüfung der Normalverteilung anhand von Histogramm und QQ-Plot: Wir entscheiden für normalverteilte Daten. Abbildung 8.5: Histogramm und QQ-Plot für ESC- und Kontrollgruppe Für die Berechnung des Standardfehlers verwenden wir die Standardabweichung der Stichprobe, da wir die Standardabweichung der Population nicht kennen: \\[SE = \\sqrt{\\frac{s_{esc}^2}{n_{esc}} + \\frac{s_{ctrl}^2}{n_{ctrl}}} = \\sqrt{\\frac{5.17^2}{9} + \\frac{2.76^2}{9}} = 1.95\\] Für die Bestimmung der Anzahl Freiheitsgrade \\(df\\) der \\(t\\)-Verteilung verwenden wir den kleineren Wert für \\(n - 1\\). Hier haben beide Gruppen den gleichen Umfang n und wir verwenden \\(df\\) = 8. Den kritischen \\(t\\)-Wert für eine \\(t\\)-Verteilung mit \\(df\\) = 8 für ein 95%-Konfidenzintervall erhalten wir in `R`` ### R-Code # t-Wert für ein 95%-Konfidenzintervall mit df = 8 qt(.975, 8) ## [1] 2.306004 Durch Einsetzen können wir jetzt das 95%-Konfidenzintervall für die Differenz des Effekts zwischen den beiden Stichproben berechnen: \\[CI_{95} = 7.83 \\pm 2.31 \\times 1.95 = [3.33; 12.33]\\] Das 95%-Konfidenzintervall beinhaltet Null nicht und wir haben Evidenz für einen signifikanten Effekt. Schlussfolgerung: Die Behandlung mit embryonalen Stammzellen bei Schafen, die einen Herzinfarkt erlitten haben, verbessert die Pumpfunktion des Herzens signifikant im Durchschnitt um 7.83% [3.33% 12.33%] im Vergleich zu keiner Behandlung. 8.6.2 Der Zweistichproben-T-Test für unabhängige Stichproben Schritt-für-Schritt Für einen T-Test für einen Mittelwertsunterschied ist eine der Voraussetzungen, dass der Stichprobenumfang \\(n\\) gleich oder grösser als 30 ist. Dies ist für das Beispiel mit den Schafen nicht gegeben und wir verwenden ein neues Beispiel. Frage: Hat es einen Einfluss auf das Geburtsgewicht von Neugeborenen, wenn schwangere Frauen rauchen? Wir prüfen diese Frage anhand eines Datensatzes, der eine Zufallsstichprobe von 150 Müttern und ihren Neugeborenen umfasst. Die Variable habit erfasst, ob die Mutter während der Schwangerschaft geraucht hat oder nicht und die Variable weightgibt das Geburtsgewicht in g an. Die Raucherinnengruppe umfasst 50 Mütter, die Nichtraucherinnengruppe 100 Mütter. Die Tabelle gibt die ersten 5 Einträge im Datensatz an: Tabelle 8.7: Datensatz Geburtsgewicht (g) und Raucherstatus f_age m_age weeks premature visits gained weight sex_baby smoke 31 30 39 full term 13 1 3121 male smoker 30 28 39 full term 13 0 3402 female nonsmoker 43 31 41 full term 5 20 3202 female smoker 36 35 40 full term 12 29 4028 male nonsmoker 33 27 41 full term 15 38 3175 male smoker Das Vorgehen für die statistische Analyse ist wie bisher: Vorbereitung: Identifiziere den für die Frage relevanten Parameter (die Prüfgrösse), formuliere die Hypothesen und lege das Signifikanzniveau \\(\\alpha\\) fest Prüfe, ob die Voraussetzungen erfüllt sind. Wenn die Voraussetzungen erfüllt sind, berechne SE, das 95%-Konfidenzintervall, den \\(t_{df}\\)-Wert und den \\(p\\)-Wert. Schlussfolgerung: Beurteile den Hypothesentest, indem du den p-Wert mit dem Signifkanzniveau \\(\\alpha\\) vergleichst. Formuliere eine Schlussfolgerung im Zusammenhang mit der Fragestellung in leicht verständlicher Sprache. 1. Hypothesen formulieren Die Prüfgrösse ist \\(\\mu_s - \\mu_{ns}\\) Signifikanzniveau \\(\\alpha = 0.05\\) Hypothesen: - \\(H_0: \\mu_s = \\mu_{ns}\\), der Raucherstatus hat keinen Einfluss auf das Geburtsgewicht von Neugeboren. - \\(H_A: \\mu_s \\neq \\mu_{ns}\\), der Raucherstatus hat einen Einfluss auf das Geburtsgewicht von Neugeboren. 2. Voraussetzungen prüfen Es handelt sich um eine Zufallsstichprobe, die Daten sind unabhängig. Auf Grund von Histogramm und QQ-Plot entscheiden wir, dass die Daten normalverteilt sind. Der Stichprobenumfang in jeder Gruppe ist n &gt; 30. Die Streuung der Daten ist in beiden Stichproben gleich. Wir gehen immer davon aus, dass die Streuung der Daten nicht gleich ist und führen grundsätzlich den Welchs-Test durch, der eine Anpassung des Zweistichproben-T-Tests für ungleiche Varianzen ist. Abbildung 8.6: Histogramm und QQ-Plot für Geburtsgewicht nach Raucherstatus der Mutter Berechnungen von Kennzahlen, SE, t-Wert und p-Wert Tabelle 8.8: Kennzahlen für Geburtsgewicht (g) nach Raucherstatus der Mutter smoke n m s nonsmoker 100 3256.6 650.53 smoker 50 3075.0 724.61 Neugeborene von nicht-rauchenden Müttern sind im Durchschnitt \\(3256.6 - 3075.0 = 181.6g\\) schwerer als von rauchenden Müttern. Berechnung des Standardfehlers SE der Prüfgrösse: \\[SE = \\sqrt{\\frac{s_{ns}^2}{n_{ns}} + \\frac{s_s^2}{n_s}} = \\sqrt{\\frac{651^2}{100} + \\frac{725^2}{50}} = 121.4\\] Berechnung des 95%-Konfidenzintervalls Kritischer t-Wert ### R-Code qt(.975, df = 49) ## [1] 2.009575 \\[CI_{95} = 181.6 \\pm 2.01 \\times 121.4 = [-62.4; 425.6]\\] Neugeborene von Nichtraucherinnen sind im Durchschnitt um 181.6 [-62.4; 425.6] schwerer als Neugeborene von Raucherinnen. Das 95%-Konfidenzintervall beinhaltet Null, d.h. kein Unterschied im Geburtsgewicht ist ein plausibler Wert, und wir haben keine Evidenz gegen die Nullhypothese. Berechnung des t-Werts: \\[t = \\frac{181.6 - 0}{121.4} = 1.496\\] Berechnung des \\(p\\)-Werts: Für die Berechnung des p-Werts verwenden wir für die Anzahl Freiheitsgrade den kleineren Wert für \\(n_{nonsmoker} - 1 = 99\\) und für \\(n_{smoker} - 1 = 49\\) also \\(df = 49\\): Wir können den p-Wert für \\(t_{49}\\) wieder in einer Tabelle nachschlagen oder mit R/jamoviberechnen: ### R-Code # p-Wert für eine zweiseitige Hyptothese und df = 49 2 * (1-pt(1.496, df = 49)) ## [1] 0.1410672 \\(p = 0.141\\); Dieser \\(p\\)-Wert ist grösser als \\(\\alpha = 0.05\\) und wir haben keine ausreichende Evidenz, um die Nullhypothese zu verwerfen. Schlussfolgerung: Untersucht wurde die Frage, ob Neugeborene von rauchenden Müttern ein anderes Geburtsgewicht haben als Neugeborene von nichtrauchtenden Müttern. Anhand der vorliegenden Daten konnte kein signifikanter Unterschied für deas Geburtsgewicht von Neugeborenen rauchender und nichtrauchender Mütter festgestellt werden: Neugeborene von nichtrauchenden Müttern sind im Durchschnitt 181.6 [-62.4; 425.6] leichter als von nichtrauchenden Müttern, t(49) = 1.496, p = 0.141. Anmerkung: Dies ist ein vergleichsweise kleiner Datensatz; grössere Datensätze in aktuellen Studien liefern Evidenz dafür, dass Neugeborene von rauchenden Müttern ein geringeres Geburtsgewicht aufweisen als von nichtrauchenden Müttern. In den 70er-Jahren hat die Tabak-Industrie diese Tatsache sogar als Werbung mit dem Argument benutzt, dass Mütter kleinere Babies bei der Geburt bevorzugen. (Reeves and Bernstein 2006) 8.6.3 R/jamovi R Code und Output ### R-Code t.test( weight ~ smoke, data = births, alternative = &quot;two.sided&quot;, # Voreinstellung, muss nicht angegeben werden paired = FALSE, # Voreinstellung, muss nicht angegeben werden var.equal = FALSE # Voreinstellung, muss nicht angegeben werden ) ## ## Welch Two Sample t-test ## ## data: weight by smoke ## t = 1.4961, df = 89.275, p-value = 0.1381 ## alternative hypothesis: true difference in means between group nonsmoker and group smoker is not equal to 0 ## 95 percent confidence interval: ## -59.56991 422.76991 ## sample estimates: ## mean in group nonsmoker mean in group smoker ## 3256.6 3075.0 R führt standardmässig einen Welchs-Test durch. jamovi-Output jamovi\\..\\T-Tests\\Independent Samples T-Test &gt; Welch's jamovi-Output Welch-Test 8.7 Nicht-parametrische Tests Die bisher besprochenen Testverfahren (t-Tests) können nur durchgeführt werden, wenn gewisse Voraussetzungen erfüllt sind: Besonders bei kleineren Stichprobenumfängen müssen die Daten aus einer normalverteilten Population stammen. Wir kontrollieren das jeweils mittels Histogramm und QQ-Plot. Der minimale Stichprobenumfang bei gepaarten Daten sollte n &gt; 12 und bei unabhängigen Daten n &gt; 30 sein. Es handelt sich um quantitative Daten. Es stellt sich nun die Frage, wie man Hypothesentests durchführt, wenn diese Bedingungen nicht erfüllt sind. Ist die Verteilung der Daten nicht bekannt, so müssen andere Testverfahren, sog. nicht-parametrische Verfahren verwendet werden. Diese stellen keine Annahme bezüglich der Verteilung der Daten voraus und eignen sich daher besonders für kleine Stichproben, bei denen die Beurteilung von Normalitätstests oft mit einer grossen Unsicherheit verbunden ist. Ein weiterer Vorteil der nichtparametrischen Verfahren besteht darin, dass auch qualitativ-ordinalen Daten, z.B. VAS-Skalen oder Schulnoten, analysiert werden können. 8.7.1 Rang-Methoden (rank tests) Rangtests spielen in der Klasse der nichtparametrischen Verfahren eine dominierende Rolle. Dabei ist die zu berechnende Testgrösse nur eine Funktion der rangierten (geordneten) Beobachtungen; die Beobachtungswerte selber werden nicht verwendet. Dies bedeutet, dass man nur die ordinale Information der Daten nutzt. Daher ist auch die Mindestanforderung an die Daten, dass sie qualitativ-ordinal skaliert sind. Mathematisches Detail (nicht zu lernen): Die nichtparametrischen Methoden arbeiten mit diskreten Verteilungen. Die Berechnung von \\(p\\)-Werten erfolgt jedoch über eine sog. Approximation (Annäherung) an die Normalverteilung, welche eine kontinuierliche Verteilung ist. Bei der Aproximation einer diskreten an eine kontinuierliche Verteilung muss ein Korrekturfaktor Kontinuitätskorrektur (engl. continuity correction) eingeführt werden, der in der Ausgabe von Statistikprogrammen erwähnt wird. 8.7.2 Wilcoxon-Vorzeichenrangtest jamovi\\T-Tests\\Paired Samples T-Test\\Wilcoxon Rank Der Wilcoxon-Vorzeichenrangtest wird für gepaarte Daten oder den Einstichprobenfall gewählt. Beispiel: Wie Lange dauert eine Schwangerschaft? Und hängt die genaue Bestimmung von der Untersuchungsmethode ab? Zur Verfügung stehen zwei Methoden um die Schwangerschaftsdauer zu bestimmen: Einerseits die Methode der letzten Menstruationsperiode (LMP) und andererseits die Ultraschallmethode (US). Zufällig werden zehn schwangere Frauen ausgewählt und nach beiden Methoden die Schwangerschaftsdauer bestimmt. Die Untersuchung wird blindiert durchgeführt, so dass die LMP-Untersucher:innen die Ergebnisse der US-Untersucher:innen nicht kennen und umgekehrt. Die Bestimmung der Schwangerschaftsdauer bei zehn schwangeren Frauen einer einfachen Stichprobe aus der gegebenen Population liefert folgende LMP und US Daten: Tabelle 8.9: Daten für Schwangerschaftsdauer ID LMP US LMPminusUS 1 275 273 2 2 292 285 7 3 281 270 11 4 284 272 12 5 285 278 7 6 283 276 7 7 290 291 -1 8 294 290 4 9 300 279 21 10 284 292 -8 Wie können wir diese Daten interpretieren? Als erstes berechnen wir die Kennzahlen und erstellen Grafiken zum Vergleich der beiden Bestimmungsmethoden. Tabelle 8.10: Kennzahlen Schwangerschaftsdauer name m Median s LMP 286.8 284.5 7.2 US 280.6 278.5 8.3 Abbildung 8.7: Boxplots für Schwangerschaftsdauer Der Vergleich von Mittelwert und Median und die Boxplots zeigen, dass die Daten linkssteil verteilt sind. Zudem ist der Stichprobenumfang mit n = 10 klein. Die Voraussetzungen für einen t-Test für gepaarte Daten sind nicht gegeben. Hypothesen: \\(H_0: Median_{LMP} = Median_{US}\\), die LMP- und die US-Methode ergeben die gleiche Schwangerschaftsdauer. \\(H_A: Median_{LMP} \\neq Median_{US}\\), die LMP- und die US-Methode ergeben eine unterschiedliche Schwangerschaftsdauer. Merke: Beim Wilcoxon-Vorzeichenrangtest vergleichen wir Mediane und nicht Mittelwerte! Signifikanzniveau: \\(\\alpha = 0.05\\) Vorgehen Wilcoxon-Vorzeichenrangtest [Das Prinzip des Wilcoxon-Vorzeichen-Rangtests wird hier exemplarisch an einem Beispiel erläutert. Üblicherweise wird der Test in einem Statistikprogramm durchgeführt.] Gilt die Nullhypothese, so kann die Differenz der LMP- und US-Werte einer schwangeren Frau sowohl positiv wie auch negativ sein; weder positive noch negative Werte sollten überwiegen und die Differenzen sollten symmetrisch um Null verteilt sein. Der Wilcoxon-Vorzeichen-Rangtest prüft, ob die paarweisen Differenzen symmetrisch mit dem Median gleich Null verteilt sind. Zur Durchführung des Tests werden diese Differenzen passend nach Rängen geordnet (rangiert). Es werden die absoluten Differenzen (Abstände zu Null) rangiert, ohne das Vorzeichen zu beachten. Ist eine Differenz Null, wird sie bei der Rangierung nicht verwendet und vom Stichprobenumfang n abgezogen. Tabelle 8.11: Daten, Differenzen, Ränge und Vorzeichen der Differenzen der LMP- und US-Werte der Schwangerschaftsdauer ID LMP US LMPminusUS Rang Vorzeichen 1 275 273 2 2 plus 2 292 285 7 5 plus 3 281 270 11 8 plus 4 284 272 12 9 plus 5 285 278 7 5 plus 6 283 276 7 5 plus 7 290 291 -1 1 minus 8 294 290 4 3 plus 9 300 279 21 10 plus 10 284 292 -8 7 minus Abbildung 8.8: Punktediagramm der Schwangerschaftsdauer, US- und LMP-Werte mit Rängen Wenn die Differenzen symmetrisch um Null angeordnet sind, haben wir Evidenz dafür, dass \\(H_0\\) wahr ist. Beachte, dass einige dieser Differenzen der Schwangerschaftsdauer gleich sind. Der Wert 7 kommt drei Mal vor. Diesen drei Werten sollten die Ränge 4, 5 und 6 zugeordnet werden. Ihr mittlerer Rang (Mittelwert von 4, 5 und 6) ist 5. Deshalb wird dieser mittlere Rang jedem der drei Werte zugeordnet. Wir vergleichen jetzt die Summe der positiven Ränge mit der Summe der negativen Ränge. Sind diese beiden Rangsummen etwa gleich gross, haben wir keine Evidenz gegen die Nullhypothese, andernfalls werden wir die Nullhypothese ablehnen. Als einfache Testgrösse W verwenden wir Rangsumme der positiven Differenzen. Summe der positiven Ränge: 2 + 3 + 5 + 5 + 5 + 8 + 9 + 10 = 47 Summe der negativen Ränge: 1 + 7 = 8 Testgrösse \\(W\\) (in R Testgrösse \\(V\\)) = 47 Berechnung des p-Werts für \\(W = 47\\) und \\(n = 10\\) ### R-Code W &lt;- 47 p_Wert &lt;- 2 * psignrank(W, n = 10, lower.tail = FALSE) p_Wert ## [1] 0.03710938 Schlussfolgerung: In einer Stichprobe von n = 10 schwangeren Frauen wurde die Frage untersucht, wie lange eine Schwangerschaft dauert und ob die Untersuchungsmethoden US und LMP zum gleichen Ergebnis kommen. Die Methode US ergibt gegenüber der Methode LMP eine um durchschnittlich um 6.2 Tage kürzere Schwangerschaftsdauer, Wilcoxon-Vorzeichenrangtest W = 47, p = 0.037. 8.7.2.1 R/jamovi R Code und Output ### R-Code wilcox.test(ss$LMP, ss$US, paired = TRUE, alternative = &quot;two.sided&quot;, correct = TRUE) # mit Kontinuitätskorrektur ## ## Wilcoxon signed rank test with continuity correction ## ## data: ss$LMP and ss$US ## V = 47, p-value = 0.05217 ## alternative hypothesis: true location shift is not equal to 0 Anmerkung: Bei der Berechnung in R kann entspricht die ausgegebene Testgrösse V \\(W\\). In R kann entschieden werden, ob die Kontinuitätskorrektur durchgeführt wird oder nicht Bei unterschiedlichen Stichprobenumfängen sollte dies immer geschehen. jamovi führt die Kontinuitätskorrektur immer durch. jamovi\\..\\T-Tests\\Paired Samples T-Test &gt; Wilcoxon Rank jamovi-Output Wilcoxon Rank 8.7.3 Wilcoxon-Rangsummentest Der Wilcoxon-Rangsummentest (= Mann-Whitney-U-Test) wird für den Vergleich von zwei Mittelwerten verwendet, wenn der Stichprobenumfang n &lt; 30 ist oder wenn die Daten nicht normalverteilt sind. Beispiel: Erreichen Studierende, die während einer Woche täglich 30 Minuten Statistikübungen machen, bessere Noten in einer Statistikprüfung? Für diese Studie wurden 15 Studierende zufällig ausgewählt und zufällig den Gruppen INT (n = 8) und CON (n = 7) zugeteilt. Beide Gruppen besuchten die Statistikvorlesung. Die Studierenden der Gruppe INT machten zusätzlich während einer Woche täglich 30 Min. Statistikübungen, die Gruppe CON machte keine Statistikübungen. Nach einer Woche wurde ein Statistiktest durchgeführt, der mit 0 bis 100 Punkten bewertet wurde. Tabelle 8.12: Daten Statistikresultate INT CON 89, 92, 94, 96, 91, 99, 84, 90 88, 93, 95, 75, 72, 80, 81 Tabelle 8.13: Kennzahlen für Statistikresultate Gruppe n m Median s CON 7 83.43 81.0 8.81 INT 8 91.88 91.5 4.58 Die deskriptive Analyse ergibt, dass die Interventionsgruppe im Durchschnitt 8.45 Punkte mehr erreicht als die Kontrollgruppe. Der Stichprobenumfang ist kleiner als 30 und die Daten sind leicht linkssteil verteilt; daher sind die Voraussetzungen für einen T-Test nicht erfüllt. Abbildung 8.9: Boxplot für Statistikresultate Hypothesen \\(H_0: P(INT &gt; CON) = P(CON &gt; INT)\\), die Summen der Rangplätze von INT und CON unterscheiden sich nicht. \\(H_A: P(INT &gt; CON) \\neq P(CON &gt; INT)\\), die Summen der Rangplätze von INT und CON unterscheiden sich. Signifikanzniveau \\(\\alpha = 0.05\\) Für den Mann-Whitney-U-Test berechnen wir die Testgrösse U. \\(U\\) ist der kleinere Wert von den beiden \\(U_1\\) und \\(U_2\\), die wie folgt berechnet werden: \\(U_1 = n_1 \\times n_2+\\frac{n_1 \\times (n_1+1)}{2} - R_1\\) \\(U_2 = n_1 \\times n_2+\\frac{n_2 \\times (n_2+1)}{2} - R_2\\) wobei, \\(n_1\\) und \\(n_2\\) die jeweiligen Stichprobenumfänge und \\(R_1\\) und \\(R_2\\) die Rangsummen der Gruppen 1 und 2 sind. Tabelle 8.14: Statistikresultate mit Rängen Gruppe Punkte Rang INT 99 1 INT 96 2 CON 95 3 INT 94 4 CON 93 5 INT 92 6 INT 91 7 INT 90 8 INT 89 9 CON 88 10 INT 84 11 CON 81 12 CON 80 13 CON 75 14 CON 72 15 Tabelle 8.14: Rangsummen für INT und CON Gruppe Rangsumme CON 72 INT 48 Abbildung 8.10: Punktediagramm der Ränge für Statistikresultate Berechnung der Testgrössen \\(U_1\\) für die Interventionsgruppe und \\(U_2\\) für die Kontrollgruppe \\(U_1 = 8\\times7+\\frac{8(8+1)}{2} - 48 = 44\\) \\(U_2 = 8\\times7+\\frac{7(7+1)}{2} - 72 = 12\\) Unsere Testgrösse \\(U\\) ist die kleinere der beiden Grössen \\(U_1\\) und \\(U_2\\): \\(U = 12\\) Berechnung des p-Werts mit R ### R-Code U &lt;- 12 p_Wert &lt;- 2 * (1 - pwilcox(U, m = 8, n = 7, lower.tail = FALSE)) p_Wert ## [1] 0.07210567 Da der p-Wert mit 0.0721 grösser als \\(\\alpha = 0.05\\) verwerfen wir die Nullhypothese nicht. Schlussfolgerung: Untersucht wurde die Frage, ob Studierende, die während einer Woche täglich 30 Minuten Statistikübungen machen, bessere Punktzahlen erreichen als Studierende, die das nicht tun. Studierende, die während einer Woche täglich 30 Minunten Statistikübungen machen, erreichten in unserer Studie im Durchschnitt eine um 8.45 Punkte höhere Punktzahl in der Statistikprüfung, Mann-Whitney-U = 12, p = 0.0721. Damit liegt keine Evidenz dafür vor, dass sich die Prüfungsergebnisse im Durchschnitt zwischen den beiden Gruppen unterscheiden. 8.7.3.1 R/jamovi R Code und Output ### R-Code wilcox.test( Punkte ~ Gruppe, data = statex, paired = FALSE, alternative = &quot;two.sided&quot;) ## ## Wilcoxon rank sum exact test ## ## data: Punkte by Gruppe ## W = 12, p-value = 0.07211 ## alternative hypothesis: true location shift is not equal to 0 jamovi-Output jamovi\\T-Tests\\Independent Samples T-Test\\Mann-Whitney U jamovi-Output Mann Whitney U-Test 8.7.3.2 Voraussetzungen für den Wilcoxon-Rangsummen-Test: Die Daten sind mindestens qualitativ-ordinal skaliert (Likert-Skalen, visuelle Analogskalen). Es müssen zwei unabhängige Zufallsstichproben vorliegen. Die Daten sollten gleich verteilt sein (z.B. beide linksschief) Abbildung 8.11: Gleiche versus ungleiche Verteilung References "],["inferenz-für-nominale-daten.html", "9 Inferenz für nominale Daten 9.1 Lernziele 9.2 Der \\(\\chi^2\\)-Test 9.3 Referenzen", " 9 Inferenz für nominale Daten In diesem Kapitel lernen wir, wie Häufigkeiten von qualitativ-nominalen Variablen statistisch verglichen werden. Für die Analyse qualitativer Daten existieren zahlreiche statistische Werkzeuge, von denen hier nur eine kleine Auswahl behandelt wird. 9.1 Lernziele Verwende einen \\(\\chi^2\\)-Test, wenn die Unabhängigkeit von zwei nominalen Variablen geprüft werden soll: \\(H_0\\): Die zwei Variablen sind unabhängig. \\(H_A\\): Die zwei Variablen sind abhängig. Berechne die erwarteten Werte in Kreuztabellen als \\[E = \\frac{Zeilensumme \\times Spaltensumme}{Total}\\] Berechne die Anzahl Freiheitsgrade der \\(\\chi^2\\)-Verteilung als \\(df = (Z-1)\\times(S-1)\\), wobei Z die Anzahl Zeilen und S die Anzahl Spalten darstellt. 9.2 Der \\(\\chi^2\\)-Test Der \\(\\chi^2\\)-Test ist einer der ältesten Hypothesentests. Er wurde um 1900 von Karl Pearson entwickelt und später von Sir Ronald Fisher verfeinert. Der \\(\\chi^2\\)-Test prüft, ob eine beobachtete Häufigkeitsverteilung einer nominalen Variable einer erwarteten Verteilung entspricht. Beispiel: Hatten die Eltern von Kindern mit Allergien selber häufiger Allergien als die Eltern von Kindern ohne Allergien? Für diese Fragestellung wurde eine Zufallsstichprobe von 38 Kindern und deren Eltern zu ihrem Allergiestatus befragt. Codiert wurden die Daten mit 0 = keine Allergie und 1 = Allergie. (Holbreich et al. 2012) 9.2.1 Hypothesen und Signifikanzniveau \\(H_0\\): Es besteht keine Beziehung zwischen einer Allergie bei Kindern und deren Eltern. Die relative Häufigkeit der Kinder, bei denen mindestens ein Elternteil eine Allergie hat(te), ist in den Populationen der Allergiker und der Nichtallergiker gleich. Wir nehmen also an: Die Wahrscheinlichkeit, dass mindestens ein Elternteil eine Allergie hatte, hat keinen Zusammenhang damit, ob das befragte Kind selber eine Allergie hat oder nicht. \\(H_A\\): Es besteht eine Beziehung zwischen einer Allergie bei Kinderen und deren Eltern. Die relative Häufigkeit der Kinder, bei denen mindestens ein Elternteil eine Allergie hatte, unterscheidet sich zwischen den Populationen der Allergiker und der Nichtallergiker. Wir nehmen also an: Die Wahrscheinlichkeit, dass mindestens ein Elternteil eine Allergie hat(te), hängt davon ab, ob die befragte Person selber eine Allergie hat oder nicht. Als Entscheidungsgrenze legen wir auch in diesem Fall ein Signifikanzniveau von \\(\\alpha = 0.05\\) fest. Für die Darstellung der Ergebnisse eignet sich eine Vierfeldertafel (Kreuztabelle, Kontingenztabelle): ## ## CONTINGENCY TABLES ## ## Contingency Tables ## -------------------------------------------------------------- ## kind 0 1 Total ## -------------------------------------------------------------- ## 0 Observed 17 5 22 ## % of total 44.73684 13.15789 57.89474 ## ## 1 Observed 7 9 16 ## % of total 18.42105 23.68421 42.10526 ## ## Total Observed 24 14 38 ## % of total 63.15789 36.84211 100.00000 ## -------------------------------------------------------------- ## ## ## &lt;U+03C7&gt;² Tests ## -------------- ## Value ## -------------- ## N 38 ## -------------- 17 (44.7%) Eltern, deren Kinder keine Allergie haben, sind keine Allergiker:innen. 7 (18.4%) Eltern, deren Kinder eine Allergie haben, sind keine Allergiker:innen. 5 (13.2%) Eltern, deren Kinder keine Allergie haben, sind Allergiker:innen. 14 (36.8%) Eltern, deren Kinder eine Allergie haben, sind Allergiker:innen. Die Fälle, in denen Kinder und deren Eltern den gleichen Allergiestatus (beide Allergie oder beide keine Allergie) haben, machen zusammen über 78% der Fälle aus. Dies könnte ein Hinweis sein, dass eine Beziehung zwischen dem Allergiestatus von Kindern und deren Eltern besteht. Als nächstes möchten wir erfahren, ob die beobachteten Daten den Erwartungen unter der Nullhypothese entsprechen. Dazu müssen wir die erwarteten Werte berechnen. 9.2.2 Berechnen der erwarteten Werte unter der Nullhypothese Die Berechnung erfolgt am einfachsten, indem man die Zeilen- und Spaltensummen multipliziert und durch das Gesamttotal dividiert. Schema: Spalte A Spalte B Zeile A \\(\\frac{Zeilensumme A \\times Spaltensumme A}{Total}\\) \\(\\frac{Zeilensumme A \\times Spaltensumme B}{Total}\\) Zeilensumme A Zeile B \\(\\frac{Zeilensumme B \\times Spaltensumme A}{Total}\\) \\(\\frac{Zeilensumme B \\times Spaltensumme B}{Total}\\) Zeilensumme B Spaltensumme A Spaltensumme B Total Übungshalber kann man das von Hand machen, einfacher geht es aber mit R/jamovi ## ## CONTINGENCY TABLES ## ## Contingency Tables ## ---------------------------------------------------------- ## kind 0 1 Total ## ---------------------------------------------------------- ## 0 Observed 17 5 22 ## Expected 13.89474 8.105263 22.00000 ## ## 1 Observed 7 9 16 ## Expected 10.10526 5.894737 16.00000 ## ## Total Observed 24 14 38 ## Expected 24.00000 14.000000 38.00000 ## ---------------------------------------------------------- ## ## ## &lt;U+03C7&gt;² Tests ## -------------- ## Value ## -------------- ## N 38 ## -------------- Der Vergleich der erwarteten mit den beobachteten Werten unterstützt unsere bereits gemachte Vermutung: Die beobachteten Fälle, bei denen die Eltern den gleichen Allergiestatus haben wie die Kinder sind deutlich grösser, als wir sie unter der Nullhypothese erwarten würden. 9.2.3 Voraussetzungen Um einen \\(\\chi^2\\)-Test durchzuführen müssen folgende Voraussetzungen erfüllt sein: Die erwarteten Häufigkeiten in jeder Zelle der Tabelle müssen grösser als 5 sein. Ist diese Bedingung nicht erfüllt, kann der Fishers exakter Test verwendet werden. Der Test darf nur auf absolute Häufigkeiten und niemals auf relative Häufigkeiten angewendet werden. Die Daten stammen aus einer Zufallsstichprobe. Um eine Entscheidung zu treffen, ob die Beziehung statistisch signifikant ist müssen wir die Testgrösse \\(\\chi^2\\) berechnen. Die Formel dazu ist: \\[\\chi^2 = \\sum_{i=1}^n \\frac{(O_i - E_i)^2}{E_i}\\] Das sieht für manche beängstigend aus, aber wir machen das hier nur, um das Prinzip zu zeigen: \\(O\\) steht für beobachtete Werte, \\(E\\) für erwartete Werte. Jetzt setzen wir unsere Werte aus der Tabelle oben in die Formel ein: \\[\\chi^2 = \\frac{(17-13.9)^2}{13.9} + \\frac{(5-8.1)^2}{8.1} + \\frac{(7-10.1)^2}{10.1} + \\frac{(9-5.9)^2}{5.9} \\approx 4.46\\] Unsere Testgrösse ist \\(\\chi^2 = 4.46\\). Wie für die bereits bekannten Testgrössen \\(z\\) und \\(t\\) existiert auch für \\(\\chi^2\\) eine spezifische Wahrscheinlichkeitsverteilung, eben die \\(\\chi^2\\)-Verteilung. Es würde zu weit führen, im Detail auf diese Verteilung einzugehen, deren Form wie wie bei der t-Verteilung nur durch die Anzahl Freiheitsgrade df definiert ist. Anhand von Tabellen oder mit R/jamoviist es möglich, die Wahrscheinlichkeit für unseren \\(\\chi^2\\)-Wert zu berechnen. In R/jamovi erfolgt diese Berechnung mit der Funktion pchisq(). Die Freiheitsgrade in einer \\(n \\times m\\)-Tabelle werden berechnet als \\(df = (n - 1)\\times(m-1)\\), im vorliegenden Fall also: \\(df = (2-1)\\times(2-1) = 1\\). Abbildung 9.1: Chi-Quadrat-Verteilung für df = 1 Ohne komplizierte Berechnungen kann der Test in jamovidurchgeführt werden und ergibt: ## ## CONTINGENCY TABLES ## ## Contingency Tables ## ---------------------------------------------------------- ## kind 0 1 Total ## ---------------------------------------------------------- ## 0 Observed 17 5 22 ## Expected 13.89474 8.105263 22.00000 ## ## 1 Observed 7 9 16 ## Expected 10.10526 5.894737 16.00000 ## ## Total Observed 24 14 38 ## Expected 24.00000 14.000000 38.00000 ## ---------------------------------------------------------- ## ## ## &lt;U+03C7&gt;² Tests ## ------------------------------------- ## Value df p ## ------------------------------------- ## &lt;U+03C7&gt;² 4.473688 1 0.0344206 ## N 38 ## ------------------------------------- 9.2.4 Interpretation des \\(\\chi^2\\)-Tests Die Wahrscheinlichkeit für \\(\\chi^2 = 4.47\\) und \\(df = 1\\) ist \\(p = 0.034\\). Da der p-Wert kleiner als das Signifikanzniveau \\(\\alpha = 0.05\\) ist, verwerfen wir die Nullhypothese zu Gunsten der Alternativhypothese. Schlussfolgerung: Untersucht wurde die Frage, ob eine Beziehung zwischen dem Allergiestatus von Kindern und dem Allergiestatus ihrer Eltern besteht. Anhand einer Zufallsstichprobe von 38 Kindern und deren Eltern konnte ein signifikanter Zusammenhang festgestellt werden: Kinder von Eltern ohne Allergien leiden eher seltener als erwartet an Allergien und Kinder von Eltern mit Allergien leiden eher häufiger als erwartet an Allergien, \\(\\chi^2(1)\\) = 4.47, p = 0.034. Hinweis: Bei einer Vierfeldertafel (2 Zeilen und 2 Kolonnen) ist der Zusammenhang zwischen der Zeilen- und der Kolonnenvariable statistisch signifikant auf dem Niveau von 5%, wenn der \\(\\chi^2\\)-Wert grösser als 3.84 ist. Früher musste der exakte p-Wert in Tabellen der \\(\\chi^2\\)-Verteilung nachgeschaut werden, heute macht das der PC. 9.3 Referenzen "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
